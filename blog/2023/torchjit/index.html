<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Deploying Pytorch Model Without Releasing Model Code | Yen-Lin Chen</title> <meta name="author" content="Yen-Lin Chen"> <meta name="description" content="Deploying pytorch Model without releasing model code"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jipq6175.github.io/blog/2023/torchjit/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yen-Lin </span>Chen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blogs<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Deploying Pytorch Model Without Releasing Model Code</h1> <p class="post-meta">March 8, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/coding"> <i class="fas fa-hashtag fa-sm"></i> coding</a>   <a href="/blog/tag/solving"> <i class="fas fa-hashtag fa-sm"></i> solving</a>     ·   <a href="/blog/category/pytorch"> <i class="fas fa-tag fa-sm"></i> pytorch</a>   </p> </header> <article class="post-content"> <p>I have been encountering situations where I would like to deploy a trained pytorch model but feeling reluctant to have the full model details revealed. This might be the case where end users will try to copy and reproduce the model (even though the training data is the key) or the code or model has not been published or the model source code needs to be protected.</p> <p>My typical workflow for preliminary model deployemnt has been setting up the models and load the training checkpoints and then do model inference:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># saving the model
</span><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sh">'</span><span class="s">model.pt</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># loading the model
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">model.pt</span><span class="sh">'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="c1"># inference 
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="nf">model</span><span class="p">()</span></code></pre></figure> <p>Even the above is dockerized, in the container, there is still raw model code. The end user can just ssh and fetch the code.</p> <p>Another way to avoid revealing the model code in the deployment is using a cloud api, which I will explore later in my current project.</p> <p>For now, what I am after is like a binary file, that can just load the saved model and do inference on user’s data for some prediction. I found this interesting tool: <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html" rel="external nofollow noopener" target="_blank">TorchScript</a>. Basically, it can save the model not as <code class="language-plaintext highlighter-rouge">state_dict</code> but as JIT compiled function, similar to how <code class="language-plaintext highlighter-rouge">Julia</code> compiles a function into binary.</p> <h3 id="simple-example">Simple Example</h3> <p>A very basic example. Say one has a model to deploy without source code.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">99</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="nf">print</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.5713</span><span class="p">,</span> <span class="mf">0.4536</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.7102</span><span class="p">,</span> <span class="mf">0.2850</span><span class="p">,</span> <span class="mf">0.1824</span><span class="p">,</span> <span class="mf">0.1124</span><span class="p">]])</span></code></pre></figure> <p>Instead of saving the model dictionary, one can do</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">traced_cell</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">traced_cell</span><span class="p">,</span> <span class="sh">'</span><span class="s">model.jit</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>The <code class="language-plaintext highlighter-rouge">torch.jit.trace</code> takes 2 arguments: <code class="language-plaintext highlighter-rouge">model</code> and <code class="language-plaintext highlighter-rouge">inputs</code> which can be tensor or tuple of tensors. If the model’s forward pass take multiple tensors, they can be <code class="language-plaintext highlighter-rouge">torch.jit.trace(model, (x1, x2, x3))</code>.</p> <p>Now at inference time, one does not need to define <code class="language-plaintext highlighter-rouge">Model</code> in the code, just load <code class="language-plaintext highlighter-rouge">model.jit</code> then deploy.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">99</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">model.jit</span><span class="sh">'</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="nf">print</span><span class="p">(</span><span class="nf">loaded_model</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.5713</span><span class="p">,</span> <span class="mf">0.4536</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.7102</span><span class="p">,</span> <span class="mf">0.2850</span><span class="p">,</span> <span class="mf">0.1824</span><span class="p">,</span> <span class="mf">0.1124</span><span class="p">]])</span></code></pre></figure> <p>The outputs are the same.</p> <h3 id="gnn-example">GNN Example</h3> <p>The model I am trying to deploy is a GNN model with multiple input tensors of complex information. I will use a trivial GNN model trained on Cora dataset.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># load the Cora data
</span><span class="kn">from</span> <span class="n">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">Planetoid</span>
<span class="kn">from</span> <span class="n">torch_geometric.transforms</span> <span class="kn">import</span> <span class="n">NormalizeFeatures</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="nc">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">data/Planetoid</span><span class="sh">'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Cora</span><span class="sh">'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">NormalizeFeatures</span><span class="p">())</span>

<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Dataset: </span><span class="si">{</span><span class="n">dataset</span><span class="si">}</span><span class="s">:</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">======================</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of graphs: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of features: </span><span class="si">{</span><span class="n">dataset</span><span class="p">.</span><span class="n">num_features</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of classes: </span><span class="si">{</span><span class="n">dataset</span><span class="p">.</span><span class="n">num_classes</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Dataset</span><span class="p">:</span> <span class="nc">Cora</span><span class="p">():</span>
<span class="o">======================</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">graphs</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">features</span><span class="p">:</span> <span class="mi">1433</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">classes</span><span class="p">:</span> <span class="mi">7</span></code></pre></figure> <p>The GNN model is just a three-hop graph convolution.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GraphConv</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">GraphNet</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">GraphNet</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">89</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">num_node_features</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">num_classes</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span> 
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">).</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">).</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="nc">GraphNet</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nc">GraphNet</span><span class="p">(</span>
  <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="mi">1433</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="p">)</span></code></pre></figure> <p>Let’s train it briefly:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GraphNet</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train_gnn</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">)</span> 
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">train_mask</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">train_mask</span><span class="p">])</span>  
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  
    <span class="k">return</span> <span class="n">loss</span>

<span class="k">def</span> <span class="nf">test_gnn</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">test_correct</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">test_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">test_mask</span><span class="p">]</span>  
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">test_correct</span><span class="p">.</span><span class="nf">sum</span><span class="p">())</span> <span class="o">/</span> <span class="nf">int</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">test_mask</span><span class="p">.</span><span class="nf">sum</span><span class="p">())</span>  
    <span class="k">return</span> <span class="n">test_acc</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">)):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">train_gnn</span><span class="p">()</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test_gnn</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Epoch</span><span class="p">:</span> <span class="mi">050</span><span class="p">,</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.8477</span><span class="p">,</span> <span class="n">Test</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.697</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5670</span><span class="p">,</span> <span class="n">Test</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.731</span></code></pre></figure> <p>Assume the model is fully trained and is ready to be saved.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">traced_cell</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">))</span> <span class="c1"># the model inputs are node feature x and edge indices
</span><span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">traced_cell</span><span class="p">,</span> <span class="sh">'</span><span class="s">gnn_model.jit</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>And in the inference time, in another machine or compute environment, just load the <code class="language-plaintext highlighter-rouge">gnn_model.jit</code> without explicitly writing the <code class="language-plaintext highlighter-rouge">GraphNet</code> model:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">Planetoid</span>
<span class="kn">from</span> <span class="n">torch_geometric.transforms</span> <span class="kn">import</span> <span class="n">NormalizeFeatures</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">gnn_model.jit</span><span class="sh">'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="nc">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">data/Planetoid</span><span class="sh">'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Cora</span><span class="sh">'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">NormalizeFeatures</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">2708</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span></code></pre></figure> <p>This is the model prediction for 2708 nodes with 7 classes.</p> <p>We still can get the number of parameters is the same way and look into model weights:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="k">break</span>

<span class="nf">print</span><span class="p">()</span>
<span class="nf">sum</span><span class="p">(</span><span class="n">param</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span> <span class="mf">0.0042</span><span class="p">,</span>  <span class="mf">0.0584</span><span class="p">,</span>  <span class="mf">0.0186</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0327</span><span class="p">,</span>  <span class="mf">0.0167</span><span class="p">,</span>  <span class="mf">0.0612</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0389</span><span class="p">,</span>  <span class="mf">0.0680</span><span class="p">,</span>  <span class="mf">0.0121</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0318</span><span class="p">,</span>  <span class="mf">0.0492</span><span class="p">,</span>  <span class="mf">0.0837</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0114</span><span class="p">,</span>  <span class="mf">0.0003</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0106</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0071</span><span class="p">,</span>  <span class="mf">0.0634</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0186</span><span class="p">],</span>
        <span class="p">...,</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0026</span><span class="p">,</span>  <span class="mf">0.0363</span><span class="p">,</span>  <span class="mf">0.0133</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0569</span><span class="p">,</span>  <span class="mf">0.0296</span><span class="p">,</span>  <span class="mf">0.0702</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0274</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0403</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0286</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0239</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0148</span><span class="p">,</span>  <span class="mf">0.0049</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0077</span><span class="p">,</span>  <span class="mf">0.0201</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0033</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0302</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0283</span><span class="p">,</span>  <span class="mf">0.0827</span><span class="p">]],</span>
       <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="mi">94279</span></code></pre></figure> <h3 id="save-compiled-torch-function">Save compiled torch function</h3> <p><code class="language-plaintext highlighter-rouge">torch.jit.trace</code> extends beyond just pytorch models. It can be applied to pytorch functions as well. It can save a compiled function, which can be loaded without defining the function explicitly, like a binary.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">some_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nf">some_function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span></code></pre></figure> <p>And use the same trick.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">traced_cell</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">some_function</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">traced_cell</span><span class="p">,</span> <span class="sh">'</span><span class="s">some_function.jit</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>In another python script or in another machine, just do:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">f</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">some_function.pth</span><span class="sh">"</span><span class="p">)</span>
<span class="n">f</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nc">RecursiveScriptModule</span><span class="p">(</span><span class="n">original_name</span><span class="o">=</span><span class="n">PlaceholderModule</span><span class="p">)</span></code></pre></figure> <p>And</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">f</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span></code></pre></figure> <p>That’s pretty convenient. The inference pipeline can consist of a number of these compiled models as blackboxes without revealing the code of the model or functions.</p> <p>Another advantage. There are a number of models with different hyperparameters at deployment. I had to fetch the model config via <code class="language-plaintext highlighter-rouge">wandb</code> and initiate the model accordingly before loading the state dictionary. But with saved jit-compiled model, just load them and forward pass (given that they all take the same inputs).</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Yen-Lin Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 27, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>