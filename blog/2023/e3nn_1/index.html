<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Neural Networks with Euclidean Symmetries - 1 | Yen-Lin Chen</title> <meta name="author" content="Yen-Lin Chen"> <meta name="description" content="Playing and benchmarking with E3NN"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jipq6175.github.io/blog/2023/e3nn_1/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yen-Lin </span>Chen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blogs<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Neural Networks with Euclidean Symmetries - 1</h1> <p class="post-meta">June 18, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/coding"> <i class="fas fa-hashtag fa-sm"></i> coding</a>   <a href="/blog/tag/reading"> <i class="fas fa-hashtag fa-sm"></i> reading</a>   <a href="/blog/tag/solving"> <i class="fas fa-hashtag fa-sm"></i> solving</a>     ·   <a href="/blog/category/models"> <i class="fas fa-tag fa-sm"></i> models</a>   </p> </header> <article class="post-content"> <p>Recently, I have been working with equivariant or invariant models. The models leverage inductive bias in the data. For example, convolutional layers is translational equivariant. The messaging aggregation function in the graph neural networks is permutational invariant. Physical data is typically in 3D and the models should respect euclidean symmetries, E(3). If the model does not respect E(3) symmetry, it is usually required to augment the data by random rotation and translation, which is an infinite amount of augmented data and the model might be hard to optimize.</p> <p>If \(f: V \to V\) is an equivariant function on \(G\) and \(g\) is a group operation in \(G\). We have a data \(x\) on some vector space \(V\). We have</p> \[f(g \circ x) = g \circ f(x)\] <p>I am going to explore a general framework <code class="language-plaintext highlighter-rouge">e3nn</code>, which has taken care of the equivariant operations using irreproducible representations, <code class="language-plaintext highlighter-rouge">irreps</code>. There are 3 cases/tasks I want to explore in this post:</p> <ol> <li> <p>Tetris shape prediction: Given 3D coordinates of the voxels of a tetris block, predict the shape. The coordinates might be randomly rotated or translated and the model needs to generalize.</p> </li> <li> <p>Trajectory prediction: Given a 12-body system and coordinates at certain time, predict 12 coordinates at the next time step. The system and physical motions should be independent of the reference frame, therefore, if we rotate or translate the coordinates, the motions should be equivariant.</p> </li> <li> <p>Electron density prediction: The electron density is usually represented by the linear combinations of spherical harmonics, \(Y^l_m\). The goal is to predict the coefficients, which fits nicely to the irreps in <code class="language-plaintext highlighter-rouge">e3nn</code>.</p> </li> </ol> <h1 id="1-tetris">1. Tetris</h1> <p>Given 3D coordinates of the voxels of a tetris block, predict the shape. The coordinates might be randomly rotated or translated and the model needs to generalize.</p> <h2 id="11-packages">1.1 Packages</h2> <p>We will use some basic packages like <code class="language-plaintext highlighter-rouge">torch</code>, geometric libraries <code class="language-plaintext highlighter-rouge">torch_geometric</code> and augmented torch libraries <code class="language-plaintext highlighter-rouge">torch_cluster</code> and <code class="language-plaintext highlighter-rouge">torch_scatter</code>. The main one I am going to use is the <code class="language-plaintext highlighter-rouge">e3nn</code> package.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># minimal example for mesing with e3nn
</span><span class="kn">import</span> <span class="n">torch</span><span class="p">,</span> <span class="n">logging</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="n">torch_cluster</span> <span class="kn">import</span> <span class="n">radius_graph</span>
<span class="kn">from</span> <span class="n">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GATConv</span>
<span class="kn">from</span> <span class="n">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter</span>

<span class="kn">from</span> <span class="n">e3nn</span> <span class="kn">import</span> <span class="n">o3</span>
<span class="kn">from</span> <span class="n">e3nn.o3</span> <span class="kn">import</span> <span class="n">FullyConnectedTensorProduct</span>
<span class="kn">from</span> <span class="n">e3nn.util.test</span> <span class="kn">import</span> <span class="n">assert_equivariant</span>
<span class="kn">from</span> <span class="n">e3nn.nn.models.gate_points_2101</span> <span class="kn">import</span> <span class="n">Network</span>

<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span></code></pre></figure> <h2 id="12-tetris-toy-dataset">1.2 Tetris toy dataset</h2> <p>Each tetris block contain 4 voxels of size 1x1x1. There are 8 different shapes.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># chiral_shape_1
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># chiral_shape_2
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># square
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)],</span>  <span class="c1"># line
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># corner
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># L
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>  <span class="c1"># T
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># zigzag
</span>    <span class="p">]</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">get_default_dtype</span><span class="p">())</span>

    <span class="c1"># Since chiral shapes are the mirror of one another we need an *odd* scalar to distinguish them
</span>    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># chiral_shape_1
</span>            <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># chiral_shape_2
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># square
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># line
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># corner
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># L
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># T
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># zigzag
</span>        <span class="p">],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">get_default_dtype</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="c1"># apply shuffling of data
</span>    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span> 
        <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randperm</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="c1"># apply random rotation
</span>    <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">"</span><span class="s">zij,zaj-&gt;zai</span><span class="sh">"</span><span class="p">,</span> <span class="n">o3</span><span class="p">.</span><span class="nf">rand_matrix</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">pos</span><span class="p">)),</span> <span class="n">pos</span><span class="p">)</span>

    <span class="c1"># put in torch_geometric format
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">)</span> <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">pos</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="nf">iter</span><span class="p">(</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>

    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span></code></pre></figure> <p>Note that the chiral shape has parity, i.e. the label of the chiral shape is a <code class="language-plaintext highlighter-rouge">pseudo-scalar</code>, which flip signs upon mirror reflection.</p> <p>Everything should look familiar, maybe except for <code class="language-plaintext highlighter-rouge">o3.rand_matrix(n)</code>. It generates \(n\) 3x3 random rotational matrices, which were applied to the coordinates.</p> <p>Let’s take a look at the data.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
</pre></td> <td class="code"><pre><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></td> </tr></tbody></table></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nc">DataBatch</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">batch</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">ptr</span><span class="o">=</span><span class="p">[</span><span class="mi">9</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span></code></pre></figure> <p>The data follows the <code class="language-plaintext highlighter-rouge">torch_geometric</code> convention where <code class="language-plaintext highlighter-rouge">batch</code> represents which graph the positions belong to and the <code class="language-plaintext highlighter-rouge">ptr</code> is the pointer to the start of each graph.</p> <h2 id="13-gnn-baseline">1.3 GNN Baseline</h2> <p>Let’s build a simple GNN baseline model using message passing with attention: <code class="language-plaintext highlighter-rouge">GATConv</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># GNN base line
</span><span class="k">class</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim_in</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dim_out</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">GNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim_in</span> <span class="o">=</span> <span class="n">dim_in</span>
        <span class="n">self</span><span class="p">.</span><span class="n">edge_dim</span> <span class="o">=</span> <span class="n">edge_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim_out</span> <span class="o">=</span> <span class="n">dim_out</span>
        <span class="n">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>

        <span class="c1"># irreps of spherical harmonics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">gat1</span> <span class="o">=</span> <span class="nc">GATConv</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gat2</span> <span class="o">=</span> <span class="nc">GATConv</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">GELU</span><span class="p">(),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">num_neighbors</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">4</span>
        
        <span class="c1"># tensors of indices representing the graph, using fully connected
</span>        <span class="n">edge_index</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">10.1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        
        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># GNN message passing
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gat1</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_features</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gat2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_features</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Again, this is a very typical GNN and forward pass. However, there are some foreign stuff sneaking in the code and I’ll explain. Since the input or the data only contains a set of 4 coordinates, (x, y, z). The node and edge contain absolutely no features at all except for the coordinates. I am going to use, again, spherical harmonics to featurize the edges and nodes.</p> <p>The line <code class="language-plaintext highlighter-rouge">self.irreps_sh = o3.Irreps.spherical_harmonics(3)</code> is the basis of the spherical harmonics, containing the following irreps:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span></code></pre></figure> <p><code class="language-plaintext highlighter-rouge">1x0e+1x1o+1x2e+1x3o</code></p> <p>Ok and let me expand these weird codes. There are 4 irreps in the above expression. Each irrep is of the form of <code class="language-plaintext highlighter-rouge">mxlp</code>, where</p> <ul> <li> <code class="language-plaintext highlighter-rouge">m</code> is the multiplicity, i.e. the number of features</li> <li> <code class="language-plaintext highlighter-rouge">x</code> just stands for times</li> <li> <p><code class="language-plaintext highlighter-rouge">l</code> is the rotation order, or the first quantum number of electron orbitals or the order of spherical harmonics.</p> <ul> <li> <code class="language-plaintext highlighter-rouge">l = 0</code> is transformed as scalar (one number), or the <code class="language-plaintext highlighter-rouge">l = 0</code> orbital, which is a sphere.</li> <li> <code class="language-plaintext highlighter-rouge">l = 1</code> is transformed as vector (three numbers), or the <code class="language-plaintext highlighter-rouge">l = 1</code> orbital, which aligns with the x, y, z axes, corresponding to 3 quantum numbers <code class="language-plaintext highlighter-rouge">m = -1, 0, 1</code>.</li> <li> <code class="language-plaintext highlighter-rouge">l = 2</code> is transformed as ?…? (five numbers), or the <code class="language-plaintext highlighter-rouge">l = 2</code> orbital, which are more complicated, corresponding to 5 quantum numbers <code class="language-plaintext highlighter-rouge">m = -2, -1, 0, 1, 2</code>.</li> </ul> </li> <li> <code class="language-plaintext highlighter-rouge">p</code> describes the parity: even <code class="language-plaintext highlighter-rouge">e</code> or odd <code class="language-plaintext highlighter-rouge">o</code>, describing how these tensors transform under mirror reflection.</li> </ul> <p>So <code class="language-plaintext highlighter-rouge">16x1o</code> is a set of 16 vectors with odd parity.</p> <p>Another line is the <code class="language-plaintext highlighter-rouge">radius_graph(x=data.pos, r=10.1, batch=data.batch)</code> which constructs the <code class="language-plaintext highlighter-rouge">edge_index</code> just using the coordinates and batch. I used <code class="language-plaintext highlighter-rouge">r = 10.1</code> or something <code class="language-plaintext highlighter-rouge">r &gt; 3.1</code> to construct the fully connected graph of 4 nodes. These edges are directional, because they are translational vectors. So in the above line, we will have <code class="language-plaintext highlighter-rouge">4 * 3 = 12</code> edges for each graph. Therefore,</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">10.1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">).</span><span class="n">shape</span>
<span class="c1"># 12 * 8 (graphs) edges in total</span></code></pre></figure> <p><code class="language-plaintext highlighter-rouge">torch.Size([2, 96])</code></p> <p>Since the input is only the 3D coordinates, the straightforward featurization is using the distance vector, \(\mathbf{r}_i - \mathbf{r}_j\) where \(\mathbf{r}\) is the position vector. We further use the coefficients of spherical harmonics as edge features, i.e. we project the distance vector on <code class="language-plaintext highlighter-rouge">l=0, 1, 2, 3</code> spherical harmonics and get the coefficients, with a total number of <code class="language-plaintext highlighter-rouge">1 + 3 + 5 + 7 = 16</code> coefficients. Note that \(&lt;Y^l_m, Y^{l'}_{m'}&gt; = \delta_{ll'}\delta_{mm'}\), meaning that they are orthogonal bases.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">edge_features</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># 96 (edges) x 16 (edge features) tensor</span></code></pre></figure> <p>The node features are the aggregated of the edge features of the inward edges.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># 32 (nodes) x 16 (node features) tensor</span></code></pre></figure> <p>With the node and edge features using spherical harmonics, we can just create a graph convolution and a readout for tetris shape prediction.</p> <p>Let’s build a general training function that can be used for all the models built for this task.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># model training script 
</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>

    <span class="n">every_n</span> <span class="o">=</span> <span class="n">epochs</span> <span class="o">//</span> <span class="mi">100</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)})</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span> 
        <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="n">acc</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="nf">round</span><span class="p">().</span><span class="nf">eq</span><span class="p">(</span><span class="n">labels</span><span class="p">).</span><span class="nf">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">double</span><span class="p">().</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span>

        <span class="n">s</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">epoch </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="mi">5</span><span class="n">d</span><span class="si">}</span><span class="s"> | loss </span><span class="si">{</span><span class="mf">1e3</span> <span class="o">*</span> <span class="n">loss</span><span class="si">:</span><span class="o">&lt;</span><span class="mf">10.1</span><span class="n">f</span><span class="si">}</span><span class="s"> | </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">acc</span><span class="si">:</span><span class="mf">5.1</span><span class="n">f</span><span class="si">}</span><span class="s">% accuracy</span><span class="sh">'</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">every_n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">logs</span></code></pre></figure> <p>Now we can try to train our GNN baseline model:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">g</span><span class="p">,</span> <span class="n">g_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">GNN</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">g_shuffle</span><span class="p">,</span> <span class="n">g_shuffle_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">GNN</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># epoch 10000 | loss 41.9       |  75.0% accuracy: 100%|██████████| 10001/10001 [01:25&lt;00:00, 117.05it/s]
# epoch 10000 | loss 40.5       |  75.0% accuracy: 100%|██████████| 10001/10001 [01:25&lt;00:00, 116.74it/s]</span></code></pre></figure> <p>Training on CPU took about 90 seconds for 10000 epochs. We tried no shuffling and shuffling and the final loss were \(41.9\) and \(40.5\) respectively. They achieved final accuracy of \(75\%\), which is not optimal given the easiness of the task and small number of data and large GNN models with <code class="language-plaintext highlighter-rouge">GATConv</code>.</p> <h2 id="14-e3nn">1.4 E3NN</h2> <p>In previous GNN model, I used a small part of <code class="language-plaintext highlighter-rouge">e3nn</code> for featurization but the model is still not aware of the E(3) symmetry: it just did something like <code class="language-plaintext highlighter-rouge">torch.nn.Linear</code> and ignored the relationship/interaction of each element under E(3). We were also toruched on the irreps, which I feel it might be better to go through them again.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># We have seen the irreps for spherical harmonics with lmax = 3
</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># 1x0e + 1x1o + 1x2e + 1x3o representing spherical harmonics of lmax = 3</span></code></pre></figure> <p>Similar to the <code class="language-plaintext highlighter-rouge">hidden dimension</code> in the hidden layers of neural networks, we can also define the <code class="language-plaintext highlighter-rouge">hidden irreps</code> in e3nn.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">irreps_mid</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">64x0e + 24x1e + 24x1o + 16x2e + 16x2o</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># 64x0e = 64 hidden scalar, l = 0
# 24x1e = 24 hidden pseudo-vector, l = 1
# 24x1o = 24 hidden vector, l = 1
# 16x2e = 16 even tensor, l = 2
# 16x2o = 16 odd tensor, l=2
# So we have 64 + 24 x 3 + 24 x 3 + 16 x 5 + 16 x 5 = 368 dim tensor as output of the hidden layer. </span></code></pre></figure> <p>The neural network layer (or the Linear layer) in e3nn is called the <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code> with trainable weights. At initialization, it takes 2 input irreps and 1 output 1rreps and in the forward pass, it takes 2 tensors with corresponding input irreps. This layer dictates the interaction between different irreps.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># tensor product 1
</span><span class="n">tp1</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">irreps_in2</span><span class="o">=</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">)</span>
<span class="c1"># each path corresponds to one parameters, the path is defined by |l1 - l2| &lt;= lout &lt;= l1 + l2
# the above layer contains 648 paths and therefore 648 parameters
# this can be shown: 64 * 4 (0e) + 24 * 3 (1e) + 24 * 6 (1o) + 16 * 7 (2e) + 16 * 4 (2o)</span></code></pre></figure> <p>We can check if the above tensor product is the same as exhausting all possible paths of the irreps.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># or we can check this: 
</span><span class="n">npaths</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">in1</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">1x0e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x1o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x2e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x3o</span><span class="sh">'</span><span class="p">]:</span> 
    <span class="k">for</span> <span class="n">in2</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">1x0e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x1o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x2e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x3o</span><span class="sh">'</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">64x0e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">24x1e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">24x1o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">16x2e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">16x2o</span><span class="sh">'</span><span class="p">]:</span> 
            <span class="n">p</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="n">in1</span><span class="p">),</span> 
                                                  <span class="n">irreps_in2</span><span class="o">=</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="n">in2</span><span class="p">),</span> 
                                                  <span class="n">irreps_out</span><span class="o">=</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="n">out</span><span class="p">)).</span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">npaths</span> <span class="o">+=</span> <span class="n">p</span>
            <span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">in1</span><span class="si">}</span><span class="s"> + </span><span class="si">{</span><span class="n">in2</span><span class="si">}</span><span class="s"> -&gt; </span><span class="si">{</span><span class="n">out</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">npaths</span> <span class="o">==</span> <span class="n">tp1</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># The output: 
# 1x0e + 1x0e -&gt; 64x0e, 64
# 1x0e + 1x1o -&gt; 24x1o, 24
# 1x0e + 1x2e -&gt; 16x2e, 16
# 1x1o + 1x0e -&gt; 24x1o, 24
# 1x1o + 1x1o -&gt; 64x0e, 64
# 1x1o + 1x1o -&gt; 24x1e, 24
# 1x1o + 1x1o -&gt; 16x2e, 16
# 1x1o + 1x2e -&gt; 24x1o, 24
# 1x1o + 1x2e -&gt; 16x2o, 16
# 1x1o + 1x3o -&gt; 16x2e, 16
# 1x2e + 1x0e -&gt; 16x2e, 16
# 1x2e + 1x1o -&gt; 24x1o, 24
# 1x2e + 1x1o -&gt; 16x2o, 16
# 1x2e + 1x2e -&gt; 64x0e, 64
# 1x2e + 1x2e -&gt; 24x1e, 24
# 1x2e + 1x2e -&gt; 16x2e, 16
# 1x2e + 1x3o -&gt; 24x1o, 24
# 1x2e + 1x3o -&gt; 16x2o, 16
# 1x3o + 1x1o -&gt; 16x2e, 16
# 1x3o + 1x2e -&gt; 24x1o, 24
# 1x3o + 1x2e -&gt; 16x2o, 16
# 1x3o + 1x3o -&gt; 64x0e, 64
# 1x3o + 1x3o -&gt; 24x1e, 24
# 1x3o + 1x3o -&gt; 16x2e, 16</span></code></pre></figure> <p>And we can visualize these interaction paths:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tp1</span><span class="p">.</span><span class="nf">visualize</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/paths-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/paths-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/paths-1400.webp"></source> <img src="/assets/img/posts/e3nn/paths.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Now we can define our simple equivariant model using e3nn’s <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">InvariantPolynomial</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">InvariantPolynomial</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> 
        <span class="c1"># dimension = 16 = 1 + 3 + 5 + 7
</span>        
        <span class="n">irreps_mid</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">64x0e + 24x1e + 24x1o + 16x2e + 16x2o</span><span class="sh">'</span><span class="p">)</span> 
        <span class="c1"># dimension = 368 = (64 * 1) + (24 * 3) + (24 * 3) + (16 * 5) + (16 * 5)
</span>        
        <span class="n">irreps_out</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">0o + 6x0e</span><span class="sh">'</span><span class="p">)</span> 
        <span class="c1"># dimension = (1 * 1) + (6 * 1), the first one is the pseudo-scalar for chiral +1, -1
</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tp1</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> 
                                               <span class="n">irreps_in2</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span>
                                               <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">tp2</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">,</span>
                                               <span class="n">irreps_in2</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span>
                                               <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_out</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tp2</span><span class="p">.</span><span class="n">irreps_out</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">num_neighbors</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">4</span>
        
        <span class="c1"># tensors of indices representing the graph
</span>        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
        
        <span class="c1"># edge distance vector
</span>        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        
        <span class="n">edge_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
        <span class="c1"># edge_sh is the coefficients of spherical harmonics from l=0 to l=3
</span>        <span class="c1"># or edge_sh is the projection of edge_vec on spherical harmonics basis
</span>        <span class="c1"># edge_sh is a 50 (number of edges by `radius_graph`) x 16 (l=3 spherical harmonics, i.e. 1 + 3 + 5 + 7) 
</span>        
        
        <span class="c1"># For each node, the initial features are the sum of the spherical harmonics of the neighbors
</span>        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_sh</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>


        <span class="c1"># For each edge, tensor product the features on the source node with the spherical harmonics
</span>        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp1</span><span class="p">(</span><span class="n">node_features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_sh</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
        

        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp2</span><span class="p">(</span><span class="n">node_features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_sh</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>


        <span class="c1"># For each graph, all the node's features are summed as final prediction
</span>        <span class="k">return</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span></code></pre></figure> <p>We use the <code class="language-plaintext highlighter-rouge">train</code> function again.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">f</span><span class="p">,</span> <span class="n">f_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantPolynomial</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">f_shuffle</span><span class="p">,</span> <span class="n">f_shuffle_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantPolynomial</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># epoch 10000 | loss 7.3        | 100.0% accuracy: 100%|██████████| 10001/10001 [00:41&lt;00:00, 241.84it/s]
# epoch 10000 | loss 2.0        | 100.0% accuracy: 100%|██████████| 10001/10001 [00:41&lt;00:00, 243.12it/s]</span></code></pre></figure> <p>Clearly, the model was trained better due to the E(3) equivariance. No shuffling and shuffling model achieved a final loss of \(7.3\) and \(2.0\) respectively with \(100\%\) accuracy, which is a lot better than the GNN baseline.</p> <h2 id="15-fancy-e3nn">1.5 Fancy E3NN</h2> <p>I have seen some people use the existent model of e3nn instead of writing the <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code>. We will use this fancier model from e3nn: <code class="language-plaintext highlighter-rouge">gate_points_2101.Network</code>.</p> <p>We start off by assigning some hyperparameter:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">irreps_in</span><span class="sh">"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>  <span class="c1"># no input features
</span>    <span class="sh">"</span><span class="s">irreps_hidden</span><span class="sh">"</span><span class="p">:</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">64x0e + 24x1e + 24x1o + 16x2e + 16x2o</span><span class="sh">'</span><span class="p">),</span>  <span class="c1"># hyperparameter: hidden irreps
</span>    <span class="sh">"</span><span class="s">irreps_out</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">0o + 6x0e</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># the same output irreps
</span>    <span class="sh">"</span><span class="s">irreps_node_attr</span><span class="sh">"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">irreps_edge_attr</span><span class="sh">"</span><span class="p">:</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="c1"># using spherical(3) for featurization
</span>    <span class="sh">"</span><span class="s">layers</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>  <span class="c1"># hyperparameter: depth of the hidden irreps layer
</span>    <span class="sh">"</span><span class="s">max_radius</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span> 
    <span class="sh">"</span><span class="s">number_of_basis</span><span class="sh">"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">radial_layers</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">radial_neurons</span><span class="sh">"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">num_neighbors</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># average number of neighbors w/in max_radius
</span>    <span class="sh">"</span><span class="s">num_nodes</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>  <span class="c1"># not important unless reduce_output is True
</span>    <span class="sh">"</span><span class="s">reduce_output</span><span class="sh">"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>  <span class="c1"># setting this to true would give us one scalar as an output.
</span><span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Network</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span> </code></pre></figure> <p>The output of the model is a <code class="language-plaintext highlighter-rouge">32 x 7</code> tensor, i.e. for each coordinate (regardless of the batch), the model outputs the 7-tensor. We need to aggregate these 4 7-tensors like before according to batch. So we created another wrapper model:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">InvariantNetwork</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">InvariantNetwork</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model_kwargs</span> <span class="o">=</span> <span class="n">model_kwargs</span>
        <span class="n">self</span><span class="p">.</span><span class="n">network</span> <span class="o">=</span> <span class="nc">Network</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span> 
        <span class="n">node_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model_kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">num_nodes</span><span class="sh">'</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span></code></pre></figure> <p>Again, we use our <code class="language-plaintext highlighter-rouge">train</code> function.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">ff</span><span class="p">,</span> <span class="n">ff_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantNetwork</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ff_shuffle</span><span class="p">,</span> <span class="n">ff_shuffle_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantNetwork</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># epoch 10000 | loss 0.0        | 100.0% accuracy: 100%|██████████| 10001/10001 [04:12&lt;00:00, 39.67it/s]
# epoch 10000 | loss 0.0        | 100.0% accuracy: 100%|██████████| 10001/10001 [04:17&lt;00:00, 38.89it/s]</span></code></pre></figure> <p>And.. take a look at those too-good-to-be-true losses and accuracies.</p> <h2 id="16-comparisons">1.6 Comparisons</h2> <p>Let’s compare the 3 models trained: GNN, E3NN Basic, E3NN Fancy. We plot the training losses and accuracies using the logs.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_yscale</span><span class="p">(</span><span class="sh">'</span><span class="s">log</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Loss</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/compare-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/compare-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/compare-1400.webp"></source> <img src="/assets/img/posts/e3nn/compare.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <h2 id="17-check-equivariance">1.7 Check Equivariance</h2> <p>Finally, we need to check the model equivariance, using our very first equation</p> \[f(g \circ x) = g \circ f(x)\] <p>where \(g\) here is a 3D rotation or translation and \(f\) is our trained model. The model is acturally invariant, i.e. the output does not depend on the transformation of group operation.</p> \[f(g \circ x) = f(x)\] <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># == Check equivariance ==
# Because the model outputs (psuedo)scalars, we can easily directly
# check its equivariance to the same data with new rotations:
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Testing equivariance directly...</span><span class="sh">"</span><span class="p">)</span>

<span class="n">data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">rotated_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># GNN
</span><span class="n">error</span> <span class="o">=</span> <span class="nf">g</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">g</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">shuffle_error</span> <span class="o">=</span> <span class="nf">g_shuffle</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">g_shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">GNN: Equivariance error = </span><span class="si">{</span><span class="n">error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">GNN Shuffle: Equivariance error = </span><span class="si">{</span><span class="n">shuffle_error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># E3NN Basic
</span><span class="n">error</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">f</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">shuffle_error</span> <span class="o">=</span> <span class="nf">f_shuffle</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">f_shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Basic: Equivariance error = </span><span class="si">{</span><span class="n">error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Basic Shuffle: Equivariance error = </span><span class="si">{</span><span class="n">shuffle_error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># E3NN Fancy
</span><span class="n">error</span> <span class="o">=</span> <span class="nf">ff</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">ff</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">shuffle_error</span> <span class="o">=</span> <span class="nf">ff_shuffle</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">ff_shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Fancy: Equivariance error = </span><span class="si">{</span><span class="n">error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Fancy Shuffle: Equivariance error = </span><span class="si">{</span><span class="n">shuffle_error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>


<span class="c1"># Testing equivariance directly...
</span>
<span class="c1"># GNN: Equivariance error = 3.6e-01
# GNN Shuffle: Equivariance error = 3.3e-01
</span>
<span class="c1"># E3NN Basic: Equivariance error = 9.5e-07
# E3NN Basic Shuffle: Equivariance error = 9.5e-07
</span>
<span class="c1"># E3NN Fancy: Equivariance error = 5.5e-06
# E3NN Fancy Shuffle: Equivariance error = 5.7e-06</span></code></pre></figure> <p>And we can test the equivariance using e3nn’s <code class="language-plaintext highlighter-rouge">assert_equivariant</code> function.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Testing equivariance using `assert_equivariance`...</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># We can also use the library's `assert_equivariant` helper
# `assert_equivariant` also tests parity and translation, and
# can handle non-(psuedo)scalar outputs.
# To "interpret" between it and torch_geometric, we use a small wrapper:
</span>
<span class="k">def</span> <span class="nf">fwrapper</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span> <span class="k">return</span> <span class="nf">f</span><span class="p">(</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">ffwrapper</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span> <span class="k">return</span> <span class="nf">ff</span><span class="p">(</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">))</span>

<span class="c1"># `assert_equivariant` uses logging to print a summary of the equivariance error,
# so we enable logging
</span><span class="n">logging</span><span class="p">.</span><span class="nf">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>

<span class="nf">assert_equivariant</span><span class="p">(</span>
    <span class="n">fwrapper</span><span class="p">,</span>
    <span class="n">args_in</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">],</span> <span class="c1"># We provide the original data that `assert_equivariant` will transform...
</span>    <span class="n">irreps_in</span><span class="o">=</span><span class="p">[</span> <span class="c1"># ...in accordance with these irreps...
</span>        <span class="sh">"</span><span class="s">cartesian_points</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># pos has vector 1o irreps, but is also translation equivariant
</span>        <span class="bp">None</span><span class="p">,</span>  <span class="c1"># `None` indicates invariant, possibly non-floating-point data
</span>    <span class="p">],</span>
    <span class="n">irreps_out</span><span class="o">=</span><span class="p">[</span><span class="n">f</span><span class="p">.</span><span class="n">irreps_out</span><span class="p">],</span> <span class="c1"># ...and confirm that the outputs transform correspondingly for these irreps:
</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="nf">assert_equivariant</span><span class="p">(</span><span class="n">ffwrapper</span><span class="p">,</span> <span class="n">args_in</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">],</span> <span class="n">irreps_in</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">cartesian_points</span><span class="sh">"</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">irreps_out</span><span class="o">=</span><span class="p">[</span><span class="n">f</span><span class="p">.</span><span class="n">irreps_out</span><span class="p">])</span>


<span class="c1"># INFO:e3nn.util.test:Tested equivariance of `fwrapper` -- max componentwise errors:
# (parity_k=0, did_translate=False) -&gt; max error=7.153e-07 in argument 0
# (parity_k=0, did_translate=True) -&gt; max error=2.339e-06 in argument 0
# (parity_k=1, did_translate=False) -&gt; max error=8.848e-07 in argument 0
# (parity_k=1, did_translate=True) -&gt; max error=1.810e-06 in argument 0
# INFO:e3nn.util.test:Tested equivariance of `ffwrapper` -- max componentwise errors:
# (parity_k=0, did_translate=False) -&gt; max error=2.742e-06 in argument 0
# (parity_k=0, did_translate=True) -&gt; max error=1.824e-05 in argument 0
# (parity_k=1, did_translate=False) -&gt; max error=3.345e-06 in argument 0
# (parity_k=1, did_translate=True) -&gt; max error=2.146e-05 in argument 0
# Testing equivariance using `assert_equivariance`...</span></code></pre></figure> <p>And this concludes the part 1 of initial messing around of e3nn.</p> <h1 id="references">References</h1> <ol> <li>Mario Geiger, Tess Smidt, e3nn: Euclidean Neural Networks, https://arxiv.org/abs/2207.09453</li> <li>https://e3nn.org</li> <li>https://docs.e3nn.org/en/latest/examples/tetris_polynomial.html</li> </ol> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Yen-Lin Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 27, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>