<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>C4 Group CNN | Yen-Lin Chen</title> <meta name="author" content="Yen-Lin Chen"> <meta name="description" content="A small exercise to implement C4 group convolution"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jipq6175.github.io/blog/2023/c4_convolution/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yen-Lin </span>Chen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blogs<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">C4 Group CNN</h1> <p class="post-meta">June 13, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/coding"> <i class="fas fa-hashtag fa-sm"></i> coding</a>   <a href="/blog/tag/reading"> <i class="fas fa-hashtag fa-sm"></i> reading</a>     ·   <a href="/blog/category/models"> <i class="fas fa-tag fa-sm"></i> models</a>   </p> </header> <article class="post-content"> <p>This was my learning process for the simple group convolution from scratch, which I did back in 2021 along with the <a href="https://geometricdeeplearning.com/lectures/" rel="external nofollow noopener" target="_blank">Geometric Deep Learning (GDL) course</a>. This is part of the tutorial 2, which can be found <a href="https://colab.research.google.com/drive/1p9vlVAUcQZXQjulA7z_FyPrB9UXFATrR" rel="external nofollow noopener" target="_blank">here</a>. I was trying to remind myself of some of the key concepts by cleaning my previous codes and summarizing here for myself.</p> <p>The key of the group equivariant neural network is to identify the spaces of input, hidden and output because the network will perform like a function mapping from one space to another. I use \(X\), \(Y\) as input and output spaces and \(H_i\) as the i-th hidden space. The network consists a number of layers, transforming the input to hidden to output:</p> \[X \to H_1 \to H_2 \to ... \to H_i \to ... \to Y\] <p>Each of the layers is represented as \(\to\) in the above and depneding on which spaces the layers map from and to, we need to consider the design of the layers. This will be the focus of this post.</p> <h3 id="0-dependencies">0. Dependencies</h3> <p>Let’s just load some dependencies for later use.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># packages
</span><span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">torch</span><span class="p">,</span> <span class="n">einops</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="n">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>

<span class="n">TOL</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="c1"># if torch.cuda.is_available(): DEVICE = 'cuda'
# else: DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'
</span><span class="n">DEVICE</span> <span class="o">=</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span> <span class="c1"># I find the 'mps' device is buggy or I have not spent time to write better code for the mac gpu
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span></code></pre></figure> <h3 id="1-group">1. Group</h3> <p>A group \((G, \circ )\) is a set \(G\) with a binary operation: \(\circ : G\times G \to G\), which satisfies the following (Ignored the \(\circ\)).</p> <ul> <li>Associativity: \(a (bc) = (ab) c\)</li> <li>Identity: \(e \in G\), \(g e = e g = g\)</li> <li>Inverse: \(\forall g \in G\), \(gg^{-1} = g^{-1}g = e\)</li> </ul> <p>Consider the group \(G = C_4\), the cyclic group with \(\pi / 2\) planar rotation. \(\|C_4\| = 4\). Let \(X\) be the set of some \(n\times n\) gray images. An image \(x \in X\) is a function \(x: p \to x[p] \in R\) which maps each pixel \(p = (h, w)\) to a real number.</p> <p>An element \(g \in G = C_4\), transforms an image \(x \in X\) into the image \(gx \in X\) through rotation. The rotated image \(gx\) is \([gx](p) = x(g^{-1}p)\) where \(g^{-1}p\) is the pixel in the unrotated image. This action is the following:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># rotate an image, the x is ... x H x W in dimension
</span><span class="k">def</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="p">.</span><span class="nf">rot90</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span></code></pre></figure> <h3 id="2-equivariant-convolution-layers">2. Equivariant Convolution Layers</h3> <p>An equivariant layer (or function) \(\psi: X \to Y\) from an input G-space \(X\) to an output G-space \(Y\). The input space is the pixel space and we choose the same output space: \(Y=X\). So both input and output are the gray-scale image (they might be of different sizes / dimensions.)</p> <p>The equivariant layer will be \(3 \times 3\) filter. We will verify that a random filter is not a rotational equivariant layer.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># random filter
</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span> <span class="o">**</span> <span class="mi">3</span>
<span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">psi_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">psi_gx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">gx</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">g_psi_x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$g.\psi(x)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$\psi(g.x)$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">TOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>Not equivariant!!</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig1-1400.webp"></source> <img src="/assets/img/posts/gcnn/fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Clearly, if the filter \(\psi\) has no constraint on the weights,</p> \[\psi(gx) \neq g\psi(x)\] <p>There must be some \(C_4\) symmetry boiled in the filter. Let’s first try the isotropic filter where there are 2 trainable weights: one in the middle, the the other in the ring.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Isotropic filter
# The filter looks like: 
# a, a, a
# a, b, a
# a, a, a
</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>

<span class="nb">filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">filter</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">()</span> <span class="c1"># middle pixel
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">filter</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">()</span> <span class="c1"># ring pixel
</span>
<span class="c1"># we recycle the previous codes: 
</span><span class="n">psi_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">psi_gx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">gx</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">g_psi_x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$g.\psi(x)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$\psi(g.x)$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">TOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>Equivariant</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig2-1400.webp"></source> <img src="/assets/img/posts/gcnn/fig2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Let’s use this filter to build a equivariant convolution layer:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">IsotropicEConv2d</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">IsotropicEConv2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>

        <span class="c1"># for each filter contains 2 parameters
</span>        <span class="c1"># There are total of in_channels x out_channels filters
</span>        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">out_channels</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">bias</span> <span class="k">else</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">build_filter</span><span class="p">(</span><span class="n">self</span><span class="p">):</span> 
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">)</span>
        <span class="nb">filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="nb">filter</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
        <span class="nb">filter</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">filter</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">_filter</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">build_filter</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span></code></pre></figure> <p>Since this layer maps from input space \(X\) to input space \(X\), so we define the following equivariance checker.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">check_equivariance_XX</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">):</span> 

    <span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

    <span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">psi_x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">psi_gx</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
    <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">psi_x</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span></code></pre></figure> <p>Let’s check if the <code class="language-plaintext highlighter-rouge">IsotropicEConv2d</code> is acturally equivariant:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">33</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">layer</span> <span class="o">=</span> <span class="nc">IsotropicEConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">check_equivariance_XX</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">g_psi_x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$g.\psi(x)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$\psi(g.x)$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <p>Equivariant</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig3-1400.webp"></source> <img src="/assets/img/posts/gcnn/fig3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Unfortunately, isotropic filters are not very expressive. Instead, we would like to use more general, unconstrained filters. To do so, we need to rely on group convolution.</p> <p>Let \(X\) be the space of grayscale images, \(\psi \in X\) be a filter and \(x \in x\) be an input image. The group convolution is</p> \[[\psi x](t, r) = \sum_{p} \psi((t, r)^{-1}p)x(p) = \sum_{p} \psi(r^{-1}(p - t))x(p)\] <p>The output of the convolution is not a grayscale image in \(X\). It is now a function over the rotational group. The use of the filter \(\psi\) in the group convolution maps the input space \(X\) into a new larger space $Y$, where \(Y\) is the space of all function \(y: p_4 \to \mathbf{R}\).</p> <p>This is the lifting convolution since it maps the space \(X\) to the more complex space \(Y\). Note that a function \(y \in Y\) can be implemented as a 4-channel image, where the ith channel is defined as \(y_i(t) = y(y, r=i) \in \mathbf{R}, i \in \{0, 1, 2, 3\}\)</p> <p>In the end of the day, we want to have a network</p> \[X \to H_1 \to H_2 \to ... \to Y\] <p>where \(X\) is the grayscale image or the 3-channel image space and \(H\)’s are the group (hidden) space and \(Y\) can be a pooled invariant output or equivariant output space.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span> 
    <span class="c1"># y is (..., 4, h, w)
</span>    <span class="c1"># r = 0, 1, 2, 3
</span>    
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">3</span>
    <span class="k">assert</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>
    <span class="k">assert</span> <span class="n">r</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

    <span class="n">ry</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="c1"># then we just rotate each of the 4 channels
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">ry</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span> <span class="o">%</span> <span class="mi">4</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">r</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ry</span></code></pre></figure> <p>See the rotation p4 group by \(r = 1\):</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Test the rotation by r = 1
</span><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span> <span class="o">**</span> <span class="mi">3</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span>


<span class="n">ry</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">'</span><span class="s">Original y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">ry</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">'</span><span class="s">Rotated y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig4-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig4-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig4-1400.webp"></source> <img src="/assets/img/posts/gcnn/fig4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig5-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig5-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig5-1400.webp"></source> <img src="/assets/img/posts/gcnn/fig5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Next, we will build a lifting convoltuion. The input is a grayscale image \(x \in X\) and the output is a function \(y \in Y\). This can berealized by exploiting the usual convolution using 4 rotated copies of a <code class="language-plaintext highlighter-rouge">SINGLE</code> learnable filter. The image is colvolved with each copy independently by stacking 4 copies into a unique filter with 4 output channels.</p> <p>Finally, a convolutional layer usually includes a bias term. In a normal convolutional network, it is common to share the same bias over all pixels, i.e. the same bias is summed to the features at each pixel. Similarly, when we use a lifting convolution, we share the bias over all pixels but also over all rotations, i.e. over the output channels.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Lift conv of C4 Group
</span>
<span class="k">class</span> <span class="nc">LiftingConv2d</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LiftingConv2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="c1"># learnable weights for `out_channels x in_channels` different learnable filters, each of shape `kernel_size x kernel_size`
</span>        <span class="c1"># later populate the larger C4 filters of shape `out_channels x 4 x in_channels x kernel_size x kernel_size` by rotating 4 times 
</span>        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">).</span><span class="nf">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                                                               <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">)),</span>
                                         <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_build_filter</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># using the tensors of learnable parameters, build 
</span>        <span class="c1"># - the `out_channels x 4 x in_channels x kernel_size x kernel_size` filter
</span>        <span class="c1"># - the `out_channels x 4` bias
</span>        <span class="n">_filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">_filter</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c -&gt; c g</span><span class="sh">'</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        
        <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_build_filter</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">_filter</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">lifting _filter has shape </span><span class="si">{</span><span class="n">_filter</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        <span class="k">assert</span> <span class="n">_bias</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">lifting _bias has shape </span><span class="si">{</span><span class="n">_bias</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        
        <span class="n">_filter</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_filter</span><span class="p">,</span> <span class="sh">'</span><span class="s">o c i w h -&gt; (o c) i w h</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c g -&gt; (c g)</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">_bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="sh">'</span><span class="s">b (o c) w h -&gt; b o c w h</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    </code></pre></figure> <p>Since this layer maps from input space \(X\) to group space \(Y\), so we define the following equivariance checker.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">check_equivariance_XY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">):</span> 

    <span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

    <span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in X
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">psi_x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">psi_gx</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
    <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in Y
</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">psi_x</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span>
    </code></pre></figure> <p>Let’s check if the <code class="language-plaintext highlighter-rouge">LiftingConv2d</code> is equivariant.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Let's check if the layer is really equivariant
</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">33</span>

<span class="n">layer</span> <span class="o">=</span> <span class="nc">LiftingConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># layer.to(DEVICE)
</span><span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
<span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">check_equivariance_XY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Equivariant</p> <p>The lifting convolution is only the first piece of building the \(C_4\) equivariant neural network. Remember we are after</p> \[X \to H_1 \to H_2 \to ... \to Y\] <p>and lifting convolution is the first “\(\to\)”, we still need to build equivariant layers from \(H_i \to H_j\).</p> <p>As compared to the usual CNN: \(X \to X \to X ... \to Y\).</p> <p>We will construct the convolution on the <code class="language-plaintext highlighter-rouge">OUTPUT</code> from the lifting convolution.</p> \[[\psi x](t, r) = \sum_{s \in C_4}\sum_{p}[r \psi](p-t, s)x(p, s)\] <p>So we simply use additional 4-rotated filters for the convolution of the input, i.e. 4 rotated filters for 4 channels from lift convolution. The output of this group convolution is also 4 channels and we can stack this group convolution to build a deep G-CNN.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># GroupConv2d
</span>
<span class="k">class</span> <span class="nc">GroupConv2d</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GroupConv2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> 
                                                     <span class="mi">4</span><span class="p">,</span>
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">).</span><span class="nf">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                                                               <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">)),</span>
                                         <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_build_filter</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># using the tensors of learnable parameters, build 
</span>        <span class="c1"># - the `out_channels x 4 x in_channels x 4 x kernel_size x kernel_size` filter
</span>        <span class="c1"># - the `out_channels x 4` bias
</span>        <span class="n">_filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">_filter</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c -&gt; c g</span><span class="sh">'</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        
        <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_build_filter</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">_filter</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">groupconv _filter has shape </span><span class="si">{</span><span class="n">_filter</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        <span class="k">assert</span> <span class="n">_bias</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">groupconv _bias has shape </span><span class="si">{</span><span class="n">_bias</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        
        <span class="n">_filter</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_filter</span><span class="p">,</span> <span class="sh">'</span><span class="s">o c i s w h -&gt; (o c) (i s) w h</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c g -&gt; (c g)</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="c1"># x is `batch_size x in_channels x 4 x W x H`
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="sh">'</span><span class="s">b i c w h -&gt; b (i c) w h</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">_bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="sh">'</span><span class="s">b (o c) w h -&gt; b o c w h</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    
        </code></pre></figure> <p>Now, <code class="language-plaintext highlighter-rouge">GroupConv2d</code> maps from group space \(Y\) to the same group space \(Y\). We will define another equivariance checker.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">check_equivariance_YY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">):</span> 

    <span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

    <span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in Y
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">psi_x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">psi_gx</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
    <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in Y
</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">psi_x</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span>
    </code></pre></figure> <p>And ckeck the equivariance.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Let's check if the layer is really equivariant
</span><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">33</span>

<span class="n">layer</span> <span class="o">=</span> <span class="nc">GroupConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">check_equivariance_YY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Equivariant</p> <h3 id="3-implement-a-deep-rotation-equivariant-cnn">3. Implement A Deep Rotation Equivariant CNN</h3> <p>Fianlly, you can combine the layers you have implemented earlier to build a rotation equivariant CNN. You model will take in input batches of $33 \times 33$ images with a single input channel.</p> <p>The network performs a first <em>lifting layer</em> with $8$ output channels and is followed by $4$ <em>group convolution</em> with, respectively, $16$, $32$, $64$ and $128$ output channels. All convolutions have kernel size $3$, padding $1$ and stride $1$ and should use the bias. All convolutions are followed by <code class="language-plaintext highlighter-rouge">torch.nn.MaxPool3d</code> and <code class="language-plaintext highlighter-rouge">torch.nn.ReLU</code>. Note that we use <code class="language-plaintext highlighter-rouge">MaxPool3d</code> rather than <code class="language-plaintext highlighter-rouge">MaxPool2d</code> since our feature tensors have $5$ dimensions (there is an additional dimension of size $4$). In all pooling layers, we will use a kernel of size $(1, 3, 3)$, a stride of $(1, 2, 2)$ and a padding of $(0, 1, 1)$. This ensures pooling is done only on the spatial dimensions, while the rotational dimension is preserved. The last pooling layer, however, will also pool over the rotational dimension so it will use a kernel of size $(4, 3, 3)$, stride $(1, 1, 1)$ and padding $(0, 0, 0)$.</p> <p>Finally, the features extracted from the convolutional network are used in a linear layer to classify the input in $10$ classes.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Equivariant Networks
</span>
<span class="c1"># Lifting Layers: X -&gt; Y over p4
# GroupConv Layers: Y -&gt; Y over p4
</span>
<span class="c1"># So the idea is to have a lifting layer followed by groupconv layers and non linearities
</span>
<span class="c1"># to make it invariant, make sure to use c4_pooling at the end
</span><span class="k">class</span> <span class="nc">C4CNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">C4CNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">channels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">n_classes</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">liftingconv</span> <span class="o">=</span> <span class="nc">LiftingConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> 
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">GroupConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">())</span>
            
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span> <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool3d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">groupconv_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">3200</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_c4_pool</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span> 
        <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span> <span class="c1"># batch, channel, group, height, weight
</span>        <span class="k">assert</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>

        <span class="n">x_pre_pool</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">x_pool</span> <span class="o">=</span> <span class="n">x_pre_pool</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_pool</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span> 
        <span class="n">lifted_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">liftingconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">gp_encoded_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">groupconv_encoder</span><span class="p">(</span><span class="n">lifted_x</span><span class="p">)</span> <span class="c1"># batch x channel x group x width x height
</span>
        <span class="c1"># Before pooling, the network is equivariant and after pooling, the model is invariant
</span>        <span class="c1"># however, the hidden features are still equivariant 
</span>        <span class="n">pooled_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_c4_pool</span><span class="p">(</span><span class="n">gp_encoded_x</span><span class="p">)</span> <span class="c1"># batch x channel x 1 x width x height
</span>        <span class="n">flattened_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">pooled_x</span><span class="p">)</span> <span class="c1"># batch x 3200
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">flattened_x</span><span class="p">)</span></code></pre></figure> <p>So <code class="language-plaintext highlighter-rouge">C4CNN</code> is invariant to \(C_4\) rotation, meaning that it can recognize an image even though it’s rotated in \(C_4\). the <code class="language-plaintext highlighter-rouge">C4CNN</code>, though invariant, it contains a lot to hidden features that are equivariant. In other words:</p> <p>Rotated image -&gt; rotated features -&gt; rotated features -&gt; … -&gt; invariant output</p> <p>Allowing the equivariant hidden features make the model more powerful and data efficient because the model is already symmetry-restricted.</p> <p>Let’s check if the <code class="language-plaintext highlighter-rouge">C4CNN</code> is invariant.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">net</span> <span class="o">=</span> <span class="nc">C4CNN</span><span class="p">()</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># batch x n_classes
</span>
<span class="c1"># Let's check if the model is invariant!
</span><span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">gy</span> <span class="o">=</span> <span class="nf">net</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">gy</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">TOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span></code></pre></figure> <h3 id="4-compare-cnn-to-gcnn-on-rotated-mnist-dataset">4. Compare CNN to GCNN on rotated MNIST dataset</h3> <p>After buidling the <code class="language-plaintext highlighter-rouge">C4CNN</code> as \(C_4\)-invariant model with \(C_4\)-equivariant features, we want to compare it with typical CNN on the rotated MNIST dataset.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># dataset
# https://zenodo.org/record/3670627/files/mnist_rotation_new.zip?download=1
</span><span class="k">class</span> <span class="nc">MnistRotDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">]</span>
            
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span> <span class="nb">file</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat</span><span class="sh">'</span>
        <span class="k">else</span><span class="p">:</span> <span class="nb">file</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat</span><span class="sh">'</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">)</span>    
        <span class="n">self</span><span class="p">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># images in MNIST are only 28x28
</span>        <span class="c1"># we pad them to have shape 33 x 33
</span>        <span class="n">self</span><span class="p">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">images</span><span class="p">,</span> <span class="n">pad_width</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">edge</span><span class="sh">'</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">self</span><span class="p">.</span><span class="n">images</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">)</span>


<span class="n">train_set</span> <span class="o">=</span> <span class="nc">MnistRotDataset</span><span class="p">(</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ToTensor</span><span class="p">())</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="nc">MnistRotDataset</span><span class="p">(</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ToTensor</span><span class="p">())</span></code></pre></figure> <p>We define functions to train and test models, which is typical pytorch forward pass with/without gradients.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">nepoch</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">nepoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>

            <span class="c1"># x, t = x.to(DEVICE), t.to(DEVICE)
</span>            <span class="n">y</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
          
            <span class="n">y</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">t</span><span class="p">).</span><span class="nf">sum</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
    
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="o">*</span><span class="mf">100.</span>
    <span class="k">return</span> <span class="n">accuracy</span></code></pre></figure> <p>Next, we define a CNN model similar to <code class="language-plaintext highlighter-rouge">C4CNN</code> by recycling the code.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Build a normal CNN 
</span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">channels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">first_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span> <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">first_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># x = torch.nn.functional.layer_norm(x, x.shape[-3:])
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">convs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># apply average pooling over remaining spatial dimensions
</span>        <span class="c1"># x = torch.nn.functional.adaptive_avg_pool2d(x, 1).squeeze()
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></code></pre></figure> <p>Let’s finally get the models trained and report the accuracies.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># training and keep the stats
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training C4CNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">c4cnn</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="nc">C4CNN</span><span class="p">(),</span> <span class="n">nepoch</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training CNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">cnn</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="nc">CNN</span><span class="p">(),</span> <span class="n">nepoch</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>


<span class="n">acc_c4cnn</span> <span class="o">=</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">c4cnn</span><span class="p">)</span>
<span class="n">acc_cnn</span> <span class="o">=</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">cnn</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">C4CNN Test Accuracy: </span><span class="si">{</span><span class="n">acc_c4cnn</span> <span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">CNN Test Accuracy: </span><span class="si">{</span><span class="n">acc_cnn</span> <span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">C4CNN</span> <span class="n">Test</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">91.744</span>
<span class="n">CNN</span> <span class="n">Test</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">82.134</span></code></pre></figure> <h3 id="5-final-note">5. Final Note</h3> <p>The performance of <code class="language-plaintext highlighter-rouge">C4CNN</code> is significantly higher. I also did 25 repeated runs and <code class="language-plaintext highlighter-rouge">C4CNN</code> and <code class="language-plaintext highlighter-rouge">CNN</code> averaged <code class="language-plaintext highlighter-rouge">92%</code> and <code class="language-plaintext highlighter-rouge">81%</code> in accuracy. However, <code class="language-plaintext highlighter-rouge">C4CNN</code> took about <code class="language-plaintext highlighter-rouge">5x</code> more time to train. Considering the (maybe) <code class="language-plaintext highlighter-rouge">4x</code> data one needs to augment, this might not be beneficial in this case and also <a href="https://distill.pub/2020/circuits/equivariance" rel="external nofollow noopener" target="_blank">natural equivariance</a> shows up in the trained filters.</p> <p>However, equivariance makes a lot difference in the continuous group where one cannot just rotate the filters to achieve equivariance.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Yen-Lin Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 27, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>