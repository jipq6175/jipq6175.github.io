<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://jipq6175.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jipq6175.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-27T15:26:56+00:00</updated><id>https://jipq6175.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Discrete Flow Matching</title><link href="https://jipq6175.github.io/blog/2025/discrete_flow_matching/" rel="alternate" type="text/html" title="Discrete Flow Matching"/><published>2025-06-27T11:01:32+00:00</published><updated>2025-06-27T11:01:32+00:00</updated><id>https://jipq6175.github.io/blog/2025/discrete_flow_matching</id><content type="html" xml:base="https://jipq6175.github.io/blog/2025/discrete_flow_matching/"><![CDATA[<p>We will explore the generative discrete flow matching model on <code class="language-plaintext highlighter-rouge">2D Checkerboard</code> and <code class="language-plaintext highlighter-rouge">Sequence</code> data.</p> <p>One benefit of DFM is to compute the ELBO or log-probability for any given data, by forward solving ODE using the trained model.</p> <p>This notebook is the standalone version for future references.</p> <h1 id="table-of-contents">Table of Contents:</h1> <ol> <li> <p>Discrete Frameworks</p> <p>1.1 Scheduler</p> <p>1.2 Mixture of discrete paths</p> <p>1.3 Training losses</p> <p>1.4 ODE/SDE solvers for DFM</p> </li> <li>Training Pipeline</li> <li>ELBO estimates</li> </ol> <p>The above will be applied to 2 cases: <code class="language-plaintext highlighter-rouge">2D</code> and <code class="language-plaintext highlighter-rouge">Sequence</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>

<span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">torch</span><span class="p">,</span> <span class="n">einops</span><span class="p">,</span> <span class="n">copy</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">matplotlib.cm</span> <span class="k">as</span> <span class="n">cm</span>

<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="kn">from</span> <span class="n">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Callable</span>
<span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="n">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">from</span> <span class="n">math</span> <span class="kn">import</span> <span class="n">ceil</span>
<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span>

<span class="n">SAVE_PATH</span> <span class="o">=</span> <span class="sh">'</span><span class="s">discrete_flow/</span><span class="sh">'</span>
<span class="n">os</span><span class="p">.</span><span class="nf">makedirs</span><span class="p">(</span><span class="n">SAVE_PATH</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <h2 id="1-discrete-frameworks">1. Discrete Frameworks</h2> <p>In the continuous case, at train time we do the following:</p> <ol> <li>Sample \(t\in[0,1]\)</li> <li>Sample data point \(x_1\sim q(x)\)</li> <li> <table> <tbody> <tr> <td>Sample $$x \sim p_t(x</td> <td>x_1)\(given some\)p_t$$</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>Compute corresponding vector field $$u_t(x</td> <td>x_1)$$</td> </tr> </tbody> </table> </li> <li>Use neural network \(v_{t,\theta}(x)\) to regress on the vector field</li> </ol> <p>In the discrete case, steps 1-2 remain and we need to massage the following steps:</p> <ol> <li>Sample \(x \sim p_t(x\|x_1)\) given some \(p_t\) using mixture of discrete path.</li> </ol> <p>4-5. Instead of regress on the flow vector field, we predict the \(x_1\) given \(x_t\) with typical cross-entropy loss or generalized KL-loss.</p> <p>We first take a look at the schedulers, which are identical to the continuous case. The scheduler holds the time-dependent mean \(\alpha_t\) and variance \(\sigma_t\) that models the normal distribution</p> \[p_t(x|x_1)\sim\mathcal{N}(x| \alpha_t x_1, \sigma_t^2I)\] <p>Again, \(\alpha_t\) and \(\sigma_t\) need to satisfy the boundary condition: \(\alpha_1 = \sigma_0 = 1\) and \(\alpha_0 = \sigma_1 = 0\)</p> <p>In the continuous case, the source distribution, \(p_0\) is usually signal-less by design to be a normal Gaussian distribution. In the discrete case, the source distribution at each position can be 2 cases:</p> <ol> <li>Uniform distribution over the discrete space or the vocabularies.</li> <li>Mask token</li> </ol> <p>Both source distributions provide signal-less and can be coupled with data distribution via any schedulers.</p> <h3 id="11-scheduler">1.1 Scheduler</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SchedulerOutput</span><span class="p">:</span> 
    
    <span class="n">alpha_t</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">sigma_t</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">d_alpha_t</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">d_sigma_t</span><span class="p">:</span> <span class="n">Tensor</span>
        

<span class="k">class</span> <span class="nc">Scheduler</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">Scheduler Base
       p_t(x | x_1) = N(x | alpha_t * x_1, sigma_t^2 * I)
    </span><span class="sh">'''</span>
    
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SchedulerOutput</span><span class="p">:</span>
        <span class="k">pass</span>


<span class="k">class</span> <span class="nc">ConditionalOTScheduler</span><span class="p">(</span><span class="n">Scheduler</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">Conditional OT Scheduler
       p_t(x | x_1) = N(x | t x_1, (1-t)^2 I)
    </span><span class="sh">'''</span>
    
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SchedulerOutput</span><span class="p">:</span> 
        <span class="k">return</span> <span class="nc">SchedulerOutput</span><span class="p">(</span><span class="n">alpha_t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> 
                               <span class="n">sigma_t</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">,</span> 
                               <span class="n">d_alpha_t</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">t</span><span class="p">),</span>
                               <span class="n">d_sigma_t</span><span class="o">=-</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>

    
<span class="k">class</span> <span class="nc">PolynomialScheduler</span><span class="p">(</span><span class="n">Scheduler</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">Polynomial Scheduler
       p_t(x | x_1) = N(x | t^n x_1, (1-t^n)^2 I)
    </span><span class="sh">'''</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span> 
        <span class="k">assert</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>
    
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SchedulerOutput</span><span class="p">:</span> 
        <span class="n">n</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">n</span>
        <span class="k">return</span> <span class="nc">SchedulerOutput</span><span class="p">(</span><span class="n">alpha_t</span><span class="o">=</span><span class="n">t</span> <span class="o">**</span> <span class="n">n</span><span class="p">,</span> 
                               <span class="n">sigma_t</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span> <span class="o">**</span> <span class="n">n</span><span class="p">,</span> 
                               <span class="n">d_alpha_t</span><span class="o">=</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">**</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span>
                               <span class="n">d_sigma_t</span><span class="o">=-</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">**</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
    
    
<span class="k">class</span> <span class="nc">CosineScheduler</span><span class="p">(</span><span class="n">Scheduler</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">Cosine Scheduler
       p_t(x | x_1) = N(x | sin(pi*t/2) x_1, cos(pi*t/2)^2 I)
    </span><span class="sh">'''</span>
    
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SchedulerOutput</span><span class="p">:</span> 
        <span class="n">pi</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">pi</span>
        <span class="k">return</span> <span class="nc">SchedulerOutput</span><span class="p">(</span><span class="n">alpha_t</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">*</span> <span class="n">t</span><span class="p">),</span>
                               <span class="n">sigma_t</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">*</span> <span class="n">t</span><span class="p">),</span> 
                               <span class="n">d_alpha_t</span><span class="o">=</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">*</span> <span class="n">t</span><span class="p">),</span>
                               <span class="n">d_sigma_t</span><span class="o">=-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">*</span> <span class="n">t</span><span class="p">))</span>
</code></pre></div></div> <h3 id="12-mixture-of-discrete-path">1.2 Mixture of Discrete Path</h3> <p>We denote a sequence \(x\) as an array with \(N\) element: \(x = (x_1, x_2, x_3, ..., x_N)\) where each element takes on discrete value from a set of vocabulary of size \(d\). The sequence space is then \(d^N\).</p> <p>Given samples from source and target distributions, \(x_0\) and \(x_1\), and any data coupling \(\pi(x_0, x_1)\), the probability path \(p_t\) can be represented with marginal probability paths:</p> \[p_t(x) = \sum_{x_0, x_1}p_t(x \mid x_0, x_1)\pi(x_0, x_1)\] <p>Since \(x\) is an N-dim array, we can further represent the marginal probability paths using the mixture of its individual components:</p> \[p_t(x|x_0, x_1) = \prod_{i=1}^N p_t(x^i \mid x_0, x_1)\] <p>\(p_t(x^i \mid x_0, x_1)\) is a time-dependent probability on the vocabulary set with boundary conditions defined by the source and target:</p> \[p_0(x^i \mid x_0, x_1) = \delta_{x_0}(x^i)\] \[p_1(x^i \mid x_0, x_1) = \delta_{x_1}(x^i)\] <p>where \(\delta_y(x^i) = 1\) if \(x^i = y^i\) and \(0\) otherwise.</p> <p>Then we can use a convex linear combination (similar to those in continuous case) to represent the individual one of a mixture of discrete paths:</p> \[p_t(x^i \mid x_0, x_1) = (1-\kappa_t)p_0(x^i \mid x_0, x_1) + \kappa_t p_1(x^i \mid x_0, x_1) = (1-\kappa_t)\delta_{x_0}(x^i) + \kappa_t \delta_{x_1}(x^i)\] <p>with \(0 &lt; \kappa_t &lt; 1\), \(\kappa_0 = 0\), \(\kappa_1 = 1\) and monotonically increasing.</p> <p>This individual marginal probability path for position \(i\) indicates that given time \(t\) and \(x_0\) and \(x_1\), \(x^i\) only got 2 choices: \(x_0^i\) with probability \(\kappa_t\) and \(x_1^i\) with probability \(1-\kappa_t\), i.e. \(x_i\) assumes either the source or target with time-dependent probability.</p> <p>The conditional marginal generating (forward) velocity is then</p> \[u_t^i(x^i \mid z) = \frac{\dot{\kappa_t}}{1 - \kappa_t}\left[p_{1 \mid t}(x^i|z) - \delta_z(x^i) \right]\] <p>(See Gat. et al 2024 for derivation)</p> <p>This velocity is used then the model is trained to be the denoiser (as compared to noise-prediction.) The \(\kappa_t\) is from the scheduler and \(p_{1 \mid t}(x^i \mid x)\) is the posterior probability defined on the vocabulary set of size \(d\). Essentially, this is from the trained neural network given noised sequence \(x_t\) at time \(t\) and predicting the posterior of the clean sequence \(x_1\). \(\delta_z(x^i)\) is the one-hot probability of \(x_t\). So this velocity makes \(x_t\) move toward predicted \(x_1\) at sampling. Note that \(\kappa_t = 1\) when \(t=1\) is a singularity for the generating velocity, so we typically do the sampling till \(t = 1-\epsilon\) and use \(p_{1 \mid t=1-\epsilon}(x^i \mid x)\) as the sample at \(x_1\).</p> <p>The reverse velocity is then</p> \[u_t^i(x^i \mid z) = \frac{\dot{\kappa_t}}{\kappa_t}\left[\delta_z(x^i) - p_{0 \mid t}(x^i \mid x) \right]\] <p>which will be used for corrector sampling during the generating/inferencing process.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">unsqueeze_to_match</span><span class="p">(</span><span class="n">source</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">how</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">suffix</span><span class="sh">"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Unsqueeze the source tensor to match the dimensionality of the target tensor.

    Args:
        source (Tensor): The source tensor to be unsqueezed.
        target (Tensor): The target tensor to match the dimensionality of.
        how (str, optional): Whether to unsqueeze the source tensor at the beginning
            (</span><span class="sh">"</span><span class="s">prefix</span><span class="sh">"</span><span class="s">) or end (</span><span class="sh">"</span><span class="s">suffix</span><span class="sh">"</span><span class="s">). Defaults to </span><span class="sh">"</span><span class="s">suffix</span><span class="sh">"</span><span class="s">.

    Returns:
        Tensor: The unsqueezed source tensor.
    </span><span class="sh">"""</span>
    <span class="nf">assert </span><span class="p">(</span>
        <span class="n">how</span> <span class="o">==</span> <span class="sh">"</span><span class="s">prefix</span><span class="sh">"</span> <span class="ow">or</span> <span class="n">how</span> <span class="o">==</span> <span class="sh">"</span><span class="s">suffix</span><span class="sh">"</span>
    <span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">how</span><span class="si">}</span><span class="s"> is not supported, only </span><span class="sh">'</span><span class="s">prefix</span><span class="sh">'</span><span class="s"> and </span><span class="sh">'</span><span class="s">suffix</span><span class="sh">'</span><span class="s"> are supported.</span><span class="sh">"</span>

    <span class="n">dim_diff</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="nf">dim</span><span class="p">()</span> <span class="o">-</span> <span class="n">source</span><span class="p">.</span><span class="nf">dim</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">dim_diff</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">how</span> <span class="o">==</span> <span class="sh">"</span><span class="s">prefix</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">how</span> <span class="o">==</span> <span class="sh">"</span><span class="s">suffix</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">source</span>



<span class="k">def</span> <span class="nf">expand_tensor_like</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">expand_to</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">`input_tensor` is a 1d vector of length equal to the batch size of `expand_to`,
    expand `input_tensor` to have the same shape as `expand_to` along all remaining dimensions.

    Args:
        input_tensor (Tensor): (batch_size,).
        expand_to (Tensor): (batch_size, ...).

    Returns:
        Tensor: (batch_size, ...).
    </span><span class="sh">"""</span>
    <span class="k">assert</span> <span class="n">input_tensor</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">Input tensor must be a 1d vector.</span><span class="sh">"</span>
    <span class="nf">assert </span><span class="p">(</span>
        <span class="n">input_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">expand_to</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="s">The first (batch_size) dimension must match. Got shape </span><span class="si">{</span><span class="n">input_tensor</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s"> and </span><span class="si">{</span><span class="n">expand_to</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">.</span><span class="sh">"</span>

    <span class="n">dim_diff</span> <span class="o">=</span> <span class="n">expand_to</span><span class="p">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="n">input_tensor</span><span class="p">.</span><span class="n">ndim</span>

    <span class="n">t_expanded</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="n">t_expanded</span> <span class="o">=</span> <span class="n">t_expanded</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim_diff</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">t_expanded</span><span class="p">.</span><span class="nf">expand_as</span><span class="p">(</span><span class="n">expand_to</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">PathSample</span><span class="p">:</span> 
    <span class="sh">'''</span><span class="s">Sample of conditional probability path</span><span class="sh">'''</span>

    <span class="n">x_1</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">x_0</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">dx_t</span><span class="p">:</span> <span class="n">Tensor</span>
        

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DiscretePathSample</span><span class="p">:</span> 
    <span class="sh">'''</span><span class="s">Sample of conditional discrete probability path</span><span class="sh">'''</span>
    
    <span class="n">x_1</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">x_0</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span>
    <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span>
        
        

<span class="k">class</span> <span class="nc">ProbPath</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">Probability Path Base Class</span><span class="sh">'''</span>
    
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_0</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PathSample</span><span class="p">:</span> 
        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">assert_sample_shape</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_0</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span> 
        <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x_1</span><span class="p">.</span><span class="n">shape</span>
        
        
<span class="c1"># mixture discrete path
</span><span class="k">class</span> <span class="nc">MixtureDiscreteProbPath</span><span class="p">(</span><span class="n">ProbPath</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">Mixture Discrete Probability Path</span><span class="sh">'''</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">:</span> <span class="n">Scheduler</span><span class="p">):</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">scheduler</span>
        
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_0</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DiscretePathSample</span><span class="p">:</span> 
        <span class="n">self</span><span class="p">.</span><span class="nf">assert_sample_shape</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        
        <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">scheduler</span><span class="p">(</span><span class="n">t</span><span class="p">).</span><span class="n">sigma_t</span>
        <span class="n">sigma_t</span> <span class="o">=</span> <span class="nf">expand_tensor_like</span><span class="p">(</span><span class="n">sigma_t</span><span class="p">,</span> <span class="n">x_1</span><span class="p">)</span>
        
        <span class="c1"># sigma_t determines the probability to stay at source
</span>        <span class="c1"># with probability of 1 - sigma_t it flips to target / data
</span>        <span class="n">source_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x_1</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">sigma_t</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">source_indices</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="nc">DiscretePathSample</span><span class="p">(</span><span class="n">x_1</span><span class="o">=</span><span class="n">x_1</span><span class="p">,</span> <span class="n">x_0</span><span class="o">=</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">posterior_to_velocity</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">posterior_logits</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span> 

        <span class="c1"># this is p_{1|t}(x|z)
</span>        <span class="n">posterior</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">posterior_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">vocabulary_size</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># this is p_t(x|z)
</span>        <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">vocabulary_size</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="nf">unsqueeze_to_match</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">x_t</span><span class="p">)</span>
        
        <span class="n">scheduler_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">scheduler</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="n">kappa_t</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">alpha_t</span>
        <span class="n">d_kappa_t</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">d_alpha_t</span>
        
        <span class="nf">return </span><span class="p">(</span><span class="n">d_kappa_t</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">kappa_t</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">posterior</span> <span class="o">-</span> <span class="n">x_t</span><span class="p">)</span>
</code></pre></div></div> <h3 id="13-training-losses">1.3 Training Losses</h3> <p>For training the probability denoiser, i.e. training a model that reproduces \(p_{1 \mid t}(x^i \mid z)\), the loss takes the form:</p> \[\mathcal{L}(\theta) = -\sum_i \textbf{E}_{t, (X_0, X_1), X_t}\left[\log{p_{1 \mid t}(X_1^i \mid X_t)} \right]\] <p>This is essentially the cross entropy loss. The model is trained to predict the signal sequence \(X_1\) given some noised sequence of \(X_t\). In analogy to image, this is predicting the noise-less image \(X_1\) given some noised images \(X_t\) instead of predicting the flow vector field \(u_t(X_t)\)</p> <p>Alternatively, we can use generalized KL loss, which takes the form:</p> \[\mathcal{L}(\theta) = -\sum_i \textbf{E}_{t, (X_0, X_1), X_t}\frac{\dot{\kappa_t}}{1-\kappa_t}\left[(\delta_{x_1}(x_t^i) - 1)\log{p_{1 \mid t}(x_1^i \mid x_t)} + \delta_{x_1}(x_t^i) - p_{1 \mid t}(x_1^i \mid x_t) \right]\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MixturePathGeneralizedKL</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">modules</span><span class="p">.</span><span class="n">loss</span><span class="p">.</span><span class="n">_Loss</span><span class="p">):</span>
    <span class="sa">r</span><span class="sh">"""</span><span class="s">A generalized KL loss for discrete flow matching.
    A class that measures the generalized KL of a discrete flow model :math:`p_{1|t}` w.r.t. a probability path given by ``path``. Note: this class is assuming that the model is trained on the same path.

    For a model trained on a space :math:`\mathcal{S} = \mathcal{T}^d`, :math:`\mathcal{T} = [K] = \set{1,2,\ldots,K}`, the loss is given by

    .. math::
            \ell_i(x_1, x_t, t) = -\frac{\dot{\kappa}_t}{1-\kappa_t} \biggr[  p_{1|t}(x_t^i|x_t) -\delta_{x^i_1}(x_t^i) + (1-\delta_{x^i_1}(x_t^i))\left(\log p_{1|t}(x_1^i|x_t)\right)\biggr],

    where :math:`\kappa_t` is the scheduler associated with ``path``.

    Args:
        path (MixtureDiscreteProbPath): Probability path (x-prediction training).
        reduction (str, optional): Specify the reduction to apply to the output ``</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="s">`` | ``</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="s">`` | ``</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="s">``. ``</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="s">``: no reduction is applied to the output, ``</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="s">``: the output is reduced by mean over sequence elements, ``</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="s">``: the output is reduced by sum over sequence elements. Defaults to </span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="s">.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">MixtureDiscreteProbPath</span><span class="p">,</span> <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">mean</span><span class="sh">"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">reduction</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">logits</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sh">"""</span><span class="s">Evaluates the generalized KL loss.

        Args:
            logits (Tensor): posterior model output (i.e., softmax(``logits``) :math:`=p_{1|t}(x|x_t)`), shape (batch, d, K).
            x_1 (Tensor): target data point :math:`x_1 \sim q`, shape (batch, d).
            x_t (Tensor): conditional sample at :math:`x_t \sim p_t(\cdot|x_1)`, shape (batch, d).
            t (Tensor): times in :math:`[0,1]`, shape (batch).

        Raises:
            ValueError: reduction value must be one of ``</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="s">`` | ``</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="s">`` | ``</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="s">``.

        Returns:
            Tensor: Generalized KL loss.
        </span><span class="sh">"""</span>
        <span class="n">x_1_shape</span> <span class="o">=</span> <span class="n">x_1</span><span class="p">.</span><span class="n">shape</span>

        <span class="c1"># extract x_1 value of log(p_{1|t}(x|x_t)).
</span>        <span class="n">log_p_1t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_p_1t_x1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="n">log_p_1t</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">x_1</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">log_p_1t_x1</span> <span class="o">=</span> <span class="n">log_p_1t_x1</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">*</span><span class="n">x_1_shape</span><span class="p">)</span>

        <span class="c1"># extract x_t value of p_{1|t}(x|x_t).
</span>        <span class="n">p_1t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">log_p_1t</span><span class="p">)</span>
        <span class="n">p_1t_xt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="n">p_1t</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">x_t</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">p_1t_xt</span> <span class="o">=</span> <span class="n">p_1t_xt</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">*</span><span class="n">x_1_shape</span><span class="p">)</span>

        <span class="n">scheduler_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">scheduler</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

        <span class="n">jump_coefficient</span> <span class="o">=</span> <span class="p">(</span><span class="n">scheduler_output</span><span class="p">.</span><span class="n">d_alpha_t</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">alpha_t</span><span class="p">))[(...,)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_1</span><span class="p">.</span><span class="nf">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">jump_coefficient</span> <span class="o">=</span> <span class="n">jump_coefficient</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">x_1_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">delta_x1_xt</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_t</span> <span class="o">==</span> <span class="n">x_1</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">log_p_1t</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">jump_coefficient</span> <span class="o">*</span> <span class="p">(</span><span class="n">p_1t_xt</span> <span class="o">-</span> <span class="n">delta_x1_xt</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delta_x1_xt</span><span class="p">)</span> <span class="o">*</span> <span class="n">log_p_1t_x1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="sh">"</span><span class="s">mean</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="sh">"</span><span class="s">sum</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">==</span> <span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">loss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">reduction</span><span class="si">}</span><span class="s"> is not a valid value for reduction</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="14-odesde-solvers">1.4 ODE/SDE Solvers</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">probs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sh">"""</span><span class="s">Categorical sampler according to weights in the last dimension of ``probs`` using :func:`torch.multinomial`.

    Args:
        probs (Tensor): probabilities.

    Returns:
        Tensor: Samples.
    </span><span class="sh">"""</span>

    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="o">*</span><span class="n">probs</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">get_nearest_times</span><span class="p">(</span><span class="n">time_grid</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t_discretization</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cdist</span><span class="p">(</span>
        <span class="n">time_grid</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">t_discretization</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="sh">"</span><span class="s">donot_use_mm_for_euclid_dist</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">nearest_indices</span> <span class="o">=</span> <span class="n">distances</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">t_discretization</span><span class="p">[</span><span class="n">nearest_indices</span><span class="p">]</span>


<span class="c1"># model wrapper for the solvers
</span><span class="k">class</span> <span class="nc">ModelWrapper</span><span class="p">(</span><span class="n">ABC</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This class is used to wrap around another model, adding custom forward pass logic.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">extras</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="o">**</span><span class="n">extras</span><span class="p">)</span>
    
    

<span class="k">class</span> <span class="nc">Solver</span><span class="p">(</span><span class="n">ABC</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Abstract base class for solvers.</span><span class="sh">"""</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_0</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">pass</span>

        
<span class="k">class</span> <span class="nc">MixtureDiscreteSolver</span><span class="p">(</span><span class="n">Solver</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">ModelWrapper</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="n">MixtureDiscreteProbPath</span><span class="p">,</span>
        <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">source_distribution_p</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">solver_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span>
    <span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span> <span class="o">=</span> <span class="n">vocabulary_size</span>

        <span class="k">if</span> <span class="n">source_distribution_p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">source_distribution_p</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">(</span>
                <span class="p">[</span><span class="n">vocabulary_size</span><span class="p">]</span>
            <span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Source distribution p dimension must match the vocabulary size </span><span class="si">{</span><span class="n">vocabulary_size</span><span class="si">}</span><span class="s">. Got </span><span class="si">{</span><span class="n">source_distribution_p</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">.</span><span class="sh">"</span>

        <span class="n">self</span><span class="p">.</span><span class="n">source_distribution_p</span> <span class="o">=</span> <span class="n">source_distribution_p</span>
        
        <span class="k">assert</span> <span class="n">solver_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">solver_type</span> <span class="o">=</span> <span class="n">solver_type</span>

    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">x_init</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">step_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">div_free</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">dtype_categorical</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">time_grid</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span>
        <span class="n">return_intermediates</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">model_extras</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">div_free</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="nf">assert </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">source_distribution_p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">),</span> <span class="sh">"</span><span class="s">Source distribution p must be specified in order to add a divergence-free term to the probability velocity.</span><span class="sh">"</span>

        <span class="c1"># Initialize the current state `x_t` with the initial state `X_0`.
</span>        <span class="n">time_grid</span> <span class="o">=</span> <span class="n">time_grid</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">x_init</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">step_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># If step_size is None then set the t discretization to time_grid.
</span>            <span class="n">t_discretization</span> <span class="o">=</span> <span class="n">time_grid</span>
            <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">time_grid</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If step_size is float then t discretization is uniform with step size set by step_size.
</span>            <span class="n">t_init</span> <span class="o">=</span> <span class="n">time_grid</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">t_final</span> <span class="o">=</span> <span class="n">time_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
            <span class="nf">assert </span><span class="p">(</span><span class="n">t_final</span> <span class="o">-</span> <span class="n">t_init</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">step_size</span><span class="p">,</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Time interval [time_grid[0], time_grid[-1]] must be larger than step_size. Got a time interval [</span><span class="si">{</span><span class="n">t_init</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">t_final</span><span class="si">}</span><span class="s">] and step_size </span><span class="si">{</span><span class="n">step_size</span><span class="si">}</span><span class="s">.</span><span class="sh">"</span>

            <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">ceil</span><span class="p">((</span><span class="n">t_final</span> <span class="o">-</span> <span class="n">t_init</span><span class="p">)</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
            <span class="n">t_discretization</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">t_init</span> <span class="o">+</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">t_final</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x_init</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">return_intermediates</span><span class="p">:</span>
                <span class="c1"># get order of intermediate steps:
</span>                <span class="n">order</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">time_grid</span><span class="p">)</span>
                <span class="c1"># Compute intermediate steps to return via nearest points in t_discretization to time_grid.
</span>                <span class="n">time_grid</span> <span class="o">=</span> <span class="nf">get_nearest_times</span><span class="p">(</span><span class="n">time_grid</span><span class="o">=</span><span class="n">time_grid</span><span class="p">,</span> <span class="n">t_discretization</span><span class="o">=</span><span class="n">t_discretization</span><span class="p">)</span>

        <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_init</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
        <span class="n">steps_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">return_intermediates</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_init</span><span class="p">.</span><span class="nf">clone</span><span class="p">()]</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">t_final</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">NFE: </span><span class="si">{</span><span class="n">steps_counter</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="nf">nullcontext</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">t_discretization</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">t_discretization</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_discretization</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

                <span class="c1"># Sample x_1 ~ p_1|t( \cdot |x_t)
</span>                <span class="n">p_1t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="o">**</span><span class="n">model_extras</span><span class="p">)</span>
                <span class="n">x_1</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">p_1t</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>

                <span class="c1"># Checks if final step
</span>                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">n_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Compute u_t(x|x_t,x_1)
</span>                    <span class="n">scheduler_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">scheduler</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>

                    <span class="n">k_t</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">alpha_t</span>
                    <span class="n">d_k_t</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">d_alpha_t</span>

                    <span class="n">delta_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">k_t</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="n">d_k_t</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta_1</span>

                    <span class="c1"># Add divergence-free part
</span>                    <span class="n">div_free_t</span> <span class="o">=</span> <span class="nf">div_free</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">if</span> <span class="nf">callable</span><span class="p">(</span><span class="n">div_free</span><span class="p">)</span> <span class="k">else</span> <span class="n">div_free</span>

                    <span class="k">if</span> <span class="n">div_free_t</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">p_0</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">source_distribution_p</span><span class="p">[(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">*</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">dim</span><span class="p">()]</span>
                        <span class="n">u</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">div_free_t</span> <span class="o">*</span> <span class="n">d_k_t</span> <span class="o">/</span> <span class="p">(</span><span class="n">k_t</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_t</span><span class="p">))</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">p_0</span> <span class="o">+</span> <span class="n">k_t</span> <span class="o">*</span> <span class="n">delta_1</span><span class="p">)</span>

                    <span class="c1"># Set u_t(x_t|x_t,x_1) = 0
</span>                    <span class="n">delta_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">delta_t</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">u</span><span class="p">)</span>

                    <span class="c1"># Sample x_t ~ u_t( \cdot |x_t,x_1) -- predictor
</span>                    <span class="n">intensity</span> <span class="o">=</span> <span class="n">u</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Assuming u_t(xt|xt,x1) := 0
</span>                    <span class="n">mask_jump</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x_t</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">h</span> <span class="o">*</span> <span class="n">intensity</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">mask_jump</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">x_t</span><span class="p">[</span><span class="n">mask_jump</span><span class="p">]</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">mask_jump</span><span class="p">].</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>
                        
                    <span class="c1">#### the following is only for Heun method
</span>                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">solver_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">:</span>
                        <span class="n">x_th</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
                        <span class="n">th</span> <span class="o">=</span> <span class="n">t</span> <span class="o">+</span> <span class="n">h</span>
                        <span class="n">p_1th</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_th</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">th</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">x_th</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="o">**</span><span class="n">model_extras</span><span class="p">)</span>
                        <span class="n">x_1th</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">p_1th</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>

                        <span class="n">scheduler_output_th</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">scheduler</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">th</span><span class="p">)</span>

                        <span class="n">k_th</span> <span class="o">=</span> <span class="n">scheduler_output_th</span><span class="p">.</span><span class="n">alpha_t</span>
                        <span class="n">d_k_th</span> <span class="o">=</span> <span class="n">scheduler_output_th</span><span class="p">.</span><span class="n">d_alpha_t</span>

                        <span class="n">delta_1th</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_1th</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">k_th</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>
                        <span class="n">u_th</span> <span class="o">=</span> <span class="n">d_k_th</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_th</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta_1th</span>

                        <span class="c1"># Add divergence-free part
</span>                        <span class="n">div_free_th</span> <span class="o">=</span> <span class="nf">div_free</span><span class="p">(</span><span class="n">th</span><span class="p">)</span> <span class="k">if</span> <span class="nf">callable</span><span class="p">(</span><span class="n">div_free</span><span class="p">)</span> <span class="k">else</span> <span class="n">div_free</span>

                        <span class="k">if</span> <span class="n">div_free_th</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">p_0</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">source_distribution_p</span><span class="p">[(</span><span class="bp">None</span><span class="p">,)</span> <span class="o">*</span> <span class="n">x_th</span><span class="p">.</span><span class="nf">dim</span><span class="p">()]</span>
                            <span class="n">u_th</span> <span class="o">=</span> <span class="n">u_th</span> <span class="o">+</span> <span class="n">div_free_th</span> <span class="o">*</span> <span class="n">d_k_th</span> <span class="o">/</span> <span class="p">(</span><span class="n">k_th</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_th</span><span class="p">))</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_th</span><span class="p">)</span> <span class="o">*</span> <span class="n">p_0</span> <span class="o">+</span> <span class="n">k_th</span> <span class="o">*</span> <span class="n">delta_1th</span><span class="p">)</span>

                        <span class="c1"># Set u_t(x_t|x_t,x_1) = 0
</span>                        <span class="n">delta_th</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_th</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                        <span class="n">u_th</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">delta_th</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">u_th</span><span class="p">),</span> <span class="n">u_th</span><span class="p">)</span>

                        <span class="c1"># combine u and u_{t+h} -- corrector
</span>                        <span class="n">u</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="n">u_th</span><span class="p">)</span>
                        <span class="n">intensity</span> <span class="o">=</span> <span class="n">u</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                        <span class="n">mask_jump</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x_t</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">h</span> <span class="o">*</span> <span class="n">intensity</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">mask_jump</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">x_t</span><span class="p">[</span><span class="n">mask_jump</span><span class="p">]</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">mask_jump</span><span class="p">].</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>
                
                <span class="n">steps_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">+</span> <span class="n">h</span>

                <span class="k">if</span> <span class="n">return_intermediates</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">time_grid</span><span class="p">):</span>
                    <span class="n">res</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="nf">clone</span><span class="p">())</span>

                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">ctx</span><span class="p">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
                    <span class="n">ctx</span><span class="p">.</span><span class="nf">refresh</span><span class="p">()</span>
                    <span class="n">ctx</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">NFE: </span><span class="si">{</span><span class="n">steps_counter</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_intermediates</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">step_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="n">order</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x_t</span>
        
        
<span class="k">class</span> <span class="nc">SimpleSolver</span><span class="p">(</span><span class="n">Solver</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">ModelWrapper</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="n">MixtureDiscreteProbPath</span><span class="p">,</span>
        <span class="n">vocabulary_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> 
        <span class="n">solver_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">stochastic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="n">source_distribution</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span>
    <span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span> <span class="o">=</span> <span class="n">vocabulary_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">solver_type</span> <span class="o">=</span> <span class="n">solver_type</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stochastic</span> <span class="o">=</span> <span class="n">stochastic</span>
        <span class="n">self</span><span class="p">.</span><span class="n">source_distribution</span> <span class="o">=</span> <span class="n">source_distribution</span>
        
    <span class="nd">@torch.no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">x_init</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">step_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">dtype_categorical</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">time_grid</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]),</span>
        <span class="n">return_intermediates</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">model_extras</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        
        <span class="c1"># Initialize the current state `x_t` with the initial state `X_0`.
</span>        <span class="n">time_grid</span> <span class="o">=</span> <span class="n">time_grid</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">x_init</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">step_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># If step_size is None then set the t discretization to time_grid.
</span>            <span class="n">t_discretization</span> <span class="o">=</span> <span class="n">time_grid</span>
            <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">time_grid</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If step_size is float then t discretization is uniform with step size set by step_size.
</span>            <span class="n">t_init</span> <span class="o">=</span> <span class="n">time_grid</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">t_final</span> <span class="o">=</span> <span class="n">time_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span>
            <span class="nf">assert </span><span class="p">(</span><span class="n">t_final</span> <span class="o">-</span> <span class="n">t_init</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">step_size</span><span class="p">,</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Time interval [time_grid[0], time_grid[-1]] must be larger than step_size. Got a time interval [</span><span class="si">{</span><span class="n">t_init</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">t_final</span><span class="si">}</span><span class="s">] and step_size </span><span class="si">{</span><span class="n">step_size</span><span class="si">}</span><span class="s">.</span><span class="sh">"</span>

            <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">ceil</span><span class="p">((</span><span class="n">t_final</span> <span class="o">-</span> <span class="n">t_init</span><span class="p">)</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
            <span class="n">t_discretization</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">t_init</span> <span class="o">+</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">t_final</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x_init</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">return_intermediates</span><span class="p">:</span>
                <span class="c1"># get order of intermediate steps:
</span>                <span class="n">order</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">time_grid</span><span class="p">)</span>
                <span class="c1"># Compute intermediate steps to return via nearest points in t_discretization to time_grid.
</span>                <span class="n">time_grid</span> <span class="o">=</span> <span class="nf">get_nearest_times</span><span class="p">(</span><span class="n">time_grid</span><span class="o">=</span><span class="n">time_grid</span><span class="p">,</span> <span class="n">t_discretization</span><span class="o">=</span><span class="n">t_discretization</span><span class="p">)</span>

        <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_init</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
        <span class="n">steps_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">return_intermediates</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_init</span><span class="p">.</span><span class="nf">clone</span><span class="p">()]</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">t_final</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">NFE: </span><span class="si">{</span><span class="n">steps_counter</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ctx</span> <span class="o">=</span> <span class="nf">nullcontext</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">ctx</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">t_discretization</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">t_discretization</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_discretization</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

                <span class="c1"># Sample x_1 ~ p_1|t( \cdot |x_t)
</span>                <span class="n">p_1t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="o">**</span><span class="n">model_extras</span><span class="p">)</span>
                <span class="n">x_1</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">p_1t</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>

                <span class="c1"># Checks if final step
</span>                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">n_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span> <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_1</span>
                <span class="k">else</span><span class="p">:</span>
                    
                    <span class="c1"># kappa
</span>                    <span class="n">scheduler_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">scheduler</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
                    <span class="n">k_t</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">alpha_t</span>
                    <span class="n">d_k_t</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">d_alpha_t</span>
                    
                    <span class="c1"># PMFs
</span>                    <span class="n">p_1t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">p_1t</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">delta_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                    <span class="n">delta_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                    
                    <span class="c1"># velocity
</span>                    <span class="n">u_t</span> <span class="o">=</span> <span class="n">d_k_t</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta_1</span> <span class="c1">#+ s_t * delta_n
</span>                    
                    <span class="c1"># Euler point
</span>                    <span class="n">p_t</span> <span class="o">=</span> <span class="n">delta_t</span> <span class="o">+</span> <span class="n">h</span> <span class="o">*</span> <span class="n">u_t</span>
                    
                    <span class="c1">###  Start Heun
</span>                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">solver_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">:</span> 
                        <span class="n">x_th</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">p_t</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>
                    
                        <span class="n">th</span> <span class="o">=</span> <span class="n">t</span> <span class="o">+</span> <span class="n">h</span>
                        <span class="n">p_1th</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_th</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">th</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="o">**</span><span class="n">model_extras</span><span class="p">)</span>
                        <span class="n">x_1th</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">p_1th</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>

                        <span class="c1"># kappa
</span>                        <span class="n">scheduler_output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">scheduler</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">th</span><span class="p">)</span>
                        <span class="n">k_th</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">alpha_t</span>
                        <span class="n">d_k_th</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">d_alpha_t</span>

                        <span class="c1"># PMFs
</span>                        <span class="n">p_1t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">p_1th</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                        <span class="n">delta_th</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_th</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                        <span class="n">delta_1th</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_1th</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                        <span class="n">u_th</span> <span class="o">=</span> <span class="n">d_k_th</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">k_th</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta_1th</span>

                        <span class="c1"># Heun
</span>                        <span class="n">p_t</span> <span class="o">=</span> <span class="n">delta_t</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">h</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_t</span> <span class="o">+</span> <span class="n">u_th</span><span class="p">)</span>
                    
                    <span class="c1">### Start stochastic
</span>                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">stochastic</span><span class="p">:</span> 
                        <span class="c1"># noise PMFs with uniform
</span>                        <span class="n">s_t</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="p">.</span><span class="n">sigma_t</span>
                        
                        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">:</span>
                            <span class="n">x_n</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint_like</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">:</span> 
                            <span class="n">x_n</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>
                        
                        <span class="n">delta_n</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">x_n</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">vocabulary_size</span><span class="p">)</span>
                        <span class="n">p_t</span> <span class="o">+=</span> <span class="n">delta_n</span> <span class="o">*</span> <span class="n">h</span> <span class="o">*</span> <span class="n">s_t</span> <span class="o">**</span> <span class="mf">0.5</span>
                        
                    <span class="c1"># Sample
</span>                    <span class="n">x_t</span> <span class="o">=</span> <span class="nf">categorical</span><span class="p">(</span><span class="n">p_t</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype_categorical</span><span class="p">))</span>
                
                <span class="n">steps_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">+</span> <span class="n">h</span>

                <span class="k">if</span> <span class="n">return_intermediates</span> <span class="ow">and</span> <span class="p">(</span><span class="n">t</span> <span class="ow">in</span> <span class="n">time_grid</span><span class="p">):</span>
                    <span class="n">res</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="nf">clone</span><span class="p">())</span>

                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="n">ctx</span><span class="p">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
                    <span class="n">ctx</span><span class="p">.</span><span class="nf">refresh</span><span class="p">()</span>
                    <span class="n">ctx</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">NFE: </span><span class="si">{</span><span class="n">steps_counter</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">return_intermediates</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">step_size</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="n">order</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x_t</span>
        
</code></pre></div></div> <h2 id="2-training-pipeline">2. Training Pipeline</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_discrete_flow_matching_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">x_1_gen_fn</span><span class="p">,</span> <span class="n">loss_type</span><span class="o">=</span><span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">,</span> <span class="n">source_distribution</span><span class="o">=</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="n">model_prefix</span><span class="o">=</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">,</span> 
                                       <span class="n">vocab_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">):</span> 
    
    <span class="k">assert</span> <span class="n">loss_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">source_distribution</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">prefix</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">model_prefix</span><span class="si">}</span><span class="s"> training </span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s"> loss with </span><span class="si">{</span><span class="n">source_distribution</span><span class="si">}</span><span class="s"> distribution</span><span class="sh">'</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">model_prefix</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">source_distribution</span><span class="si">}</span><span class="s">_it_</span><span class="si">{</span><span class="n">iterations</span><span class="si">:</span><span class="mi">06</span><span class="n">d</span><span class="si">}</span><span class="sh">'</span>
    
    <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">added_token</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">mask_token</span> <span class="o">=</span> <span class="n">vocab_size</span>  <span class="c1"># tokens starting from zero
</span>        <span class="n">added_token</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="c1"># additional mask token
</span>    <span class="n">vocab_size</span> <span class="o">+=</span> <span class="n">added_token</span>

    <span class="c1"># model
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># optimizer
</span>    <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    
    <span class="c1"># loss function
</span>    <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">:</span> 
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="nc">MixturePathGeneralizedKL</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">:</span> 
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
        
    <span class="c1"># training loop
</span>    <span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
        
        <span class="c1"># sample data x_1
</span>        <span class="n">x_1</span> <span class="o">=</span> <span class="nf">x_1_gen_fn</span><span class="p">(</span><span class="n">n_grid_points</span><span class="o">=</span><span class="n">vocab_size</span> <span class="o">-</span> <span class="n">added_token</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># sample data
</span>        
        <span class="c1"># sample noise x_0
</span>        <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span> <span class="o">+</span> <span class="n">mask_token</span>

        <span class="c1"># sample time 
</span>        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span>

        <span class="c1"># sample probability path, in this case, (X_0,X_1) ~ pi(X_0,X_1) = p_0(X_0)p_1(X_1)
</span>        <span class="n">path_sample</span> <span class="o">=</span> <span class="n">path</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="o">=</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="o">=</span><span class="n">x_1</span><span class="p">)</span>

        <span class="c1"># The model predicts the logits for x_1 given x_t and t
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">path_sample</span><span class="p">.</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">path_sample</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>
        
        <span class="c1"># discrete flow matching generalized KL loss or Cross Entropy loss
</span>        <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">:</span> 
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">x_1</span><span class="o">=</span><span class="n">x_1</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">path_sample</span><span class="p">.</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">path_sample</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">:</span> 
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="sh">'</span><span class="s">b n d -&gt; (b n) d</span><span class="sh">'</span><span class="p">),</span> 
                           <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="sh">'</span><span class="s">b n -&gt; (b n)</span><span class="sh">'</span><span class="p">))</span>

        <span class="c1"># optimizer step
</span>        <span class="n">optim</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optim</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="c1"># loss logging
</span>        <span class="n">losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
        <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s">, Loss = </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="mf">2.3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># checkpoint
</span>    <span class="n">savepath</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">SAVE_PATH</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s">.pth</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">model</span><span class="sh">'</span><span class="p">:</span> <span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> 
                  <span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">losses</span><span class="p">)}</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">savepath</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">losses</span>
    
</code></pre></div></div> <h2 id="3-elbo-estimates">3. ELBO Estimates</h2> <p>The generalized KL divergence is also used to compute ELBO estimates:</p> \[\log{p_1(x_1)} \geq -\sum_i \textbf{E}_{t, (X_0, X_1), X_t}\frac{\dot{\kappa_t}}{1-\kappa_t}\left[(\delta_{x_1}(x_t^i) - 1)\log{p_{1 \mid t}(x_1^i \mid x_t)} + \delta_{x_1}(x_t^i) - p_{1 \mid t}(x_1^i \mid x_t) \right]\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># elbo estimate given any x_1 in the domain but not necessarity in the data distribution
</span><span class="k">def</span> <span class="nf">elbo_estimate</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">source_distribution</span><span class="p">,</span> <span class="n">n_discretization</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span> 
    
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">x_1</span><span class="p">.</span><span class="n">device</span> <span class="o">==</span> <span class="nf">next</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">x_1</span><span class="p">.</span><span class="n">device</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">generalized_kl_fn</span> <span class="o">=</span> <span class="nc">MixturePathGeneralizedKL</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">discretization</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_discretization</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="n">elbo</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)):</span>
            <span class="c1"># Lower variance estimator for time discretization
</span>            <span class="n">discretization</span> <span class="o">=</span> <span class="n">discretization</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">discretization</span> <span class="o">=</span> <span class="n">discretization</span> <span class="o">%</span> <span class="mi">1</span>
            <span class="n">discretization</span> <span class="o">=</span> <span class="n">discretization</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="mf">1e-4</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">discretization</span><span class="p">:</span>
                <span class="c1"># sample X_t ~ p_t(\cdot| x_1)
</span>                <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">:</span>
                    <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">:</span>
                    <span class="n">x_0</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="n">vocab_size</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>
                <span class="n">x_t</span> <span class="o">=</span> <span class="n">path</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="o">=</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="o">=</span><span class="n">x_1</span><span class="p">).</span><span class="n">x_t</span>

                <span class="n">logits</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

                <span class="c1"># compute ELBO
</span>                <span class="n">elbo</span> <span class="o">-=</span> <span class="nf">generalized_kl_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">x_1</span><span class="o">=</span><span class="n">x_1</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">elbo</span> <span class="o">/=</span> <span class="n">n_discretization</span> <span class="o">*</span> <span class="n">n_samples</span>

    <span class="c1"># Remember that log_q(x_1) &gt;= ELBO(x_1)
</span>    <span class="n">probability_lower_bound</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">elbo</span><span class="p">)</span>
    <span class="n">log_prob_lower_bound_per_dim</span> <span class="o">=</span> <span class="n">elbo</span> <span class="o">/</span> <span class="n">dim</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="sh">'</span><span class="s">elbo</span><span class="sh">'</span><span class="p">:</span> <span class="n">probability_lower_bound</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">logp_per_dim</span><span class="sh">'</span><span class="p">:</span> <span class="n">log_prob_lower_bound_per_dim</span><span class="p">}</span>
</code></pre></div></div> <h1 id="2d-case">2D Case</h1> <p>Here, we generate a 2D checkerboard data as \(x_1\) and train discrete flow matching model to replicate this discrete distributions.</p> <p>The model is a simple MLP predicting the logits for each position.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">inf_train_gen_2d</span><span class="p">(</span><span class="n">n_grid_points</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">n_grid_points</span> <span class="o">%</span> <span class="mi">4</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">number of grid points has to be divisible by 4</span><span class="sh">"</span>
    
    <span class="n">n_grid_points</span> <span class="o">=</span> <span class="n">n_grid_points</span> <span class="o">//</span> <span class="mi">4</span>
    
    <span class="n">x1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">n_grid_points</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">samples_x2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">n_grid_points</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
    <span class="n">x2</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">samples_x2</span>
        <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_grid_points</span>
        <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_grid_points</span>
        <span class="o">+</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">x1</span> <span class="o">/</span> <span class="n">n_grid_points</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_grid_points</span>
    <span class="p">)</span>
    
    <span class="n">x_end</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">x1</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">x2</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x_end</span><span class="p">.</span><span class="nf">long</span><span class="p">()</span>

<span class="c1"># Activation class
</span><span class="k">class</span> <span class="nc">Swish</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span> 
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>

<span class="c1"># Model class
</span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">time_dim</span> <span class="o">=</span> <span class="n">time_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>

        <span class="n">self</span><span class="p">.</span><span class="n">time_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="nc">Swish</span><span class="p">(),</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">length</span> <span class="o">+</span> <span class="n">time_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="nc">Swish</span><span class="p">(),</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="nc">Swish</span><span class="p">(),</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="nc">Swish</span><span class="p">(),</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">input_dim</span> <span class="o">*</span> <span class="n">length</span><span class="p">),</span>
        <span class="p">)</span>
        

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">time_embedding</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">token_embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span>
        
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">main</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">input_dim</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">h</span>
    
    
<span class="k">class</span> <span class="nc">WrappedModel</span><span class="p">(</span><span class="n">ModelWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">extras</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># hyperparams
</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">30000</span>

<span class="c1"># scheduler definition
</span><span class="n">scheduler</span> <span class="o">=</span> <span class="nc">PolynomialScheduler</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="nc">MixtureDiscreteProbPath</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">)</span>

<span class="c1"># do a sweep for 
# 1. source = ['uniform', 'mask']
# 2. loss = ['KL', 'CE']
# {model, losses, samples}
# samples are dict of different type
</span>
<span class="n">rlt_dct</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">source_distribution</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">]:</span>
    
    <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">loss_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">]:</span>
        <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
        
        <span class="n">input_dim</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="nf">train_discrete_flow_matching_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">inf_train_gen_2d</span><span class="p">,</span> 
                                                           <span class="n">loss_type</span><span class="o">=</span><span class="n">loss_type</span><span class="p">,</span> 
                                                           <span class="n">source_distribution</span><span class="o">=</span><span class="n">source_distribution</span><span class="p">,</span> 
                                                           <span class="n">model_prefix</span><span class="o">=</span><span class="sh">'</span><span class="s">twodim</span><span class="sh">'</span><span class="p">,</span> 
                                                           <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> 
                                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                                           <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> 
                                                           <span class="n">iterations</span><span class="o">=</span><span class="n">iterations</span><span class="p">,</span> 
                                                           <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> 
                                                           <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="sh">'</span><span class="s">model</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="sh">'</span><span class="s">losses</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
    
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># training a larger scoring model using the same scheduler: 
</span>
<span class="n">sc_hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">sc_iterations</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="n">scoring_model</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">sc_source_distribution</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">]:</span>
    
    <span class="n">sc_input_dim</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">sc_source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">sc_model</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="n">sc_input_dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="n">sc_hidden_dim</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">sc_model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">train_discrete_flow_matching_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">inf_train_gen_2d</span><span class="p">,</span> 
                                                      <span class="n">loss_type</span><span class="o">=</span><span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">,</span> 
                                                      <span class="n">source_distribution</span><span class="o">=</span><span class="n">sc_source_distribution</span><span class="p">,</span> 
                                                      <span class="n">model_prefix</span><span class="o">=</span><span class="sh">'</span><span class="s">score</span><span class="sh">'</span><span class="p">,</span> 
                                                      <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> 
                                                      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                                      <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> 
                                                      <span class="n">iterations</span><span class="o">=</span><span class="n">sc_iterations</span><span class="p">,</span> 
                                                      <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> 
                                                      <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">scoring_model</span><span class="p">[</span><span class="n">sc_source_distribution</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">sc_model</span><span class="p">)</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># sampling function
</span><span class="k">def</span> <span class="nf">sample_discrete_flow_matching_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> 
                                        <span class="n">source_distribution</span><span class="o">=</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="n">solver_type</span><span class="o">=</span><span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">nfe</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_plots</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
    
    <span class="k">assert</span> <span class="n">source_distribution</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">solver_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEuler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEulerStochastic</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeunStochastic</span><span class="sh">'</span><span class="p">]</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Sampling with </span><span class="si">{</span><span class="n">solver_type</span><span class="si">}</span><span class="s"> solver</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># infer device
</span>    <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
    
    <span class="c1"># model wrapper
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">wrapped_model</span> <span class="o">=</span> <span class="nc">WrappedModel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">solver_type</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">'</span><span class="s">Simple</span><span class="sh">'</span><span class="p">):</span> 
        <span class="n">solver</span> <span class="o">=</span> <span class="nc">SimpleSolver</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">wrapped_model</span><span class="p">,</span> 
                              <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> 
                              <span class="n">vocabulary_size</span><span class="o">=</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">),</span> 
                              <span class="n">solver_type</span><span class="o">=</span><span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span> <span class="k">if</span> <span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">solver_type</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">,</span> 
                              <span class="n">stochastic</span><span class="o">=</span><span class="sh">'</span><span class="s">Stochastic</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">solver_type</span><span class="p">,</span> 
                              <span class="n">source_distribution</span><span class="o">=</span><span class="n">source_distribution</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="n">solver</span> <span class="o">=</span> <span class="nc">MixtureDiscreteSolver</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">wrapped_model</span><span class="p">,</span> 
                                       <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> 
                                       <span class="n">vocabulary_size</span><span class="o">=</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">),</span> 
                                       <span class="n">solver_type</span><span class="o">=</span><span class="n">solver_type</span><span class="p">)</span>
    
    <span class="n">step_size</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">nfe</span>
    
    <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">:</span> 
        <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">:</span> 
        <span class="n">x_0</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="n">vocab_size</span><span class="p">).</span><span class="nf">long</span><span class="p">()</span>
    
    <span class="n">linspace_to_plot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">n_plots</span><span class="p">)</span>
    <span class="n">sol</span> <span class="o">=</span> <span class="n">solver</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">x_init</span><span class="o">=</span><span class="n">x_0</span><span class="p">,</span> 
                        <span class="n">step_size</span><span class="o">=</span><span class="n">step_size</span><span class="p">,</span> 
                        <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                        <span class="n">return_intermediates</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">time_grid</span><span class="o">=</span><span class="n">linspace_to_plot</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sol</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_2d_sol</span><span class="p">(</span><span class="n">sol</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span> 
    <span class="n">n_plots</span> <span class="o">=</span> <span class="n">sol</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">linspace_to_plot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">n_plots</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_plots</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">mask_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">]).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">linspace_to_plot</span><span class="p">):</span>
        
        <span class="n">sol_step</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">...]</span>
        <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">sol_step</span> <span class="o">=</span> <span class="n">sol_step</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">ne</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">sol_step</span><span class="p">),</span> <span class="n">mask_tensor</span><span class="p">).</span><span class="nf">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="p">...]</span>

        <span class="n">H</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">hist2d</span><span class="p">(</span><span class="n">sol_step</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sol_step</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>

        <span class="n">cmin</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">cmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">quantile</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">H</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mf">0.95</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">colors</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">hist2d</span><span class="p">(</span><span class="n">sol_step</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sol_step</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>

        <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">set_aspect</span><span class="p">(</span><span class="sh">'</span><span class="s">equal</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">t= </span><span class="si">{</span><span class="n">linspace_to_plot</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s"> t= </span><span class="si">{</span><span class="n">linspace_to_plot</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">for</span> <span class="n">source_distribution</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">loss_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">]:</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="sh">'</span><span class="s">model</span><span class="sh">'</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">solver_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEuler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEulerStochastic</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeunStochastic</span><span class="sh">'</span><span class="p">]:</span> 
            <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="n">solver_type</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">()</span>
            <span class="n">sol</span> <span class="o">=</span> <span class="nf">sample_discrete_flow_matching_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> 
                                                      <span class="n">source_distribution</span><span class="o">=</span><span class="n">source_distribution</span><span class="p">,</span> 
                                                      <span class="n">solver_type</span><span class="o">=</span><span class="n">solver_type</span><span class="p">,</span> 
                                                      <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            
            <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="n">solver_type</span><span class="p">][</span><span class="sh">'</span><span class="s">sample</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            
            <span class="c1"># randomly generate plots
</span>            <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">:</span> <span class="n">fig</span> <span class="o">=</span> <span class="nf">plot_2d_sol</span><span class="p">(</span><span class="n">sol</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">source_distribution</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">solver_type</span><span class="si">}</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/dfm/fig1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/dfm/fig1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/dfm/fig1-1400.webp"/> <img src="/assets/img/posts/dfm/fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_2d_elbo</span><span class="p">(</span><span class="n">elbo_dct</span><span class="p">):</span> 
    <span class="n">probability_lower_bound</span> <span class="o">=</span> <span class="n">elbo_dct</span><span class="p">[</span><span class="sh">'</span><span class="s">elbo</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">log_prob_lower_bound_per_dim</span> <span class="o">=</span> <span class="n">elbo_dct</span><span class="p">[</span><span class="sh">'</span><span class="s">logp_per_dim</span><span class="sh">'</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

    <span class="n">cmin</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">cmax</span> <span class="o">=</span> <span class="n">probability_lower_bound</span><span class="p">.</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1.5</span> 
    <span class="n">norm</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">colors</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">probability_lower_bound</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">).</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">origin</span><span class="o">=</span><span class="sh">'</span><span class="s">lower</span><span class="sh">'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">ELBO Estimator</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="nc">ScalarMappable</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">orientation</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">density</span><span class="sh">'</span><span class="p">)</span>


    <span class="n">cmin</span> <span class="o">=</span> <span class="o">-</span><span class="mf">8.0</span>
    <span class="n">cmax</span> <span class="o">=</span> <span class="o">-</span><span class="mf">3.0</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">colors</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">vmax</span><span class="o">=</span><span class="n">cmax</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">cmin</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">log_prob_lower_bound_per_dim</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">).</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">origin</span><span class="o">=</span><span class="sh">'</span><span class="s">lower</span><span class="sh">'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">logP(x_1)/dim Estimator</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="nc">ScalarMappable</span><span class="p">(</span><span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">orientation</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">density</span><span class="sh">'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span>


<span class="c1"># Grid of vocab_size X vocab_size
</span><span class="n">grid</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                      <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                      <span class="n">indexing</span><span class="o">=</span><span class="sh">'</span><span class="s">ij</span><span class="sh">'</span><span class="p">)</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># using the last model, (mask, CE)
</span><span class="n">elbo_dct</span> <span class="o">=</span> <span class="nf">elbo_estimate</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">source_distribution</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="nf">plot_2d_elbo</span><span class="p">(</span><span class="n">elbo_dct</span><span class="p">)</span>

</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/dfm/fig2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/dfm/fig2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/dfm/fig2-1400.webp"/> <img src="/assets/img/posts/dfm/fig2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># show and plot the elbo and logp/dim
</span><span class="k">for</span> <span class="n">source_distribution</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">loss_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">]:</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="se">\n</span><span class="s">----- </span><span class="si">{</span><span class="n">source_distribution</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s"> -----</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="sh">'</span><span class="s">model</span><span class="sh">'</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">solver_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEuler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEulerStochastic</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeunStochastic</span><span class="sh">'</span><span class="p">]:</span> 

            <span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="n">solver_type</span><span class="p">][</span><span class="sh">'</span><span class="s">sample</span><span class="sh">'</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">elbo_dct</span> <span class="o">=</span> <span class="nf">elbo_estimate</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">source_distribution</span><span class="p">)</span>
            <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="n">solver_type</span><span class="p">].</span><span class="nf">update</span><span class="p">(</span><span class="n">elbo_dct</span><span class="p">)</span>
            
            <span class="n">elbo_mean</span> <span class="o">=</span> <span class="n">elbo_dct</span><span class="p">[</span><span class="sh">'</span><span class="s">elbo</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">log_p_mean</span> <span class="o">=</span> <span class="n">elbo_dct</span><span class="p">[</span><span class="sh">'</span><span class="s">logp_per_dim</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">solver_type</span><span class="si">}</span><span class="s">, ELBO = </span><span class="si">{</span><span class="n">elbo_mean</span><span class="si">:</span><span class="p">.</span><span class="mi">8</span><span class="n">f</span><span class="si">}</span><span class="s">, LogP/dim = </span><span class="si">{</span><span class="n">log_p_mean</span><span class="si">:</span><span class="p">.</span><span class="mi">5</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="se">\n</span><span class="s">-----</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div> <p>Uniform</p> <table border="1"> <thead> <tr> <th>Method</th> <th>ELBO (KL / CE)</th> <th>LogP/dim (KL / CE)</th> </tr> </thead> <tbody> <tr> <td>Euler</td> <td>0.00001383 / 0.00001103</td> <td>-5.62259 / -5.81091</td> </tr> <tr> <td>Heun</td> <td><strong>0.00001418</strong> / 0.00001150</td> <td><strong>-5.60660</strong> / -5.77359</td> </tr> <tr> <td>SimpleEuler</td> <td>0.00001381 / 0.00001101</td> <td>-5.62421 / -5.81599</td> </tr> <tr> <td>SimpleHeun</td> <td>0.00001383 / 0.00001107</td> <td>-5.62253 / -5.80796</td> </tr> <tr> <td>SimpleEulerStochastic</td> <td>0.00001374 / 0.00001094</td> <td>-5.63223 / -5.82770</td> </tr> <tr> <td>SimpleHeunStochastic</td> <td>0.00001376 / 0.00001101</td> <td>-5.63070 / -5.81804</td> </tr> </tbody> </table> <p>Mask</p> <table border="1"> <thead> <tr> <th>Method</th> <th>ELBO (KL / CE)</th> <th>LogP/dim (KL / CE)</th> </tr> </thead> <tbody> <tr> <td>Euler</td> <td>0.00012449 / 0.00012359</td> <td>-4.51112 / -4.51102</td> </tr> <tr> <td>Heun</td> <td>0.00012453 / <strong>0.00012368</strong></td> <td>-4.50965 / <strong>-4.50959</strong></td> </tr> <tr> <td>SimpleEuler</td> <td>0.00012445 / 0.00012361</td> <td>-4.51148 / -4.51128</td> </tr> <tr> <td>SimpleHeun</td> <td>0.00012451 / 0.00012360</td> <td>-4.51088 / -4.51113</td> </tr> <tr> <td>SimpleEulerStochastic</td> <td>0.00012452 / 0.00012361</td> <td>-4.51197 / -4.51254</td> </tr> <tr> <td>SimpleHeunStochastic</td> <td>0.00012451 / 0.00012360</td> <td>-4.51180 / -4.51192</td> </tr> </tbody> </table> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Using the scoring model:
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Using the scoring model: </span><span class="sh">'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">source_distribution</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">]:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">scoring_model</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">loss_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">]:</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="se">\n</span><span class="s">----- </span><span class="si">{</span><span class="n">source_distribution</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s"> -----</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">solver_type</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">Euler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEuler</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeun</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleEulerStochastic</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SimpleHeunStochastic</span><span class="sh">'</span><span class="p">]:</span> 

            <span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="n">solver_type</span><span class="p">][</span><span class="sh">'</span><span class="s">sample</span><span class="sh">'</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">elbo_dct</span> <span class="o">=</span> <span class="nf">elbo_estimate</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">source_distribution</span><span class="p">)</span>
            <span class="n">rlt_dct</span><span class="p">[</span><span class="n">source_distribution</span><span class="p">][</span><span class="n">loss_type</span><span class="p">][</span><span class="n">solver_type</span><span class="p">].</span><span class="nf">update</span><span class="p">(</span><span class="n">elbo_dct</span><span class="p">)</span>
            
            <span class="n">elbo_mean</span> <span class="o">=</span> <span class="n">elbo_dct</span><span class="p">[</span><span class="sh">'</span><span class="s">elbo</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">log_p_mean</span> <span class="o">=</span> <span class="n">elbo_dct</span><span class="p">[</span><span class="sh">'</span><span class="s">logp_per_dim</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">solver_type</span><span class="si">}</span><span class="s">, ELBO = </span><span class="si">{</span><span class="n">elbo_mean</span><span class="si">:</span><span class="p">.</span><span class="mi">8</span><span class="n">f</span><span class="si">}</span><span class="s">, LogP/dim = </span><span class="si">{</span><span class="n">log_p_mean</span><span class="si">:</span><span class="p">.</span><span class="mi">5</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="se">\n</span><span class="s">-----</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div> <p>Uniform</p> <table border="1"> <thead> <tr> <th>Method</th> <th>ELBO (KL / CE)</th> <th>LogP/dim (KL / CE)</th> </tr> </thead> <tbody> <tr> <td>Euler</td> <td>0.00001458 / 0.00001428</td> <td>-5.59203 / -5.74789</td> </tr> <tr> <td>Heun</td> <td>0.00001462 / 0.00001437</td> <td><strong>-5.58809</strong> / -5.70745</td> </tr> <tr> <td>SimpleEuler</td> <td>0.00001458 / 0.00001426</td> <td>-5.59285 / -5.75720</td> </tr> <tr> <td>SimpleHeun</td> <td>0.00001457 / 0.00001429</td> <td>-5.59236 / -5.74419</td> </tr> <tr> <td>SimpleEulerStochastic</td> <td>0.00001456 / 0.00001422</td> <td>-5.59908 / -5.77931</td> </tr> <tr> <td>SimpleHeunStochastic</td> <td>0.00001457 / 0.00001426</td> <td>-5.59803 / -5.76159</td> </tr> </tbody> </table> <p>Mask</p> <table border="1"> <thead> <tr> <th>Method</th> <th>ELBO (KL / CE)</th> <th>LogP/dim (KL / CE)</th> </tr> </thead> <tbody> <tr> <td>Euler</td> <td>0.00012271 / 0.00012283</td> <td>-4.51789 / -4.51597</td> </tr> <tr> <td>Heun</td> <td>0.00012271 / 0.00012290</td> <td>-4.51583 / <strong>-4.51402</strong></td> </tr> <tr> <td>SimpleEuler</td> <td>0.00012268 / 0.00012283</td> <td>-4.51828 / -4.51631</td> </tr> <tr> <td>SimpleHeun</td> <td>0.00012272 / 0.00012287</td> <td>-4.51744 / -4.51593</td> </tr> <tr> <td>SimpleEulerStochastic</td> <td>0.00012270 / 0.00012280</td> <td>-4.51952 / -4.51832</td> </tr> <tr> <td>SimpleHeunStochastic</td> <td>0.00012269 / 0.00012284</td> <td>-4.51913 / -4.51717</td> </tr> </tbody> </table> <p><br/></p> <h1 id="sequence">Sequence</h1> <p>Building on the previous source type, training loss and ssampling, we now stick to: [uniform-KL, mask-CE] + [Heun] for training a sequence generation model on <code class="language-plaintext highlighter-rouge">1hxe.a2m</code>, which is a MSA from Serine Protease (<code class="language-plaintext highlighter-rouge">PDB: 1HXE</code>).</p> <p>We used fixed length including gaps in the MSA, this enables easy data loading. However, one can train without fixed length data by grouping same-length data in a batch as \(x_1\) and sample noised version of \(x_t\). The sequence length varies from batch to batch, so does the compute (CPU/GPU/Mem). If there is one length being under-represented, one can sample more time point to compensate and get batch of the same size. This might need some massage in the dataloading and preprocessing time, which we don’t do here.</p> <p>The model backbone is a Discrete Diffusion Transformer (DDiT) module.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load and process msafile
</span><span class="n">RESTYPES</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">R</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">N</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Q</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">E</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">G</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">I</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">L</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">K</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">P</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">S</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">T</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">W</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Y</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">V</span><span class="sh">'</span><span class="p">]</span>
<span class="n">RESTYPES_WITH_X_GAP</span> <span class="o">=</span> <span class="n">RESTYPES</span> <span class="o">+</span> <span class="p">[</span><span class="sh">'</span><span class="s">X</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">]</span>
<span class="n">RESTYPE_TO_IDX</span> <span class="o">=</span> <span class="p">{</span><span class="n">res</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">res</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">RESTYPES_WITH_X_GAP</span><span class="p">)}</span>

<span class="k">def</span> <span class="nf">msa_to_torch</span><span class="p">(</span><span class="n">msafile</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">isfile</span><span class="p">(</span><span class="n">msafile</span><span class="p">)</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">msafile</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">msafile</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">.a3m</span><span class="sh">'</span><span class="p">):</span> 
        <span class="n">seqs</span> <span class="o">=</span> <span class="p">[</span><span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">if</span> <span class="n">a</span><span class="p">.</span><span class="nf">isupper</span><span class="p">()</span> <span class="ow">or</span> <span class="n">a</span> <span class="o">==</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">])</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span> <span class="nf">if </span><span class="p">(</span><span class="ow">not</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">'</span><span class="s">#</span><span class="sh">'</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">'</span><span class="s">&gt;</span><span class="sh">'</span><span class="p">))]</span>
    <span class="k">elif</span> <span class="n">msafile</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">.a2m</span><span class="sh">'</span><span class="p">):</span> 
        <span class="n">seqs</span><span class="p">,</span> <span class="n">tmp</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span> 
            <span class="k">if</span> <span class="n">line</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">'</span><span class="s">&gt;</span><span class="sh">'</span><span class="p">):</span> 
                <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span> <span class="n">seqs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">else</span><span class="p">:</span> 
                <span class="n">tmp</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">upper</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">))</span>

    <span class="n">nseq</span><span class="p">,</span> <span class="n">seqlen</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">seqs</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">seqs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">nseq</span><span class="p">,</span> <span class="n">seqlen</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">seq</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">enumerate</span><span class="p">(</span><span class="n">seqs</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">RESTYPE_TO_IDX</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="k">if</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">RESTYPE_TO_IDX</span> <span class="k">else</span> <span class="mi">20</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">inf_seq_train_gen</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="n">nseq</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">device</span>
    <span class="k">assert</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="n">nseq</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nseq</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>



<span class="c1">## Model
# # model definition
</span><span class="kn">import</span> <span class="n">math</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="kn">from</span> <span class="n">einops</span> <span class="kn">import</span> <span class="n">rearrange</span><span class="p">,</span> <span class="n">repeat</span>
<span class="kn">from</span> <span class="n">omegaconf</span> <span class="kn">import</span> <span class="n">OmegaConf</span>
<span class="kn">from</span> <span class="n">omegaconf.dictconfig</span> <span class="kn">import</span> <span class="n">DictConfig</span>



<span class="k">class</span> <span class="nc">Rotary</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    From: https://github.com/louaaron/Score-Entropy-Discrete-Diffusion
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">base</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10_000</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">inv_freq</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">base</span> <span class="o">**</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">dim</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">"</span><span class="s">inv_freq</span><span class="sh">"</span><span class="p">,</span> <span class="n">inv_freq</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">seq_len_cached</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cos_cached</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sin_cached</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="n">seq_dim</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">seq_len</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">seq_len_cached</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">seq_len_cached</span> <span class="o">=</span> <span class="n">seq_len</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="n">seq_dim</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">).</span><span class="nf">type_as</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">inv_freq</span><span class="p">)</span>
            <span class="n">freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">"</span><span class="s">i,j-&gt;ij</span><span class="sh">"</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">inv_freq</span><span class="p">.</span><span class="nf">clone</span><span class="p">())</span>
            <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">freqs</span><span class="p">,</span> <span class="n">freqs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># dims are: batch, seq_len, qkv, head, dim
</span>            <span class="n">self</span><span class="p">.</span><span class="n">cos_cached</span> <span class="o">=</span> <span class="n">emb</span><span class="p">.</span><span class="nf">cos</span><span class="p">()[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:].</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">sin_cached</span> <span class="o">=</span> <span class="n">emb</span><span class="p">.</span><span class="nf">sin</span><span class="p">()[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:].</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="c1"># This makes the transformation on v an identity.
</span>            <span class="n">self</span><span class="p">.</span><span class="n">cos_cached</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:].</span><span class="nf">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">sin_cached</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:].</span><span class="nf">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">cos_cached</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">sin_cached</span>


<span class="k">def</span> <span class="nf">rotate_half</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">x</span><span class="p">[...,</span> <span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="p">[...,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span> <span class="p">:]</span>

    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="o">-</span><span class="n">x2</span><span class="p">,</span> <span class="n">x1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">apply_rotary_emb_torch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">sin</span><span class="p">,</span> <span class="n">interleaved</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    From: https://github.com/Dao-AILab/flash-attention/blob/main/flash_attn/layers/rotary.py#L20
    </span><span class="sh">"""</span>
    <span class="n">cos</span> <span class="o">=</span> <span class="n">cos</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="n">cos</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">sin</span> <span class="o">=</span> <span class="n">sin</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:</span> <span class="n">sin</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>

    <span class="n">ro_dim</span> <span class="o">=</span> <span class="n">cos</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="n">ro_dim</span> <span class="o">&lt;=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">cos</span> <span class="o">=</span> <span class="nf">repeat</span><span class="p">(</span>
        <span class="n">cos</span><span class="p">,</span> <span class="sh">"</span><span class="s">... d -&gt; ... 1 (2 d)</span><span class="sh">"</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">interleaved</span> <span class="k">else</span> <span class="sh">"</span><span class="s">... d -&gt; ... 1 (d 2)</span><span class="sh">"</span>
    <span class="p">)</span>
    <span class="n">sin</span> <span class="o">=</span> <span class="nf">repeat</span><span class="p">(</span>
        <span class="n">sin</span><span class="p">,</span> <span class="sh">"</span><span class="s">... d -&gt; ... 1 (2 d)</span><span class="sh">"</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">interleaved</span> <span class="k">else</span> <span class="sh">"</span><span class="s">... d -&gt; ... 1 (d 2)</span><span class="sh">"</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">[...,</span> <span class="p">:</span><span class="n">ro_dim</span><span class="p">]</span> <span class="o">*</span> <span class="n">cos</span> <span class="o">+</span> <span class="nf">rotate_half</span><span class="p">(</span><span class="n">x</span><span class="p">[...,</span> <span class="p">:</span><span class="n">ro_dim</span><span class="p">])</span> <span class="o">*</span> <span class="n">sin</span>


<span class="k">def</span> <span class="nf">bias_dropout_add_scale</span><span class="p">(</span>
    <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">residual</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">prob</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">residual</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">modulate</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">shift</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">scale</span><span class="p">)</span> <span class="o">+</span> <span class="n">shift</span>


<span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">([</span><span class="n">dim</span><span class="p">]))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="nf">autocast</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">dim</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>


<span class="k">class</span> <span class="nc">TimestepEmbedder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Embeds scalar timesteps into vector representations.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">frequency_embedding_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">frequency_embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">frequency_embedding_size</span> <span class="o">=</span> <span class="n">frequency_embedding_size</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">timestep_embedding</span><span class="p">(</span><span class="n">time</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_period</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Create sinusoidal timestep embeddings.
        :param t: a 1-D Tensor of N indices, one per batch element.
                          These may be fractional.
        :param dim: the dimension of the output.
        :param max_period: controls the minimum frequency of the embeddings.
        :return: an (N, D) Tensor of positional embeddings.
        </span><span class="sh">"""</span>
        <span class="n">half</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">freqs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span>
            <span class="o">-</span><span class="n">math</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">max_period</span><span class="p">)</span>
            <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">half</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="o">/</span> <span class="n">half</span>
        <span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">time</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">args</span> <span class="o">=</span> <span class="n">time</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">].</span><span class="nf">float</span><span class="p">()</span> <span class="o">*</span> <span class="n">freqs</span><span class="p">[</span><span class="bp">None</span><span class="p">]</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">args</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">args</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">%</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">embedding</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">embedding</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">embedding</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">time</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">t_freq</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">timestep_embedding</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">time</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">frequency_embedding_size</span><span class="p">)</span>
        <span class="n">t_emb</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mlp</span><span class="p">(</span><span class="n">t_freq</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">t_emb</span>


<span class="k">class</span> <span class="nc">DDiTBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">cond_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">mlp_ratio</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">dim</span> <span class="o">%</span> <span class="n">n_heads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">dim must be devisable by n_heads</span><span class="sh">"</span>

        <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="n">self</span><span class="p">.</span><span class="n">head_dim</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">//</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span>

        <span class="n">self</span><span class="p">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">qw</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kw</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vw</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">attn_out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">mlp_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">GELU</span><span class="p">(</span><span class="n">approximate</span><span class="o">=</span><span class="sh">"</span><span class="s">tanh</span><span class="sh">"</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">mlp_ratio</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">adaLN_modulation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">cond_dim</span><span class="p">,</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adaLN_modulation</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adaLN_modulation</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">rotary_cos_sin</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="p">(</span>
            <span class="n">shift_msa</span><span class="p">,</span>
            <span class="n">scale_msa</span><span class="p">,</span>
            <span class="n">gate_msa</span><span class="p">,</span>
            <span class="n">shift_mlp</span><span class="p">,</span>
            <span class="n">scale_mlp</span><span class="p">,</span>
            <span class="n">gate_mlp</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">adaLN_modulation</span><span class="p">(</span><span class="n">c</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">].</span><span class="nf">chunk</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">x_skip</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nf">modulate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">norm1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">shift</span><span class="o">=</span><span class="n">shift_msa</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale_msa</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">qw</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">kw</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">vw</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">item</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">head_dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="nf">autocast</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
            <span class="n">cos</span><span class="p">,</span> <span class="n">sin</span> <span class="o">=</span> <span class="n">rotary_cos_sin</span>
            <span class="n">original_dtype</span> <span class="o">=</span> <span class="n">q</span><span class="p">.</span><span class="n">dtype</span>

            <span class="n">q</span> <span class="o">=</span> <span class="nf">apply_rotary_emb_torch</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">q</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">cos</span><span class="o">=</span><span class="n">cos</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">sin</span><span class="o">=</span><span class="n">sin</span><span class="p">.</span><span class="nf">float</span><span class="p">()</span>
            <span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">original_dtype</span><span class="p">)</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nf">apply_rotary_emb_torch</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">k</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">cos</span><span class="o">=</span><span class="n">cos</span><span class="p">.</span><span class="nf">float</span><span class="p">(),</span> <span class="n">sin</span><span class="o">=</span><span class="n">sin</span><span class="p">.</span><span class="nf">float</span><span class="p">()</span>
            <span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">original_dtype</span><span class="p">)</span>

        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nf">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="sh">"</span><span class="s">b h s d -&gt; b s (h d)</span><span class="sh">"</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nf">bias_dropout_add_scale</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">attn_out</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">scale</span><span class="o">=</span><span class="n">gate_msa</span><span class="p">,</span>
            <span class="n">residual</span><span class="o">=</span><span class="n">x_skip</span><span class="p">,</span>
            <span class="n">prob</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nf">bias_dropout_add_scale</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">mlp</span><span class="p">(</span><span class="nf">modulate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">norm2</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">shift</span><span class="o">=</span><span class="n">shift_mlp</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale_mlp</span><span class="p">)),</span>
            <span class="n">scale</span><span class="o">=</span><span class="n">gate_mlp</span><span class="p">,</span>
            <span class="n">residual</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
            <span class="n">prob</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">,</span>
            <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">DDitFinalLayer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">cond_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">norm_final</span> <span class="o">=</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">adaLN_modulation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">cond_dim</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adaLN_modulation</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adaLN_modulation</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">c</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">shift</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">adaLN_modulation</span><span class="p">(</span><span class="n">c</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">].</span><span class="nf">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nf">modulate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="nf">norm_final</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">shift</span><span class="o">=</span><span class="n">shift</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">masked</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">DictConfig</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>

        <span class="n">add_token</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">masked</span> <span class="k">else</span> <span class="mi">0</span>

        <span class="n">self</span><span class="p">.</span><span class="n">vocab_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">add_token</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">time_embedding</span> <span class="o">=</span> <span class="nc">TimestepEmbedder</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">cond_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rotary_emb</span> <span class="o">=</span> <span class="nc">Rotary</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span> <span class="o">//</span> <span class="n">config</span><span class="p">.</span><span class="n">n_heads</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="nc">DDiTBlock</span><span class="p">(</span>
                    <span class="n">dim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span>
                    <span class="n">n_heads</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span>
                    <span class="n">cond_dim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">cond_dim</span><span class="p">,</span>
                    <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">dropout</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">n_blocks</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="nc">DDitFinalLayer</span><span class="p">(</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">add_token</span><span class="p">,</span>
            <span class="n">cond_dim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">cond_dim</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">time</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">vocab_embed</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">silu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">time_embedding</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="n">time</span><span class="p">))</span>

        <span class="n">rotary_cos_sin</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">rotary_emb</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="nf">autocast</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">blocks</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">blocks</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">rotary_cos_sin</span><span class="o">=</span><span class="n">rotary_cos_sin</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">output_layer</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div> <p>Training</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">msafile</span> <span class="o">=</span> <span class="sh">'</span><span class="s">1hxe.a2m</span><span class="sh">'</span>
<span class="n">msa</span> <span class="o">=</span> <span class="nf">msa_to_torch</span><span class="p">(</span><span class="n">msafile</span><span class="p">)</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">22</span>
<span class="n">train</span> <span class="o">=</span> <span class="bp">False</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="nc">PolynomialScheduler</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="nc">MixtureDiscreteProbPath</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2048</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">n_blocks</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-3</span>

<span class="n">seq_models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">source_loss_combo</span> <span class="o">=</span> <span class="p">[(</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">),</span> 
                     <span class="p">(</span><span class="sh">'</span><span class="s">mask</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">)]</span>

<span class="nf">for </span><span class="p">(</span><span class="n">source_distribution</span><span class="p">,</span> <span class="n">loss_type</span><span class="p">)</span> <span class="ow">in</span> <span class="n">source_loss_combo</span><span class="p">:</span>

    <span class="c1"># training arguments
</span>    <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">"</span><span class="s">uniform</span><span class="sh">"</span><span class="p">:</span>
        <span class="n">added_token</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">"</span><span class="s">mask</span><span class="sh">"</span><span class="p">:</span>
        <span class="n">mask_token</span> <span class="o">=</span> <span class="n">vocab_size</span>  <span class="c1"># tokens starting from zero
</span>        <span class="n">added_token</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nb">NotImplementedError</span>

    <span class="c1"># additional mask token
</span>    <span class="n">vocab_size</span> <span class="o">+=</span> <span class="n">added_token</span>

    <span class="c1"># probability denoiser model init
</span>    <span class="c1"># Model initialization
</span>    <span class="n">cfg</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">config.yaml</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">cfg</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">n_blocks</span> <span class="o">=</span> <span class="n">n_blocks</span>
    <span class="n">cfg</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.3</span>
    <span class="n">probability_denoiser</span> <span class="o">=</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">masked</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of parameters =</span><span class="sh">'</span><span class="p">,</span> <span class="nf">sum</span><span class="p">(</span><span class="n">param</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">probability_denoiser</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()))</span>

    <span class="c1"># init optimizer
</span>    <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">probability_denoiser</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span> 
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="nc">MixturePathGeneralizedKL</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">)</span> <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">KL</span><span class="sh">'</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># train
</span>    <span class="k">if</span> <span class="n">train</span><span class="p">:</span> 
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>

        <span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>

            <span class="c1"># sample data (user's responsibility): in this case, (X_0,X_1) ~ pi(X_0,X_1)
</span>            <span class="n">x_1</span> <span class="o">=</span> <span class="nf">inf_seq_train_gen</span><span class="p">(</span><span class="n">msa</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># sample data
</span>
            <span class="k">if</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">"</span><span class="s">uniform</span><span class="sh">"</span><span class="p">:</span>
                <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">source_distribution</span> <span class="o">==</span> <span class="sh">"</span><span class="s">mask</span><span class="sh">"</span><span class="p">:</span>
                <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span> <span class="o">+</span> <span class="n">mask_token</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="nb">NotImplementedError</span>

            <span class="c1"># sample time (user's responsibility)
</span>            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">)</span>

            <span class="c1"># sample probability path
</span>            <span class="c1"># mixture of discrete probability path for each token
</span>            <span class="n">path_sample</span> <span class="o">=</span> <span class="n">path</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="o">=</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="o">=</span><span class="n">x_1</span><span class="p">)</span>

            <span class="c1"># discrete flow matching generalized KL loss
</span>            <span class="n">logits</span> <span class="o">=</span> <span class="nf">probability_denoiser</span><span class="p">(</span><span class="n">path_sample</span><span class="p">.</span><span class="n">x_t</span><span class="p">,</span> <span class="n">path_sample</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">KL</span><span class="sh">'</span><span class="p">:</span> 
                <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">x_1</span><span class="o">=</span><span class="n">x_1</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">path_sample</span><span class="p">.</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">path_sample</span><span class="p">.</span><span class="n">t</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">CE</span><span class="sh">'</span><span class="p">:</span> 
                <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="sh">'</span><span class="s">b n d -&gt; (b n) d</span><span class="sh">'</span><span class="p">),</span> 
                               <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="sh">'</span><span class="s">b n -&gt; (b n)</span><span class="sh">'</span><span class="p">))</span><span class="c1"># This should be consistent with the following:
</span>            <span class="c1"># logit_to_velocity(pred_x_1, x_t, t) - logit_to_velocity(x_1, x_t, t)
</span>
            <span class="c1"># optimizer step
</span>            <span class="n">optim</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span> 
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span> <span class="c1"># backward
</span>            <span class="n">optim</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span> <span class="c1"># update
</span>
            <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">loss = </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>    
            <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">probability_denoiser</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">seq_</span><span class="si">{</span><span class="n">source_distribution</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s">.pth</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="n">probability_denoiser</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">seq_</span><span class="si">{</span><span class="n">source_distribution</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">loss_type</span><span class="si">}</span><span class="s">.pth</span><span class="sh">'</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    
    <span class="n">seq_models</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">probability_denoiser</span><span class="p">))</span>
</code></pre></div></div> <p>Sampling</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="o">%%</span><span class="n">time</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">22</span>
<span class="n">seq</span> <span class="o">=</span> <span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">RESTYPES_WITH_X_GAP</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">msa</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">seqs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sols</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_distribution</span><span class="p">,</span> <span class="n">loss_type</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">source_loss_combo</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">seq_models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">sol</span> <span class="o">=</span> <span class="nf">sample_discrete_flow_matching_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> 
                                              <span class="n">source_distribution</span><span class="o">=</span><span class="n">source_distribution</span><span class="p">,</span> 
                                              <span class="n">solver_type</span><span class="o">=</span><span class="sh">'</span><span class="s">Heun</span><span class="sh">'</span><span class="p">,</span> 
                                              <span class="n">dim</span><span class="o">=</span><span class="n">msa</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                                              <span class="n">n_samples</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">nfe</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">n_plots</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">sols</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">sol</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">seqs</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">RESTYPES_WITH_X_GAP</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">s</span><span class="p">])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sol</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
    
    <span class="nf">print</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">source_distribution</span><span class="p">,</span> <span class="n">loss_type</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Original</span><span class="sh">'</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Samples</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nf">print</span><span class="p">(</span><span class="n">seqs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
    <span class="nf">print</span><span class="p">()</span>
    
</code></pre></div></div> <hr/> <p>Sampling with Heun solver</p> <p>uniform KL</p> <p><code class="language-plaintext highlighter-rouge">Original</code></p> <p>IVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISMLEKIYIHPRYNWRENLDRDIALMKLKKPVAFSDYIHPVCLPDRETAASLLQAGYKGRVTGWGNLKETWTANVGKGQPSVLQVVNLPIVERPVCKDSTRIRITDNMFCAGYKPDEGKRGDACEGDSGGPFVMKSPFNNRWYQMGIVSWGEGCDRDGKYGFYTHVFRLKKWIQKVIDQFGE</p> <p><code class="language-plaintext highlighter-rouge">Samples</code></p> <p>IVGGANAPAGSWPWQVSLQING–GHFCGGSLINNEWVLSAAHCFPS——-STSGIQVNLGRQNLQGSNPN-EVFRSVSTIIIHPNYNS-DSNDNDIALLRLSSPVTFNNYISPVCLAASG—STFHNGTDCWVTGFGDIRSD—-VPLPFPNTLQEVQVPVIGNRQCNCNYGGSITGNMICAGL———————————————————————</p> <p>IVGGSEAELGEWPWQVSLRYNR–SHICGGALVSDKWILSAAHCFEEY—–RDPAEWKVYMGLYSQDSLNK–YKGISVKQIISHPNYNP-ETKDYDIALLQLEEPVLYTNFVQPICLPRSG—HVFPPGTICWITGWGRIQEE——GSSSNALQKAMVPIIDRHFCSRLYPSGIKPGMICAGFI–EGG-VDACQGDSGGPLVCKE-KGSIFFLAGITSWGIGCGLPNKPGVYTRVTELNSWIREKM—–</p> <p>IVGGSAAEISTYPWQVSLTSGG–RHFCGGSVVAPKIVLTAAHCVVG——-QPSSIRVRVGRTDKATGGG—QIISVSEQWIHPKYND-NTNDGDWALIKLAQPIAYSPAIQTISLATTA—–YAAGTTATVSGWGATTGT——GDYANTLRAVAVPLVSDTECRAAYPGDLTDNMVCAGYL–DGG-RDACQGDSGGPLVAGG——KLVGLVSWGYGCGQAGKPGVYTEVS—————</p> <p>IVGGEDAPAGSWPWQVSLHTFG—HFCGGSLINNEWVVTAAHCFSR—————LGRHSLEGSNPN-EQSLSVSRVIKHPNYDS-STNDNDICLLQLQSPVTLTNYVRPVCLAASG—SVFANGTNSWVTGWGNTAEG—-VSLPFPANLQEVEVPVLGNRQCKCLYGSTITNNMICAGLL–AGG-KDSCQGDSGGPMVSKN–NSVWIQSGVVSWGYGCALPNYPGVYTRVSEYQSWINSQI—–</p> <p>IVGGEDAPAGSWPWQVSLHTFG–GHFCGGSLINKEWVLSAAHCFQS——WSTAGWEVYLGRQSLQGNNPN-EQSRTVSKIIIHPNYDS-RTNDNDIALLQLSSPVTFNNYIRPVCLAAFG—SVFNSGTSSWVTGWGNVEEG———PDTLMEVMVPVVGNRQCNCLYGVTITNNMICAGYL–AGG-KDSCQGDSGGPLVSKQ–GSRWVQAGIVSFGIGCAQPNKPGVYARVSRYQTWINSNI—–</p> <hr/> <p>Sampling with Heun solver</p> <p>mask CE</p> <p><code class="language-plaintext highlighter-rouge">Original</code></p> <p>IVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISMLEKIYIHPRYNWRENLDRDIALMKLKKPVAFSDYIHPVCLPDRETAASLLQAGYKGRVTGWGNLKETWTANVGKGQPSVLQVVNLPIVERPVCKDSTRIRITDNMFCAGYKPDEGKRGDACEGDSGGPFVMKSPFNNRWYQMGIVSWGEGCDRDGKYGFYTHVFRLKKWIQKVIDQFGE</p> <p><code class="language-plaintext highlighter-rouge">Samples</code></p> <p>IVGGSEATPGSHPWQAALYISPAEKVFCGGSLIDKCWVATAAHCFKDE——REQYVTVVLGDHHLNRTEGS-EQSLKVEEAIIHPCYNP-SSYDSDIALLKLKHPAKLSKAVSPVCLPEET—QIFSAGSECTISGWGQTEEG—–ADSYSVVLQEAQVPLIDQEQCSKPYGTELDENMMCAGYM–EGG-ADSCQGDSGGPLTCQW–DGRMFLLGITSWGYGCAKPNKPGVYTRVTNFSEWIQSTT—–</p> <p>VVGGYEAVQSKLPYNVSIQQGQSNSHFCSGALINERWVLTAAHCVMRR—YHLPRNQLEAVLGTHKLTSGGSL-GQTRRVTTIIRHPDGKDVCKYRSNIALIELNPKVNF–KVQPIRISDED—–LTPNTKCIVAGWGITKAG——-GEVLPLNKATVPYVNERACKEYHLEFLGKETLCVGHD–QGL-RGVCDGDAGGGLFCKT-SNDPWKLTGIAVGGQEPCSFTGPSIYIDIRHHLEWLMQNI—–</p> <p>VAGGNDGRPGAHPWIVALFRNG–THFCGGSLIKGSWVLSAAHCFYNH—-NTDGSDLVAIVGDHQLNRHDGE-EVLVAVSGVIMNQQYNP-NTLQYDIALIKLVQPVSFTEYIQPICLPSPR—VELNENRVCTVTGWGTTQPG—-APPLVSNPLQSVAVPVQATGDCKAAYSHSITDRMLCAGYR–EGN-KDSCQGDSGGPLLCRN–GEQYELHGVVSWGFGCGHPDFYAVYVRTSYLIQWINQTT—–</p> <p>IVGGADTTINQYPAQVSLLISSGGWHFCGGSIINNRWILTGAHCSHA——-SPNFRRVRVGSSFASEGG—–VHNVERIIVHEGYDW-LTHDNDISVLRLSTALTFSNNIQPAPIAGAN—TTVGENDAAWAAGWGATANG——GGSENALQHVQVPVVNQRQCRRNYANRITNNMICSGWL-GAGG-RDSCQGDSGGPLTHNG——TLVGVCSFGIGCALRRYPGVYARVSSYSSWIDAN——</p> <p>IIGGRLVTNESRPYQVSLRKEDSKRHSCGGFLISERFALTAAHCNLEP-RSFGQVPALTNVRVGSSFTSSGG—–LHPVRRLIVHPNYDE-QTLDHDIRLLQLDRKVHLNDTVRVVSLPDSP—-DVEDNTLCTTSGWGTTEPDTVKSG-IERPDELRELKLTILNA-ACARQ——-RHLCTGVP–KRE-SGPCAGDSGGPLVCNG——PVHGVASYSRNCG——-FTKIATYVTWLLGQT—–</p> <p>CPU times: user 49.7 s, sys: 5.29 ms, total: 49.7 s</p> <p>Wall time: 49.8 s</p> <p>For serine protease, the first couple of residues are critical for substrate recognition and binding. These residues often form the active site and are highly conserved across different species. In the sample, many of the sequences has similar <code class="language-plaintext highlighter-rouge">IVEGS</code> and <code class="language-plaintext highlighter-rouge">PWQV</code> motifs from the uniform KL track. The mask CE track also captures these motifs, but with more variability. Uniform source distribution is therefore preferred by many DFM models empirically.</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/dfm/out.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/dfm/out.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/dfm/out.gif-1400.webp"/> <img src="/assets/img/posts/dfm/out.gif" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Next, we want to assess the ELBO score for 512 sequences:</p> <p>128 from the training set, index 0 being the query <code class="language-plaintext highlighter-rouge">1hxe.pdb</code> sequence</p> <p>128 sampled sequences</p> <p>128 from the training data, with 10 N-term residue randomly mutated</p> <p>128 random sequence.</p> <p>As the following histogram shows, the sampled sequences have the highest ELBO and logP/dim (preferred), and the random sequences being highly unlikely with the most negative ELBO estimates.</p> <p>When the first 10 residues are mutated (highly preserved regions), the ELBO dropped, suggesting that the ELBO score can be used to gauge the quality of the sequence.</p> <p>The first spike was from the query, as most of the sequences in the MSA contain gap, a no-gap query sequence then becomes an outlier with high ELBO scores. One proper way to do this is to remove the gaps in the MSA or masked the gap prediction in the loss.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compute the elbo and logP for original seq, samples and random seqs
</span>
<span class="c1"># Generalized KL function (will use it to compute the elbo)
</span><span class="n">generalized_kl_fn</span> <span class="o">=</span> <span class="nc">MixturePathGeneralizedKL</span><span class="p">(</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span><span class="sh">'</span><span class="s">none</span><span class="sh">'</span><span class="p">)</span>
<span class="n">elbo_dcts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_distribution</span><span class="p">,</span> <span class="n">loss_type</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">source_loss_combo</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">seq_models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
    <span class="c1"># first 10 position random mutation
</span>    <span class="n">mut</span> <span class="o">=</span> <span class="n">msa</span><span class="p">[:</span><span class="mi">128</span><span class="p">].</span><span class="nf">clone</span><span class="p">()</span>
    <span class="n">mut</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">10</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint_like</span><span class="p">(</span><span class="n">mut</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">10</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
    
    <span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">msa</span><span class="p">[:</span><span class="mi">128</span><span class="p">],</span> 
                     <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">sols</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="mi">128</span><span class="p">]),</span>
                     <span class="n">mut</span><span class="p">,</span>
                     <span class="n">torch</span><span class="p">.</span><span class="nf">randint_like</span><span class="p">(</span><span class="n">msa</span><span class="p">[:</span><span class="mi">128</span><span class="p">],</span> <span class="n">high</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)]).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">elbo_dcts</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">elbo_estimate</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">source_distribution</span><span class="p">))</span>



<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">127</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">128</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="mi">128</span> <span class="o">+</span> <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="mi">128</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span> 
    <span class="n">my_cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">get_cmap</span><span class="p">(</span><span class="sh">'</span><span class="s">tab10</span><span class="sh">'</span><span class="p">)</span>
<span class="c1">#     rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))
</span>    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">bar</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">512</span><span class="p">),</span> <span class="n">elbo_dcts</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">logp_per_dim</span><span class="sh">'</span><span class="p">].</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="nf">my_cmap</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="n">source_loss_combo</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">seq #</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">logP/dim</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/dfm/fig3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/dfm/fig3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/dfm/fig3-1400.webp"/> <img src="/assets/img/posts/dfm/fig3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div>]]></content><author><name></name></author><category term="models"/><category term="reading"/><category term="generating"/><category term="coding"/><summary type="html"><![CDATA[Playing with discrete flow matching on toy examples]]></summary></entry><entry><title type="html">Inference-Time Scaling for Diffusion/Flow Models</title><link href="https://jipq6175.github.io/blog/2025/inference_time_scaling/" rel="alternate" type="text/html" title="Inference-Time Scaling for Diffusion/Flow Models"/><published>2025-06-14T20:20:00+00:00</published><updated>2025-06-14T20:20:00+00:00</updated><id>https://jipq6175.github.io/blog/2025/inference_time_scaling</id><content type="html" xml:base="https://jipq6175.github.io/blog/2025/inference_time_scaling/"><![CDATA[<h1 id="inference-time-scaling-for-diffusion-models-from-simple-search-to-feynman-kac-steering">Inference-Time Scaling for Diffusion Models: From Simple Search to Feynman-Kac Steering</h1> <h2 id="introduction">Introduction</h2> <p>Diffusion models have revolutionized generative AI, producing impressive results across various domains. However, generating samples with specific desired properties remains challenging. While training-based approaches exist, they require expensive fine-tuning and tie models to specific reward functions. This blog post explores <strong>inference-time scaling</strong> techniques that can steer diffusion models toward desired outputs without any additional training.</p> <p>We’ll walk through three increasingly sophisticated approaches:</p> <ol> <li><strong>Zeroth-order search</strong> - searching in the noise space</li> <li><strong>Search over paths</strong> - searching during the denoising process</li> <li><strong>Feynman-Kac steering</strong> - a particle-based approach using stochastic dynamics</li> </ol> <p>This implementation demonstrates these concepts on a 2D toy problem, but the same principles apply to the large-scale experiments in “A General Framework for Inference-time Scaling and Steering of Diffusion Models” by Singhal et al., where they show that these methods enable smaller models to outperform larger ones on real tasks like text-to-image generation.</p> <h2 id="setup-imports-and-utility-functions">Setup: Imports and Utility Functions</h2> <p>Let’s start by importing necessary libraries and defining utility functions:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># imports and util functions
</span><span class="kn">import</span> <span class="n">torch</span> 
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_checkerboard_2d</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">square_size</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high_prob</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">low_prob</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
                            <span class="n">x_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">y_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">max_attempts</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Generate 2D data points from a checkerboard distribution.
    </span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">max_attempts</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">max_attempts</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">n_samples</span>
    
    <span class="c1"># Normalize probabilities
</span>    <span class="n">max_prob</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">high_prob</span><span class="p">,</span> <span class="n">low_prob</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">checkerboard_density</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Calculate the probability density at point (x, y)</span><span class="sh">"""</span>
        <span class="c1"># Determine which square we're in
</span>        <span class="n">square_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">square_size</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">square_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">y</span> <span class="o">/</span> <span class="n">square_size</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="c1"># Checkerboard pattern: alternating high/low probability
</span>        <span class="n">is_white_square</span> <span class="o">=</span> <span class="p">(</span><span class="n">square_x</span> <span class="o">+</span> <span class="n">square_y</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">is_white_square</span><span class="p">,</span> <span class="n">high_prob</span><span class="p">,</span> <span class="n">low_prob</span><span class="p">)</span>
    
    <span class="n">points</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">attempts</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">while</span> <span class="nf">len</span><span class="p">(</span><span class="n">points</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span> <span class="ow">and</span> <span class="n">attempts</span> <span class="o">&lt;</span> <span class="n">max_attempts</span><span class="p">:</span>
        <span class="c1"># Generate random candidate points
</span>        <span class="n">batch_size</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">max_attempts</span> <span class="o">-</span> <span class="n">attempts</span><span class="p">)</span>
        <span class="n">x_candidates</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">x_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">y_candidates</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">y_range</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_range</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1"># Calculate densities
</span>        <span class="n">densities</span> <span class="o">=</span> <span class="nf">checkerboard_density</span><span class="p">(</span><span class="n">x_candidates</span><span class="p">,</span> <span class="n">y_candidates</span><span class="p">)</span>
        
        <span class="c1"># Rejection sampling
</span>        <span class="n">accept_probs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">accepted</span> <span class="o">=</span> <span class="n">accept_probs</span> <span class="o">&lt;</span> <span class="n">densities</span>
        
        <span class="c1"># Add accepted points
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">accepted</span><span class="p">)[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">points</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
                <span class="n">points</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">x_candidates</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_candidates</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
        
        <span class="n">attempts</span> <span class="o">+=</span> <span class="n">batch_size</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
</code></pre></div></div> <h2 id="flow-model-architecture">Flow Model Architecture</h2> <p>We’ll use a simple MLP-based flow model:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Flow</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">Simple MLP flow model</span><span class="sh">'''</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">net</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t_start</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t_end</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">'''</span><span class="s">Using midpoint Euler method</span><span class="sh">'''</span>
        <span class="n">t_start</span> <span class="o">=</span> <span class="n">t_start</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">expand</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_t</span> <span class="o">+</span> <span class="p">(</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">)</span> <span class="o">*</span> <span class="nf">self</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t_start</span> <span class="o">+</span> <span class="p">(</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> 
                                             <span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span> <span class="o">+</span> <span class="nf">self</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t_start</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <h2 id="1-training-the-flow-model">1. Training the Flow Model</h2> <p>We use \(x_0\) as noise, \(x_1\) as data and \(x_t \sim \mathcal{N}(x\mid\alpha_t x_1, \sigma_t^2 I)\).</p> <p>\(\alpha_t\) and \(\sigma_t\) need to satisfy:</p> <ul> <li> \[\alpha_1 = \sigma_0 = 1\] </li> <li> \[\alpha_0 = \sigma_1 = 0\] </li> </ul> <p>An optimal transport path will be used here, where:</p> <ul> <li> \[\alpha_t = t\] </li> <li> \[\sigma_t = 1-t\] </li> </ul> <p>The flow vector field is then: \(u_t = x_1 - x_0 = \frac{x_1 - x_t}{1 - t}\)</p> <p>The flow model takes in time \(t\) and noised sample \(x_t\) and predicts the flow vector field \(u_t\)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">flow</span> <span class="o">=</span> <span class="nc">Flow</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">flow</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="mf">1e-2</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)):</span>
    <span class="c1"># Generate data from checkerboard distribution
</span>    <span class="n">x_1</span> <span class="o">=</span> <span class="nc">Tensor</span><span class="p">(</span><span class="nf">generate_checkerboard_2d</span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> 
                                          <span class="n">square_size</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
                                          <span class="n">high_prob</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                          <span class="n">low_prob</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                          <span class="n">x_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                                          <span class="n">y_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x_1</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Create interpolated samples
</span>    <span class="n">x_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">x_1</span>
    <span class="n">dx_t</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">-</span> <span class="n">x_0</span>
    
    <span class="c1"># Train to predict the flow vector field
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="nf">loss_fn</span><span class="p">(</span><span class="nf">flow</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">),</span> <span class="n">dx_t</span><span class="p">).</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> <h2 id="2-basic-sampling">2. Basic Sampling</h2> <p>Once the model approximates the flow vector field \(\frac{dx_t}{dt} = u_t \approx u_t^{\theta}(x_t, t)\), we can start from random noise \(x_0\) and use Euler method to find \(x_1\) iteratively.</p> \[x_{t+h} = x_{t} + h u_t \approx x_{t} + h u_t^{\theta}(x_t, t)\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">t = </span><span class="si">{</span><span class="n">time_steps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t_start</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t_end</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">t = </span><span class="si">{</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig1-1400.webp"/> <img src="/assets/img/posts/scaling/fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure1: Evolution of samples from noise to data distribution over 8 steps]</strong></p> <h2 id="3-inference-time-scaling">3. Inference-Time Scaling</h2> <p>Note that here the model is unconditional and we cannot control the sampling using Euler’s method. However, there are scenarios where one wants to generate certain kind of data, achieving higher scores on some scoring functions. We will explore inference-time scaling with ODE sampler first and then explore inference-time steering toward some scoring functions.</p> <p>One simple way to do this is to generate a bunch of samples, and select best \(K\) out of those. This is trivially done but can be computationally expensive.</p> <h3 id="why-inference-time-scaling-works">Why Inference-Time Scaling Works</h3> <p>The key insight is that diffusion models define a mapping from noise to data, and by being strategic about:</p> <ol> <li><strong>Which noise we start from</strong> (zeroth-order search)</li> <li><strong>How we navigate the denoising path</strong> (search over paths)</li> <li><strong>When to commit computational resources</strong> (FK steering)</li> </ol> <p>We can significantly improve sample quality without any model changes. Think of it as finding better paths through the model’s learned landscape rather than changing the landscape itself.</p> <h3 id="31-zeroth-order-search">3.1 Zeroth Order Search</h3> <p>Another way is of similar concept by sampling the neighborhood of noises that generate good samples. Since the model and ODE is deterministic, the sample quality (or scores) is determined by the initial noise. The steps are as follows:</p> <ol> <li>Given a starting point <code class="language-plaintext highlighter-rouge">pivot</code> \(n\)</li> <li>Find \(N\) candidates in the pivot’s neighborhood: \(S_n^{\lambda} = \{y: d(y, n) &lt; \lambda\}\) where d is some distance metric</li> <li>Run these candidates through ODE and use a verifier/score function to compute the scores</li> <li>Find the best candidate, update pivot to be its starting point, and repeat 1-3 for \(n\) cycles.</li> </ol> <p>The scaling complexity is \(N\times n\times steps\).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">functools</span>

<span class="k">def</span> <span class="nf">flow_sample</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">150</span><span class="p">):</span> 
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">flow</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span> 
            <span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t_start</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t_end</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">verifier</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">
    High score for samples close to target point
    </span><span class="sh">'''</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">-</span> <span class="n">target</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">diff</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">line_verifier</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">
    High score for samples close to the line
    </span><span class="sh">'''</span>
    <span class="k">assert</span> <span class="n">tp</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">tp</span> <span class="o">==</span> <span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span> <span class="k">else</span> <span class="n">x_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">line</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">diff</span><span class="p">.</span><span class="nf">abs</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sample_around_point</span><span class="p">(</span><span class="n">center_x</span><span class="p">,</span> <span class="n">center_y</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">max_distance</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Generate n samples uniformly distributed within a circle of radius max_distance
    centered at point A(center_x, center_y).
    </span><span class="sh">"""</span>
    <span class="c1"># Generate random radii and angles
</span>    <span class="c1"># For uniform distribution on disk: r = sqrt(U) * max_radius
</span>    <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">radii</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_distance</span>
    
    <span class="c1"># Generate random angles [0, 2π)
</span>    <span class="n">angles</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">pi</span>
    
    <span class="c1"># Convert to Cartesian coordinates
</span>    <span class="n">x_offset</span> <span class="o">=</span> <span class="n">radii</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span>
    <span class="n">y_offset</span> <span class="o">=</span> <span class="n">radii</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span>
    
    <span class="c1"># Add to center point
</span>    <span class="n">samples</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span>
        <span class="n">center_x</span> <span class="o">+</span> <span class="n">x_offset</span><span class="p">,</span>
        <span class="n">center_y</span> <span class="o">+</span> <span class="n">y_offset</span>
    <span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">samples</span>

<span class="k">def</span> <span class="nf">sample_around_point_tensor</span><span class="p">(</span><span class="n">center_point</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">max_distance</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Alternative interface that takes center point as a tensor.
    </span><span class="sh">"""</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">center_point</span><span class="p">.</span><span class="n">device</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">center_point</span><span class="p">.</span><span class="n">dtype</span>
    
    <span class="k">return</span> <span class="nf">sample_around_point</span><span class="p">(</span>
        <span class="n">center_point</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">(),</span> 
        <span class="n">center_point</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">item</span><span class="p">(),</span> 
        <span class="n">n_samples</span><span class="p">,</span> 
        <span class="n">max_distance</span><span class="p">,</span> 
        <span class="n">device</span><span class="p">,</span> 
        <span class="n">dtype</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">inference_time_scaling_zeroth_search</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="n">sampling_fn</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">cycle</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">2048</span><span class="p">):</span> 
    <span class="n">samples</span><span class="p">,</span> <span class="n">noises</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">pvt</span> <span class="o">=</span> <span class="n">pivot</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">cycle</span><span class="p">):</span> 
        <span class="n">x_start</span> <span class="o">=</span> <span class="nf">sampling_fn</span><span class="p">(</span><span class="n">pvt</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="n">x_final</span> <span class="o">=</span> <span class="nf">flow_sample</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="nf">verify_fn</span><span class="p">(</span><span class="n">x_final</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="nf">argmax</span><span class="p">()</span>
        <span class="n">pvt</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">samples</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x_final</span><span class="p">.</span><span class="nf">cpu</span><span class="p">())</span>
        <span class="n">noises</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x_start</span><span class="p">.</span><span class="nf">cpu</span><span class="p">())</span>
    
    <span class="k">return</span> <span class="n">samples</span><span class="p">,</span> <span class="n">noises</span>

<span class="k">def</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span> 
    <span class="n">n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span> 
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">sample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sample</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">([</span><span class="n">pivot</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">()],</span> <span class="p">[</span><span class="n">pivot</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">item</span><span class="p">()],</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">([</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">()],</span> <span class="p">[</span><span class="n">target</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">item</span><span class="p">()],</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">'</span><span class="s">*</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">line</span> <span class="ow">and</span> <span class="n">tp</span><span class="p">:</span> 
            <span class="k">if</span> <span class="n">tp</span> <span class="o">==</span> <span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">:</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">hlines</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">vlines</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
    <span class="k">return</span> <span class="n">fig</span>
</code></pre></div></div> <p>Now let’s run experiments with different targets:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">pivot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">sampling_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">sample_around_point_tensor</span><span class="p">,</span> <span class="n">max_distance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1">## Target at (-2, -2)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">noises</span> <span class="o">=</span> <span class="nf">inference_time_scaling_zeroth_search</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="n">sampling_fn</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">cycle</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1">## Target at (0, 0)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">noises</span> <span class="o">=</span> <span class="nf">inference_time_scaling_zeroth_search</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="n">sampling_fn</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">cycle</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig2-1400.webp"/> <img src="/assets/img/posts/scaling/fig2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig3-1400.webp"/> <img src="/assets/img/posts/scaling/fig3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure2-3: Zeroth-order search results for different target points]</strong></p> <p>Now let’s try steering towards lines:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">77</span><span class="p">)</span>
<span class="n">line1</span><span class="p">,</span> <span class="n">line2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">line1</span><span class="p">,</span> <span class="n">line2</span> <span class="o">=</span> <span class="n">line1</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">line2</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">line1</span><span class="p">,</span> <span class="n">line2</span><span class="p">)</span>
<span class="n">sampling_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">sample_around_point_tensor</span><span class="p">,</span> <span class="n">max_distance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">pivot</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1">## Horizontal line
</span><span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">line_verifier</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line1</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">noises</span> <span class="o">=</span> <span class="nf">inference_time_scaling_zeroth_search</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="n">sampling_fn</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">cycle</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">[::</span><span class="mi">4</span><span class="p">],</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line1</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>

<span class="c1">## Vertical line
</span><span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">line_verifier</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line2</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">noises</span> <span class="o">=</span> <span class="nf">inference_time_scaling_zeroth_search</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="n">sampling_fn</span><span class="p">,</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">cycle</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">[::</span><span class="mi">4</span><span class="p">],</span> <span class="n">pivot</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line2</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig4-1400.webp"/> <img src="/assets/img/posts/scaling/fig4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig5-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig5-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig5-1400.webp"/> <img src="/assets/img/posts/scaling/fig5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure4-5: Zeroth-order search results for line targets]</strong></p> <h3 id="32-search-over-paths">3.2 Search over Paths</h3> <p>Previously, we search over initial noise. We can further do the search during the inference steps \(x_t\) by forward noising \(\Delta f\) for the good samples and then reverse \(\Delta b\). The process is the following:</p> <ol> <li>Sample \(N\) initial iid noises and run the ODE solver until some time \(t\). The noisy samples \(x_t\) serve as the search starting point.</li> <li>Sample \(M\) iid noises for each noisy samples \(x_t\), and simulate the forward noising process from \(t\) to \(t-\Delta f\) to produce \(x_{t-\Delta f}\) with size \(M\).</li> <li>Run ODE solver on each \(x_{t-\Delta f}\) to time \(t-\Delta f + \Delta b\), and obtain \(x_{t-\Delta f + \Delta b}\). Run verifiers on these samples and keep the top \(N\) candidates. Repeat steps 2-3 until \(t=1\)</li> <li>Run the remaining N samples through random search and keep the best one.</li> </ol> <p>The inference is reversing the noise, and here, we are doing <code class="language-plaintext highlighter-rouge">expand</code> -&gt; <code class="language-plaintext highlighter-rouge">forward</code> -&gt; <code class="language-plaintext highlighter-rouge">reverse</code> -&gt; <code class="language-plaintext highlighter-rouge">score</code> -&gt; <code class="language-plaintext highlighter-rouge">select</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">flow_simulate</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">step_size</span><span class="p">):</span> 
    <span class="k">assert</span> <span class="n">t_end</span> <span class="o">&gt;</span> <span class="n">t</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="n">device</span>
    
    <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">int</span><span class="p">((</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">flow</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span> 
            <span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t_start</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t_end</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">search_over_paths</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">t_start</span><span class="p">,</span> <span class="n">delta_f</span><span class="p">,</span> <span class="n">delta_b</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="n">step_size</span><span class="p">):</span> 
    <span class="c1"># delta_f and delta_b are on the time axis 
</span>    <span class="k">assert</span> <span class="n">delta_b</span> <span class="o">&gt;</span> <span class="n">delta_f</span> <span class="o">&gt;</span> <span class="n">step_size</span>
    <span class="k">assert</span> <span class="n">N</span> <span class="o">*</span> <span class="n">M</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">t_start</span> <span class="o">&gt;</span> <span class="mi">0</span>
    
    <span class="n">flow</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">flow</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
    
    <span class="n">x_hist</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># step 1: Sample N, simulate from 0 to t_start
</span>    <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x_t</span> <span class="o">=</span> <span class="nf">flow_simulate</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">t_start</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span> <span class="c1"># (N, 2)
</span>    
    <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">x_0</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()))</span>
    <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">t_start</span><span class="p">,</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()))</span>
    
    <span class="c1"># Step 2-3: Sample M from each x_t, forward to t-df, reverse to t-df+db
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">t_start</span>
    <span class="k">while</span> <span class="n">t</span> <span class="o">-</span> <span class="n">delta_f</span> <span class="o">+</span> <span class="n">delta_b</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span> 
        <span class="c1"># expand x_t and forward noise
</span>        <span class="n">x_t_df</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">repeat</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">delta_f</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">((</span><span class="n">M</span> <span class="o">*</span> <span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># reverse to t-df+db
</span>        <span class="n">x_t_df_db</span> <span class="o">=</span> <span class="nf">flow_simulate</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_t_df</span><span class="p">,</span> <span class="n">t</span> <span class="o">-</span> <span class="n">delta_f</span><span class="p">,</span> <span class="n">t</span> <span class="o">-</span> <span class="n">delta_f</span> <span class="o">+</span> <span class="n">delta_b</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>
        
        <span class="c1"># run verifier on noisy samples
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="nf">verify_fn</span><span class="p">(</span><span class="n">x_t_df_db</span><span class="p">)</span>
        
        <span class="c1"># pick top N and update x_t and t
</span>        <span class="n">top_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t_df_db</span><span class="p">[</span><span class="n">top_idx</span><span class="p">]</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">-</span> <span class="n">delta_f</span> <span class="o">+</span> <span class="n">delta_b</span>
        
        <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()))</span>
    
    <span class="c1"># push these N x_t to 1.0
</span>    <span class="n">x_final</span> <span class="o">=</span> <span class="nf">flow_simulate</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">x_final</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">x_hist</span>

<span class="k">def</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span> 
    <span class="n">n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span> 
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">sample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sample</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">([</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">item</span><span class="p">()],</span> <span class="p">[</span><span class="n">target</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">item</span><span class="p">()],</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">'</span><span class="s">*</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">line</span> <span class="ow">and</span> <span class="n">tp</span><span class="p">:</span> 
            <span class="k">if</span> <span class="n">tp</span> <span class="o">==</span> <span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">:</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">hlines</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">vlines</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">t = </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</code></pre></div></div> <p>Let’s run experiments with different targets:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Target at (0, 0)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="nf">search_over_paths</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># Target at (2.0, 0.5)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="nf">search_over_paths</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># Target at (-0.5, -0.5)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="nf">search_over_paths</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig6-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig6-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig6-1400.webp"/> <img src="/assets/img/posts/scaling/fig6.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure6: Search over paths results for different target points]</strong></p> <p>Line targets:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">77</span><span class="p">)</span>
<span class="n">line1</span><span class="p">,</span> <span class="n">line2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">line1</span><span class="p">,</span> <span class="n">line2</span> <span class="o">=</span> <span class="n">line1</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">line2</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">line1</span><span class="p">,</span> <span class="n">line2</span><span class="p">)</span>

<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">line_verifier</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line1</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="nf">search_over_paths</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line1</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>

<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">line_verifier</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line2</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="nf">search_over_paths</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.14</span><span class="p">,</span> <span class="n">verify_fn</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line2</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig7-1400.webp"/> <img src="/assets/img/posts/scaling/fig7.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure7: Search over paths results for line targets]</strong></p> <h3 id="33-feynman-kac-steering">3.3 Feynman-Kac Steering</h3> <p>Previously, we looked at ODE sampling. Here, we’ll look into the SDE sampling with Feynman-Kac steering, the most sophisticated approach based on rare-event simulation theory.</p> <h4 id="theoretical-foundation">Theoretical Foundation</h4> <p>Feynman-Kac (FK) steering is based on Feynman-Kac interacting particle systems (FK-IPS), a rare-event simulation method. The goal is to sample from a tilted distribution:</p> \[p_{\text{target}}(x_0|c) = \frac{1}{Z} p_\theta(x_0|c) \exp(\lambda r(x_0, c))\] <p>where \(r(x_0, c)\) is a reward function encoding desired properties. FK steering works by:</p> <ol> <li>Sampling multiple interacting diffusion processes (particles)</li> <li>Scoring particles using functions called potentials</li> <li>Resampling particles based on their potentials at intermediate steps</li> </ol> <p>The method defines a sequence of distributions \(p_{FK,t}(x_T, x_{T-1}, ..., x_t)\) by tilting the base distribution with potentials \(G_t\):</p> \[p_{FK,t}(x_T, ..., x_t|c) = \frac{1}{Z_t} p_\theta(x_T, ..., x_t|c) \prod_{s=T}^{t} G_s(x_T, ..., x_s, c)\] <p>The potentials must satisfy: \(\prod_{t=T}^{0} G_t(x_T, ..., x_t, c) = \exp(\lambda r(x_0, c))\)</p> <p>This ensures that sampling from \(p_{FK,0}\) produces samples from the target tilted distribution.</p> <h4 id="intuition-why-particle-based-methods-excel">Intuition: Why Particle-Based Methods Excel</h4> <p>FK steering leverages the power of particle-based methods for rare-event simulation. The key insight is that high-reward samples might be rare under the base model \(p_\theta(x_0)\), but by:</p> <ol> <li><strong>Running multiple particles in parallel</strong>: We explore different regions of the space</li> <li><strong>Resampling based on potentials</strong>: We focus compute on promising trajectories</li> <li><strong>Using intermediate rewards</strong>: We can identify good paths early and abandon poor ones</li> </ol> <p>This is fundamentally different from:</p> <ul> <li><strong>Best-of-N</strong>: Which wastes compute on full generation of poor samples</li> <li><strong>Gradient guidance</strong>: Which is limited to differentiable rewards and can get stuck in local optima</li> <li><strong>Fine-tuning</strong>: Which permanently changes the model for a single reward</li> </ul> <p>The particle-based approach adaptively allocates computational resources, similar to how evolution explores multiple mutations but only propagates successful ones.</p> <h4 id="sde-formulation">SDE Formulation</h4> <p>The SDE reverse sampling takes the form:</p> \[dx_t = v(x_t, t)dt - \frac{1}{2}\omega_ts(x_t, t) + \sqrt{\omega_t}dW_t\] <p>where \(v(x_t, t)\) is the flow vector field and \(s(x_t, t) = \nabla\log p_t(x)\) is the score. \(\omega_t\) is some time-dependent diffusion coefficient with \(\omega_1 = 0\). \(dW_t\) is a reverse-time Weiner process.</p> <p>If \(x_t \sim \mathcal{N}(x\mid\alpha_t x_1, \sigma_t^2 I)\), we have the relationship between flow \(v(x_t, t)\) and score \(s(x_t, t)\):</p> \[s(x_t, t) = \sigma_t^{-1}\frac{\alpha_tv(x_t, t) - \dot{\alpha_t}x}{\dot{\alpha_t}\sigma_t - \alpha_t\dot{\sigma_t}}\] <p>In the OT case where \(\alpha_t = t\) and \(\sigma_t = 1 - t\):</p> \[s(x_t, t) = \frac{tv(x_t, t) - x_t}{1-t}\] <p>We can pick \(\omega_t = k\sigma_t = k(1-t)\), which avoids numerical instability when \(t \rightarrow 1\) with \(0&lt;k&lt;1\) controls the stochasticity.</p> \[dx_t = \left[v(x_t, t) - \frac{k}{2}tv(x_t, t) + \frac{k}{2}x_t \right]dt + \sqrt{k(1-t)}dW_t\] <p>Notice that when \(k=0\), the SDE becomes ODE.</p> <p>First, let’s implement basic SDE sampling:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">flow_simple_stochastic</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">step_size</span><span class="p">):</span> 
    <span class="k">assert</span> <span class="n">t_end</span> <span class="o">&gt;</span> <span class="n">t</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="n">device</span>
    
    <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">int</span><span class="p">((</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">flow</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="n">x_hist</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span> 
            <span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t_start</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t_end</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="p">(</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="mf">0.5</span>
            <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_hist</span>

<span class="k">def</span> <span class="nf">flow_sde_reverse</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span> 
    <span class="k">assert</span> <span class="n">t_end</span> <span class="o">&gt;</span> <span class="n">t</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="n">device</span>
    
    <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">int</span><span class="p">((</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">flow</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="n">x_hist</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> 
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span> 
            <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">t1</span> <span class="o">=</span> <span class="n">t1</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">expand</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">=</span> <span class="nf">flow</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t1</span> <span class="o">+</span> <span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">x</span> <span class="o">+</span> <span class="nf">flow</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">k</span> <span class="o">*</span> <span class="n">t1</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">k</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">+=</span> <span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">t1</span><span class="p">))</span> <span class="o">**</span> <span class="mf">0.5</span>
            <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">())</span>
            
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_hist</span>
</code></pre></div></div> <p>Compare stochastic vs deterministic sampling:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">((</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">xhis_1</span> <span class="o">=</span> <span class="nf">flow_simple_stochastic</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">xhis_2</span> <span class="o">=</span> <span class="nf">flow_sde_reverse</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">xhis_1</span><span class="p">[::</span><span class="mi">10</span><span class="p">],</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">xhis_2</span><span class="p">[::</span><span class="mi">10</span><span class="p">],</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig8-1400.webp"/> <img src="/assets/img/posts/scaling/fig8.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig9-1400.webp"/> <img src="/assets/img/posts/scaling/fig9.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure8-9: Comparison of simple stochastic vs SDE reverse sampling]</strong></p> <p>Now the full Feynman-Kac steering implementation:</p> <h4 id="potential-functions-and-their-roles">Potential Functions and Their Roles</h4> <p>FK steering uses different types of potentials that score particles using intermediate rewards \(r_\phi(x_t)\):</p> <ol> <li><strong>DIFFERENCE</strong>: \(G_t(x_t, x_{t+1}) = \exp(\lambda(r_\phi(x_t) - r_\phi(x_{t+1})))\) <ul> <li>Prefers particles with increasing rewards</li> <li>Similar to what Twisted Diffusion Sampler (TDS) uses</li> <li>Can assign low scores to particles that reach maximum reward early</li> </ul> </li> <li><strong>MAX</strong>: \(G_t(x_T, ..., x_t) = \exp(\lambda \max_{s=t}^T r_\phi(x_s))\) <ul> <li>Prefers particles with highest rewards seen so far</li> <li>Better for bounded rewards</li> <li>May reduce diversity compared to difference potential</li> </ul> </li> <li><strong>SUM</strong>: \(G_t(x_T, ..., x_t) = \exp(\lambda \sum_{s=t}^T r_\phi(x_s))\) <ul> <li>Selects particles with highest accumulated rewards</li> <li>Balances between current and historical performance</li> </ul> </li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">Feyman_Kac_Steering</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="n">n_particles</span><span class="p">,</span> 
                        <span class="n">resampling_t_start</span><span class="p">,</span> <span class="n">resampling_t_end</span><span class="p">,</span> <span class="n">n_resampling</span><span class="p">,</span> 
                        <span class="n">step_size</span><span class="p">,</span> <span class="n">reward_fn</span><span class="p">,</span> <span class="n">potential_tp</span><span class="p">,</span> <span class="n">lmbda</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">resampling_t_start</span> <span class="o">&lt;</span> <span class="n">resampling_t_end</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="k">assert</span> <span class="n">potential_tp</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">flow</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
    
    <span class="c1"># Setup resampling schedule
</span>    <span class="n">n_steps</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">resampling_idx_start</span> <span class="o">=</span> <span class="p">(</span><span class="n">time_steps</span> <span class="o">-</span> <span class="n">resampling_t_start</span><span class="p">).</span><span class="nf">abs</span><span class="p">().</span><span class="nf">argmin</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
    <span class="n">resampling_idx_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">time_steps</span> <span class="o">-</span> <span class="n">resampling_t_end</span><span class="p">).</span><span class="nf">abs</span><span class="p">().</span><span class="nf">argmin</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
    <span class="n">resampling_idx_step</span> <span class="o">=</span> <span class="nf">int</span><span class="p">((</span><span class="n">resampling_idx_end</span> <span class="o">-</span> <span class="n">resampling_idx_start</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_resampling</span><span class="p">)</span>
    <span class="n">resampling_idx_step</span> <span class="o">+=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">resampling_idx_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">resampling_idx</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">resampling_idx_start</span><span class="p">,</span> <span class="n">resampling_idx_end</span><span class="p">,</span> <span class="n">resampling_idx_step</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">resampling steps =</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">resampling_idx</span><span class="p">))</span>
    
    <span class="c1"># init the x and potential
</span>    <span class="n">x_hist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">x_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">((</span><span class="n">n_particles</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()))</span>
    <span class="n">product_of_potentials</span><span class="p">,</span> <span class="n">population_rs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">n_particles</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">n_particles</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">time_steps</span><span class="p">):</span> 
        <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span> <span class="k">break</span>
        
        <span class="c1"># compute score and FK-Resampling
</span>        <span class="k">if</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">resampling_idx</span><span class="p">:</span> 
            <span class="n">rs_candidates</span> <span class="o">=</span> <span class="nf">reward_fn</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span>
            
            <span class="c1"># Compute importance weights based on potential type
</span>            <span class="k">if</span> <span class="n">potential_tp</span> <span class="o">==</span> <span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">lmbda</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">rs_candidates</span><span class="p">,</span> <span class="n">population_rs</span><span class="p">))</span>
            <span class="k">elif</span> <span class="n">potential_tp</span> <span class="o">==</span> <span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">rs_candidates</span> <span class="o">=</span> <span class="n">rs_candidates</span> <span class="o">+</span> <span class="n">population_rs</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">lmbda</span> <span class="o">*</span> <span class="n">rs_candidates</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">potential_tp</span> <span class="o">==</span> <span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">diffs</span> <span class="o">=</span> <span class="n">rs_candidates</span> <span class="o">-</span> <span class="n">population_rs</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">lmbda</span> <span class="o">*</span> <span class="n">diffs</span><span class="p">)</span>
            
            <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">clamp</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1e10</span><span class="p">)</span>
            <span class="n">w</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">w</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
            
            <span class="c1"># Resample indices based on weights
</span>            <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">multinomial</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">n_particles</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="n">population_rs</span> <span class="o">=</span> <span class="n">rs_candidates</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

            <span class="c1"># Update product of potentials; used for max and add potentials
</span>            <span class="n">product_of_potentials</span> <span class="o">=</span> <span class="p">(</span><span class="n">product_of_potentials</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">*</span> <span class="n">w</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>
            
        <span class="c1"># reverse / propose
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">tt</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">expand</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">=</span> <span class="nf">flow</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">tt</span> <span class="o">+</span> <span class="n">step_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span> <span class="o">+</span> <span class="nf">flow</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">tt</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">x_t</span> <span class="o">+=</span> <span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">k</span> <span class="o">*</span> <span class="n">tt</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">k</span> <span class="o">*</span> <span class="n">x_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_size</span>
            <span class="n">x_t</span> <span class="o">+=</span> <span class="n">step_size</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_t</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">k</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">tt</span><span class="p">))</span> <span class="o">**</span> <span class="mf">0.5</span>

        <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">t</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()))</span>
    
    <span class="c1"># final step
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> 
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t_start</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">t_end</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">x_hist</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">x_t</span><span class="p">.</span><span class="nf">cpu</span><span class="p">()))</span>
    
    <span class="k">return</span> <span class="n">x_hist</span>
</code></pre></div></div> <p>Now let’s run experiments with different potential types:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Target at (0, 0)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>

<span class="k">for</span> <span class="n">tp</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">]:</span> 
    <span class="nf">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="nc">Feyman_Kac_Steering</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> 
                            <span class="n">resampling_t_start</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">resampling_t_end</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">n_resampling</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                            <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">reward_fn</span><span class="o">=</span><span class="n">verify_fn</span><span class="p">,</span> <span class="n">potential_tp</span><span class="o">=</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">[::</span><span class="mi">15</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig10-1400.webp"/> <img src="/assets/img/posts/scaling/fig10.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure10: FK steering with different potential types for target (0, 0)]</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Target at (2.0, 0.5)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>

<span class="k">for</span> <span class="n">tp</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">]:</span> 
    <span class="nf">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="nc">Feyman_Kac_Steering</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> 
                            <span class="n">resampling_t_start</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">resampling_t_end</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">n_resampling</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                            <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">reward_fn</span><span class="o">=</span><span class="n">verify_fn</span><span class="p">,</span> <span class="n">potential_tp</span><span class="o">=</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">[::</span><span class="mi">15</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig11-1400.webp"/> <img src="/assets/img/posts/scaling/fig11.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure11: FK steering with different potential types for target (2.0, 0.5)]</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Target at (-0.5, -0.5)
</span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">verifier</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>

<span class="k">for</span> <span class="n">tp</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">]:</span> 
    <span class="nf">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="nc">Feyman_Kac_Steering</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> 
                            <span class="n">resampling_t_start</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">resampling_t_end</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">n_resampling</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                            <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">reward_fn</span><span class="o">=</span><span class="n">verify_fn</span><span class="p">,</span> <span class="n">potential_tp</span><span class="o">=</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">[::</span><span class="mi">15</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig12-1400.webp"/> <img src="/assets/img/posts/scaling/fig12.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure12: FK steering with different potential types for target (-0.5, -0.5)]</strong></p> <p>Line targets:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">77</span><span class="p">)</span>
<span class="n">line1</span><span class="p">,</span> <span class="n">line2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">line1</span><span class="p">,</span> <span class="n">line2</span> <span class="o">=</span> <span class="n">line1</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="n">line2</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">line1</span><span class="p">,</span> <span class="n">line2</span><span class="p">)</span>

<span class="c1"># Horizontal line
</span><span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">line_verifier</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line1</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tp</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">]:</span> 
    <span class="nf">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="nc">Feyman_Kac_Steering</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> 
                            <span class="n">resampling_t_start</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">resampling_t_end</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">n_resampling</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                            <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">reward_fn</span><span class="o">=</span><span class="n">verify_fn</span><span class="p">,</span> <span class="n">potential_tp</span><span class="o">=</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">[::</span><span class="mi">15</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line1</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">horizontal</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Vertical line
</span><span class="n">verify_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">line_verifier</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line2</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">tp</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">add</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">diff</span><span class="sh">'</span><span class="p">]:</span> 
    <span class="nf">print</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="nc">Feyman_Kac_Steering</span><span class="p">(</span><span class="n">flow</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> 
                            <span class="n">resampling_t_start</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">resampling_t_end</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">n_resampling</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                            <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">reward_fn</span><span class="o">=</span><span class="n">verify_fn</span><span class="p">,</span> <span class="n">potential_tp</span><span class="o">=</span><span class="n">tp</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="nf">plot_samples_with_time</span><span class="p">(</span><span class="n">samples</span><span class="p">[::</span><span class="mi">15</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">target</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="n">line2</span><span class="p">,</span> <span class="n">tp</span><span class="o">=</span><span class="sh">'</span><span class="s">vertical</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig13-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig13-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig13-1400.webp"/> <img src="/assets/img/posts/scaling/fig13.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/scaling/fig14-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/scaling/fig14-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/scaling/fig14-1400.webp"/> <img src="/assets/img/posts/scaling/fig14.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><strong>[Figure13-14: FK steering with different potential types for line targets]</strong></p> <h2 id="key-insights-and-conclusions">Key Insights and Conclusions</h2> <h3 id="comprehensive-comparison-of-the-three-approaches">Comprehensive Comparison of the Three Approaches</h3> <table border="1"> <thead> <tr> <th>Method</th> <th>Search Space</th> <th>Exploration Strategy</th> <th>Computational Cost</th> <th>Key Advantage</th> <th>Best Use Case</th> </tr> </thead> <tbody> <tr> <td>Zeroth-order</td> <td>Initial noise only</td> <td>Local neighborhood search</td> <td>Low: O(N × n × steps)</td> <td>Simple to implement</td> <td>Quick improvements with simple rewards</td> </tr> <tr> <td>Search over paths</td> <td>Intermediate states</td> <td>Branch and prune</td> <td>Medium: O(N × M × steps)</td> <td>Dynamic adaptation</td> <td>Exploring diverse generation paths</td> </tr> <tr> <td>FK Steering</td> <td>Full trajectory</td> <td>Particle resampling with potentials</td> <td>Medium-High</td> <td>Principled probabilistic framework</td> <td>Complex rewards, theoretical guarantees</td> </tr> </tbody> </table> <h3 id="connection-to-existing-methods">Connection to Existing Methods</h3> <p>FK steering provides a unified framework that generalizes several existing approaches:</p> <ul> <li><strong>Twisted Diffusion Sampler (TDS)</strong>: Special case using difference potential and gradient guidance</li> <li><strong>Soft Value-based Decoding (SVDD)</strong>: Special case using nested importance sampling</li> <li><strong>Best-of-N</strong>: Can be seen as FK steering with resampling only at the final step</li> </ul> <h3 id="practical-considerations">Practical Considerations</h3> <h4 id="choosing-the-right-method">Choosing the Right Method</h4> <ol> <li><strong>Use Zeroth-order search when</strong>: <ul> <li>Computational budget is limited</li> <li>Reward function is simple (e.g., distance to target)</li> <li>Quick improvements are needed</li> </ul> </li> <li><strong>Use Search over paths when</strong>: <ul> <li>Need to explore diverse generation paths</li> <li>Intermediate states provide useful signal</li> <li>Have moderate computational budget</li> </ul> </li> <li><strong>Use FK Steering when</strong>: <ul> <li>Need principled sampling from complex reward distributions</li> <li>Working with bounded rewards (use MAX potential)</li> <li>Require theoretical guarantees</li> <li>Can afford resampling overhead</li> </ul> </li> </ol> <h3 id="key-takeaways">Key Takeaways</h3> <p>The success of these methods suggests that inference-time compute may be as valuable as model scale, opening new possibilities for efficient and controllable generation. As the field advances, we may see inference-time scaling become a standard tool alongside model architecture and training data improvements.</p> <h3 id="future-directions">Future Directions</h3> <ul> <li><strong>Adaptive particle allocation</strong>: Dynamically adjust particles based on task difficulty</li> <li><strong>Learned potentials</strong>: Train intermediate reward models for better guidance</li> <li><strong>Hybrid approaches</strong>: Combine FK steering with fine-tuning for further gains</li> <li><strong>New applications</strong>: Protein design, code generation, and other domains</li> </ul> <p>The Feynman-Kac framework bridges diffusion models with rare-event simulation, providing a principled path toward more controllable and efficient generative AI.</p>]]></content><author><name></name></author><category term="models"/><category term="reading"/><category term="generating"/><category term="coding"/><summary type="html"><![CDATA[Inference time scaling for diffusion models, from search to steering]]></summary></entry><entry><title type="html">Playing with Generative Flow Matching Model</title><link href="https://jipq6175.github.io/blog/2025/flow_matching_1/" rel="alternate" type="text/html" title="Playing with Generative Flow Matching Model"/><published>2025-01-29T21:09:00+00:00</published><updated>2025-01-29T21:09:00+00:00</updated><id>https://jipq6175.github.io/blog/2025/flow_matching_1</id><content type="html" xml:base="https://jipq6175.github.io/blog/2025/flow_matching_1/"><![CDATA[<p>Previously, we were playing with score-based diffusion model, which generates data from noise prior by predicting the scores, \(\nabla_x\log p(x)\), and trained using forward SDE. Flow-based model, on the other hand, generates the data by predicting the flow vector fields that warps any prior distribution to the unknown data distribution and is a more general formalism and easier to train in practice. I will explore flow matching in 2 parts, continuous and discrete.</p> <p>In the continuous case, flow matching model aims to construct a time-dependent vector field \(v: [0, 1] \times \mathbf{R}^d \to \mathbf{R}^d\) to reshape a simple (or known sample-able) prior distribution \(p_0\) into a more complicated and unknown distribution \(p_1\). Typically, \(p_0\) and \(p_1\) are noise and data distributions respectively but \(p_0\) can actually be any prior. We let \(p_t(x)\) be the probability density path at time \(t\) and \(u_t(x)\) be the corresponding vector field, which generates \(p_t(x)\). Once we know \(u_t(x)\), we can generate a sample from prior \(x_0\), use \(u_0(x_0)\) to find \(x_t\) and use \(u_t(x_t)\) to find \(x_{2t}\) etc until we recover the data \(x_1\). So the flow matching objective is</p> \[\mathcal{L}_{FM}(\theta) = \mathbf{E}_{t,p_t(x)}||v_{t, \theta}(x) - u_t(x)||^2\] <p>where \(v_{t, \theta}(x)\) is a neural network regressing on the flow vector field \(u_t(x)\) at all time \(t\).</p> <p>We don’t have a close form of \(u_t\) but we can construct \(p_t\) and \(u_t\) <strong>per sample</strong> \(x_1 \sim q(x_1) \sim p_1\) (conditioned on a data sample), i.e. the conditional probability path \(p_t(x|x_1)\) will satisfy the following conditions at the boundaries of time: \(t=0\) and \(t=1\)</p> <ul> <li> \[p_0(x|x_1) \sim \text{prior or noise} \sim p_0(x) \sim \mathcal{N}(x|0, I)\] </li> <li> \[p_1(x|x_1) \sim \delta(x_1) \sim \mathcal{N}(x|x_1, \sigma^2I), \sigma\approx0\] </li> </ul> <p>From these conditional probability endpoints, we can construct conditional probability path \(p_t(x|x_1)\) and conditional vector field \(u_t(x|x_1)\). The conditional flow matching objective is then</p> \[\mathcal{L}_{CFM}(\theta) = \mathbf{E}_{t, q(x_1), p_t(x|x1)}||v_{t,\theta}(x) - u_t(x|x_1)||^2\] <p>where \(v_{t, \theta}(x)\) is a neural network. Previous work has shown that these 2 objectives or loss functions are equivalent in the sense that optimizing them will result in the same weight, or they have the same gradient, i.e.</p> \[\nabla_\theta \mathcal{L}_{FM}(\theta) = \nabla_\theta \mathcal{L}_{CFM}(\theta)\] <p><br/></p> <p>At training time, given \(p_0\) and training data from \(p_1\), we do the following:</p> <ol> <li>Sample \(t\in[0, 1]\)</li> <li>Sample data point \(x_1\sim p_1(x) \sim q(x)\)</li> <li>Sample \(x \sim p_t(x \mid x_1)\)</li> <li>Compute corresponding conditional vector field \(u_t(x \mid x_1)\)</li> <li>Use neural network \(v_{t,\theta}(x)\) to regress on the conditional vector field.</li> </ol> <p><br/></p> <p>So what is this conditional probability path \(p_t(x \mid x_1)\) and conditional vector field \(u_t(x \mid x_1)\)?</p> <p>The conditional flow matching objective works with <strong>ANY</strong> choice of conditional path and conditional vector field. One way to construct \(p_t(x \mid x_1)\) is to use Gaussian distribution with time-varying mean and variances:</p> \[p_t(x \mid x_1) = \mathcal{N}(x \mid \mu_t(x_1), \sigma_t(x_1)^2 I)\] <p>where \(\mu_t(x_1)\) satisfies</p> \[\begin{align*} \mu_0(x_1) = 0 \\ \mu_1(x_1) = x_1 \end{align*}\] <p>and \(\sigma_t(x_1)\) satisfies</p> \[\begin{align*} \sigma_0(x_1) = 1 \\ \sigma_1(x_1) = \sigma_{min} \end{align*}\] <p>And the unique vector field we are trying to regress to is</p> \[u_t(x \mid x_1) = \frac{\sigma'_t(x_1)}{\sigma_t(x_1)}[x - \mu_t(x_1)] + \mu'_t(x_1)\] <p>If we <strong>choose</strong> or <strong>design</strong> the conditional probability path to be Gaussian, then we can easily sample \(p_t(x \mid x_1)\) and \(u_t(x \mid x_1)\) will have exact form. Other formulations of \(p_t(x \mid x_1)\) will also work but might not have easy-to-compute \(u_t(x \mid x_1)\). Let’s look at some examples.</p> <p><br/></p> <h4 id="example-1-diffusion-conditional-vector-fields">Example 1: Diffusion Conditional Vector Fields</h4> <p>In the previous diffusion post, I looked into the variance exploding (VE), variance preserving (VP) and sub-VP SDEs, mapping from data to noise distributions.</p> <ol> <li>VE conditional path</li> </ol> <p>For VE, we kept adding noise until the signal got destroyed:</p> \[p_t(x|x_1) = \mathcal{N}(x|x_1, \sigma_{1-t}^2I)\] <p>The conditional vector field is then</p> \[u_t(x|x_1) = -\frac{\sigma'_{1-t}}{\sigma_{1-t}}(x-x_1)\] <ol> <li>VP conditional path</li> </ol> <p>For VP, while addiing noise, we also attenuate the signal:</p> \[p_t(x|x_1) = \mathcal{N}(x|\alpha_{1-t}x_1, (1 - \alpha_{1-t}^2)I)\] <p>The conditional vector field is then:</p> \[u_t(x|x_1) = \frac{\alpha_{1-t}'}{1 - \alpha_{1-t}^2}(\alpha_{1-t}x - x_1)\] <p>Note that this \(\alpha_t\) is decreasing with time \(t\) and parametrized by \(\beta(s)\):</p> \[\alpha_t = e^{-\frac{1}{2}\int_0^t\beta(s)ds}\] <p><br/></p> <h4 id="example-2-optimal-transport-conditional-vector-fields">Example 2: Optimal Transport Conditional Vector Fields</h4> <p>One natural choice for this conditional probability path is to to define mean and std to be linear in time:</p> \[\mu_t(x|x_1) = tx_1\] \[\sigma_t(x|x_1) = 1 - (1 - \sigma_{min})t\] <p>The the conditional vector field is then:</p> \[u_t(x|x_1) = \frac{x_1 - (1 - \sigma_{min})x}{1 - (1 - \sigma_{min})t}\] <p><br/></p> <p>So far, the conditional probability path and conditional vector field are conditioned on the data \(x_1\) , which is similar to the setup of diffusion modeling. However, the conditioning variable can be general, \(z = (x_1)\) or \(z = (x_1, x_0)\) by coupling the samples of prior and data distribution:</p> \[q(z) = q(x_0, x_1)\] <p><br/></p> <h4 id="example-3-independent-cfm">Example 3: Independent CFM</h4> <p>For independent coupling, \(x_0\) and \(x_1\) are independent:</p> \[q(z) = q(x_0)q(x_1) = p_0(x_0)p_1(x_1)\] <p>We can use a simple choice of conditional probability path:</p> \[p_t(x|z) = p_t(x|x_0, x_1) = \mathcal{N}(x| tx_1+(1-t)x_0, \sigma^2)\] <p>For this case</p> \[\begin{align*} \mu_t(z) = \mu_t(x_0, x_1) = tx_1 + (1-t)x_0 \\ \sigma_t(z) = \sigma_t(x_0, x_1) = \sigma^2 \end{align*}\] <p>Then the conditional vector field is then:</p> \[u_t(x|z) = u_t(x|x_0, x_1) = x_1 - x_0\] <p>which is the simplest form of flow matching and is quite neat.</p> <p>The following is the sample code snippet that shapes a Gaussian noisy distribution \(p_0\) into a data distribution \(p_1\), which is a moon distribution.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Imports
</span><span class="kn">import</span> <span class="n">torch</span> 
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>

<span class="c1">## Flow class
</span><span class="k">class</span> <span class="nc">Flow</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
 
    <span class="c1"># This is v_{t, \theta}(x) that regress the vector field u_t
</span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">net</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="c1"># This is for midpoint sampling and we will take a look later
</span>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t_start</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t_end</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">t_start</span> <span class="o">=</span> <span class="n">t_start</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">expand</span><span class="p">(</span><span class="n">x_t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x_t</span> <span class="o">+</span> <span class="p">(</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">)</span> <span class="o">*</span> <span class="nf">self</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t_start</span> <span class="o">+</span> <span class="p">(</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span> <span class="n">x_t</span> <span class="o">+</span> <span class="nf">self</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t_start</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t_end</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
        
<span class="c1">## Training
</span><span class="n">flow</span> <span class="o">=</span> <span class="nc">Flow</span><span class="p">()</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">flow</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="mf">1e-2</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
		
		<span class="c1"># Sample t \in [0, 1]
</span>		<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">x_1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># sample x_1 ~ q
</span>    <span class="n">x_1</span> <span class="o">=</span> <span class="nc">Tensor</span><span class="p">(</span><span class="nf">make_moons</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="c1"># sample x_0 ~ p
</span>    <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>
    
    <span class="c1"># compute x_t given sigma_t = 0
</span>    <span class="n">x_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">x_1</span>
    
    <span class="c1"># compute vector field u_t
</span>    <span class="n">dx_t</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">-</span> <span class="n">x_0</span>
    
    <span class="c1"># regress on the vector field
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="nf">loss_fn</span><span class="p">(</span><span class="nf">flow</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="n">x_t</span><span class="p">),</span> <span class="n">dx_t</span><span class="p">).</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
</code></pre></div></div> <p><br/> What about sampling?</p> <p>Once we get or approximate the ground truth vector field \(u_t(x_t \mid z)\) we can used it to transform a sampled point anywhere and if we do this iteratively (integrate) from \(t=0\) to \(t=1\), we can recover the data. This can be done using any ODE solver like RK or Euler methods etc.</p> <p>In the <code class="language-plaintext highlighter-rouge">Flow.step</code> function of above code, we used the midpoint method. Say we have an odinary differential equation:</p> \[y'(t) = f(t, y(t)); y(t_0) = y_0\] <p>We can use the first order approximation to find \(y(t_0+\Delta t)\):</p> \[y(t_0+\Delta t) = y(t_0) + \Delta ty'(t_0)\] <p>This can be better approximated using the derivative at the midpoint, namely \(y’(t_0 + \frac{\Delta t}{2})\):</p> \[y(t_0 + \Delta t) = y(t_0) + \Delta ty'(t_0 + \frac{\Delta t}{2}) = y(t_0) + \Delta tf(t_0 + \frac{\Delta t}{2}, y(t_0+\frac{\Delta t}{2}))\] <p>And the midpoint can be computed</p> \[y(t_0 + \frac{\Delta t}{2}) = \frac{1}{2}(y(t_0) + y(t_0 + \Delta t))\] <p>But we’re now trying to find \(y(t_0+\Delta t)\). So we need to approximate the midpoint using first order:</p> \[y(t_0 + \frac{\Delta t}{2}) = y(t_0) + \frac{\Delta t}{2}y'(t_0) = y(t_0) + \frac{\Delta t}{2}f(t_0, y(t_0))\] <p>Finally, we have</p> \[y(t_0 + \Delta t) = y(t_0) + \Delta tf(t_0 + \frac{\Delta t}{2}, y(t_0) + \frac{\Delta t}{2}f(t_0, y(t_0)))\] <p>So for our samples at \(t\), \(x_t\) given \(u_t(x_t)\)</p> \[x_{t+dt} = x_t + u_{t+dt/2}\left(x_t + \frac{dt}{2}u_t(x_t)\right)\] <p>For sampling:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
		<span class="c1"># the distribution path gor pushed forward &lt;-&gt; The data x got transformed by flow
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">x_t</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t_start</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t_end</span><span class="o">=</span><span class="n">time_steps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div></div> <p><br/></p> <h4 id="example-4-minibatch-optimal-transport-cfm">Example 4: Minibatch Optimal Transport CFM</h4> <p>Typically these flow matching (or diffusion) models are trained using minibatch:</p> <ol> <li>Sample time \(t\in [0, 1]\)</li> <li>Sample data \(x_1 \sim p_1 \sim q\) and \(x_0\sim p_0\)</li> <li>Compute the noised data \(x_t\) in terms of \(x_0\) and \(x_1\)</li> <li>Use the model \(f_{t,\theta}(x_t)\) to regress on the flow vector fields, noises or scores, etc.</li> </ol> <p>The issue for the flow matching model is that these flow vector fields might cross if we sample randomly from \(p_0\) and \(p_1\). This means that at a given noised data \(x_t\) there might exist <strong>NON-UNIQUE</strong> flow vector field \(u_t(x_t \mid x_0,x_1)\), making the training difficult because the neural net model is one-to-one. It can be mitigated by re-shuffling the minibatch samples via optimal transport.</p> <p>So at train time we do the following:</p> <ol> <li>Sample \(t\in[0,1]\)</li> <li>Sample data point \(x_1\sim q(x) = p_1(x)\)</li> <li>Sample data point \(x_0 \sim p_0(x)\)</li> <li><strong>Reshuffle / rearrange minibatch via optimal transport</strong></li> <li>Sample \(x_t \sim p_t(x \mid x_0, x_1)\)</li> <li>Compute corresponding vector field \(u_t(x_t \mid x_0, x_1)\)</li> <li>Use neural network \(v_{t,\theta}(x_t)\) to regress on the vector field \(u_t(x_t \mid x_0, x_1)\)</li> </ol> <p><br/></p> <h4 id="example-5-schrodinger-bridge">Example 5: Schrodinger Bridge</h4> <p>The Schrodinger Bridge is trying to vary the conditional variance in the conditional probability path, \(\sigma_t(z) = \sigma_t(x_0, x_1)\) such that \(p_0\) and \(p_1\) respect the prior/data distributions more faithfully.</p> \[\begin{align*} \mu_t(x_0, x_1) = tx_1 + (1-t)x_0 \\ \sigma_t(x_0, x_1) = \sqrt{t(1-t)}\sigma \end{align*}\] <p>Then the conditional vector field is then:</p> \[u_t(x|z) = u_t(x|x_0, x_1) = \frac{1-2t}{2t(1-t)}\left[ x-(tx_1 + (1-t)x_0) \right] + (x_1 - x_0)\] <p>It is also possible to train flow and score models at the same time, which is the <code class="language-plaintext highlighter-rouge">SF2M</code> model, generating stochastic trajectories in the sampling.</p> <p><br/></p> <p>Likelihood calculation?</p> <p>One benefit of using flow generative model is that they allow the tractable computation of the <strong>EXACT</strong> likelihood \(\log{p_1(x)}\) for all \(x\). Start from the flow ODE:</p> \[\frac{d}{dt}\psi_t(x) = u_t(\psi_t(x)); \psi_0(x) = x\] <p>We can use the <code class="language-plaintext highlighter-rouge">instantaneous change of variable theorem</code>:</p> <p>Let \(\mathbf{z}(t)\) be finite continuous random variable with probability \(p(\mathbf{z}(t))\) dependent on time. Let</p> \[\frac{d\mathbf{z}}{dt} = f(\mathbf{z}(t), t)\] <p>be an ODE that describe a time-dependent transformation. Then the the log likelihood of \(\mathbf{z}\) follows the ODE:</p> \[\frac{\partial \log{p(\mathbf{z}(t))}}{\partial t} = -\text{tr}\left[\frac{d\mathbf{f}}{d\mathbf{z(t)}} \right] = -(\nabla\cdot\mathbf{f})(\mathbf{z}(t))\] <p>Here \(\mathbf{z} \in \mathbf{R}^d\), \(p: \mathbf{R}^d \to \mathbf{R}\), \(\mathbf{f}: \mathbf{R}^d \times t \to \mathbf{R}^d\).</p> \[\mathbf{f}(z_1, z_2, ..., z_d, t) = (f_1, f_2, ..., f_d)\] \[\frac{d\mathbf{f}}{d\mathbf{z}} = \begin{bmatrix} \frac{\partial f_1}{\partial z_1} &amp; \frac{\partial f_1}{\partial z_2} &amp; \frac{\partial f_1}{\partial z_3} &amp; \dots &amp; \frac{\partial f_1}{\partial z_d} \\ \frac{\partial f_2}{\partial z_1} &amp; \frac{\partial f_2}{\partial z_2} &amp; \frac{\partial f_2}{\partial z_3} &amp; \dots &amp; \frac{\partial f_2}{\partial z_d} \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_d}{\partial z_1} &amp; \frac{\partial f_3}{\partial z_2} &amp; \frac{\partial f_d}{\partial z_3} &amp; \dots &amp; \frac{\partial f_d}{\partial z_d} \end{bmatrix}\] <p>Now \(\mathbf{f} \to u_t\) and \(\mathbf{z} \to \psi_t(x)\) we have</p> \[\frac{\partial \log p_t(\psi_t(x))}{\partial t} = -\text{tr}\left[\frac{\partial u_t}{\partial x}(\psi_t(x)) \right] = -(\nabla\cdot u_t)(\psi_t(x))\] <p>The divergence can be computed using the Hutchinson’s trace estimator</p> \[\text{tr}(M) = \mathbf{E}_Z\text{tr}[Z^TMZ]\] <p>where \(\mathbf{E}[Z]=0\) and \(\text{Cov}(Z, Z) = I\) for a fixed sample of \(Z\).</p> <p>Let’s call \(\psi_t(x) = f(t)\) and \(\log{p_t(\psi_t(x))} = g(t)\) and we have access to \(u_t\). Computing an unbiased estimate of \(\log{p_1(x)}\) involves simulating the following set of ODEs back in time:</p> \[\begin{align} \frac{df}{dt} = u_t(f(t)) \\ \frac{dg}{dt} = -\text{tr}\left[Z^T\frac{\partial u_t}{\partial x}(f(t)) Z \right] \end{align}\] <p>with \(f(1) = x\) and \(g(1) = 0\)</p> \[\log{p_1(x)} = \log{p_0(f(0))} - g(0)\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_likelihood</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">x_1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">log_p0</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">step_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">euler</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">atol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">time_grid</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span>
        <span class="n">return_intermediates</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="n">exact_divergence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="n">enable_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">model_extras</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]]:</span>
        <span class="sa">r</span><span class="sh">"""</span><span class="s">Solve for log likelihood given a target sample at :math:`t=0`.

        Works similarly to sample, but solves the ODE in reverse to compute the log-likelihood. The velocity model must be differentiable with respect to x.
        The function assumes log_p0 is the log probability of the source distribution at :math:`t=0`.

        Args:
            x_1 (Tensor): target sample (e.g., samples :math:`X_1 \sim p_1`).
            log_p0 (Callable[[Tensor], Tensor]): Log probability function of the source distribution.
            step_size (Optional[float]): The step size. Must be None for adaptive step solvers.
            method (str): A method supported by torchdiffeq. Defaults to </span><span class="sh">"</span><span class="s">euler</span><span class="sh">"</span><span class="s">. Other commonly used solvers are </span><span class="sh">"</span><span class="s">dopri5</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="s">midpoint</span><span class="sh">"</span><span class="s"> and </span><span class="sh">"</span><span class="s">heun3</span><span class="sh">"</span><span class="s">. For a complete list, see torchdiffeq.
            atol (float): Absolute tolerance, used for adaptive step solvers.
            rtol (float): Relative tolerance, used for adaptive step solvers.
            time_grid (Tensor): If step_size is None then time discretization is set by the time grid. Must start at 1.0 and end at 0.0, otherwise the likelihood computation is not valid. Defaults to torch.tensor([1.0, 0.0]).
            return_intermediates (bool, optional): If True then return intermediate time steps according to time_grid. Otherwise only return the final sample. Defaults to False.
            exact_divergence (bool): Whether to compute the exact divergence or use the Hutchinson estimator.
            enable_grad (bool, optional): Whether to compute gradients during sampling. Defaults to False.
            **model_extras: Additional input for the model.

        Returns:
            Union[Tuple[Tensor, Tensor], Tuple[Sequence[Tensor], Tensor]]: Samples at time_grid and log likelihood values of given x_1.
        </span><span class="sh">"""</span>
        <span class="nf">assert </span><span class="p">(</span>
            <span class="n">time_grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mf">1.0</span> <span class="ow">and</span> <span class="n">time_grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.0</span>
        <span class="p">),</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Time grid must start at 1.0 and end at 0.0. Got </span><span class="si">{</span><span class="n">time_grid</span><span class="si">}</span><span class="sh">"</span>

        <span class="c1"># Fix the random projection for the Hutchinson divergence estimator
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="n">exact_divergence</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">x_1</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span> <span class="o">-</span> <span class="mf">1.0</span>

        <span class="k">def</span> <span class="nf">ode_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">velocity_model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="o">**</span><span class="n">model_extras</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">dynamics_func</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">states</span><span class="p">):</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">set_grad_enabled</span><span class="p">(</span><span class="bp">True</span><span class="p">):</span>
                <span class="n">xt</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">()</span>
                <span class="n">ut</span> <span class="o">=</span> <span class="nf">ode_func</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">exact_divergence</span><span class="p">:</span>
                    <span class="c1"># Compute exact divergence
</span>                    <span class="n">div</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">ut</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                        <span class="n">div</span> <span class="o">+=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">ut</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">xt</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:,</span> <span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Compute Hutchinson divergence estimator E[z^T D_x(ut) z]
</span>                    <span class="n">ut_dot_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span>
                        <span class="sh">"</span><span class="s">ij,ij-&gt;i</span><span class="sh">"</span><span class="p">,</span> <span class="n">ut</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">z</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">grad_ut_dot_z</span> <span class="o">=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">ut_dot_z</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
                    <span class="n">div</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span>
                        <span class="sh">"</span><span class="s">ij,ij-&gt;i</span><span class="sh">"</span><span class="p">,</span>
                        <span class="n">grad_ut_dot_z</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                        <span class="n">z</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="p">)</span>

            <span class="k">return</span> <span class="n">ut</span><span class="p">.</span><span class="nf">detach</span><span class="p">(),</span> <span class="n">div</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span>

        <span class="n">y_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x_1</span><span class="p">.</span><span class="n">device</span><span class="p">))</span>
        <span class="n">ode_opts</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">step_size</span><span class="sh">"</span><span class="p">:</span> <span class="n">step_size</span><span class="p">}</span> <span class="k">if</span> <span class="n">step_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">set_grad_enabled</span><span class="p">(</span><span class="n">enable_grad</span><span class="p">):</span>
            <span class="n">sol</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="nf">odeint</span><span class="p">(</span>
                <span class="n">dynamics_func</span><span class="p">,</span>
                <span class="n">y_init</span><span class="p">,</span>
                <span class="n">time_grid</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
                <span class="n">options</span><span class="o">=</span><span class="n">ode_opts</span><span class="p">,</span>
                <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">,</span>
                <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">x_source</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">source_log_p</span> <span class="o">=</span> <span class="nf">log_p0</span><span class="p">(</span><span class="n">x_source</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_intermediates</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">sol</span><span class="p">,</span> <span class="n">source_log_p</span> <span class="o">+</span> <span class="n">log_det</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">sol</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">source_log_p</span> <span class="o">+</span> <span class="n">log_det</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div> <p><br/></p> <h3 id="implementation-of-2d-case">Implementation of 2D Case</h3> <p>Here, we are going to implement the <code class="language-plaintext highlighter-rouge">I-CFM</code>, <code class="language-plaintext highlighter-rouge">OT-CFM</code>, <code class="language-plaintext highlighter-rouge">Schrodinger Bridge CFM</code> and <code class="language-plaintext highlighter-rouge">SF2M</code> for the following generative examples:</p> <ol> <li>Generating moon from 8 Gaussians</li> <li>Generating moon from noises</li> <li>Generating checkerboard from noises</li> <li>Generating 8 gaussains from noises And compute the corresponding likelihoods.</li> </ol> <p>Some library imports:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">math</span><span class="p">,</span> <span class="n">torch</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">copy</span>

<span class="kn">import</span> <span class="n">ot</span> <span class="k">as</span> <span class="n">pot</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">device_count</span><span class="p">())</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span>

<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="n">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="c1"># torchdyn libraries
</span><span class="kn">from</span> <span class="n">torchdyn.core</span> <span class="kn">import</span> <span class="n">NeuralODE</span>
<span class="kn">from</span> <span class="n">torchdyn.datasets</span> <span class="kn">import</span> <span class="n">generate_moons</span>

<span class="c1"># for likelihood computation
</span><span class="kn">import</span> <span class="n">torchdiffeq</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Optional</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="n">torch.distributions</span> <span class="kn">import</span> <span class="n">Independent</span><span class="p">,</span> <span class="n">Normal</span>

</code></pre></div></div> <p>Some utils functions and distributions</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Important utils functions
</span>
<span class="k">def</span> <span class="nf">sample_conditional_pt</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">
    Draw a sample from N(mu_t(x0, x1), sigma), where
    mu_t(x0, x1) = t * x1 + (1 - t) * x0 being the interpolation between x0 and x1
    </span><span class="sh">'''</span>
    
    <span class="k">assert</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x1</span><span class="p">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">mu_t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x0</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu_t</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">epsilon</span>


<span class="c1"># conditional vector field
</span><span class="k">def</span> <span class="nf">conditional_vector_field</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">xt</span><span class="p">):</span> 
    <span class="sh">'''</span><span class="s">
    Compute the conditional vector fields u_t(x| x0, x1) = sigma_t</span><span class="sh">'</span><span class="s"> (x - mu_t) / sigma_t + mu_t</span><span class="sh">'</span><span class="s">
    Since sigma_t = sigma is a constant, sigma_t</span><span class="sh">'</span><span class="s"> = 0 in the above scenerio
    u_t(x| x0, x1) = mu_t</span><span class="sh">'</span><span class="s"> = x1 - x0
    </span><span class="sh">'''</span>
    <span class="k">return</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">x0</span>


<span class="c1"># functions for the data utils
</span>
<span class="c1"># sample 8 gaussians
</span><span class="k">def</span> <span class="nf">eight_normal_sample</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">.</span><span class="nc">MultivariateNormal</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span> <span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
               <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
               <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
               <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
               <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)),</span>
               <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)),</span>
               <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)),</span>
               <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))]</span>
                        
    <span class="n">centers</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="nf">sample</span><span class="p">((</span><span class="n">n</span><span class="p">,))</span>
    <span class="n">multi</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">multinomial</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span> <span class="n">n</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> <span class="n">data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">centers</span><span class="p">[</span><span class="n">multi</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+</span> <span class="n">noise</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="k">def</span> <span class="nf">sample_8_gaussians</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> 
    <span class="k">return</span> <span class="nf">eight_normal_sample</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="mf">0.1</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span>

<span class="c1"># sample moons
</span><span class="k">def</span> <span class="nf">sample_moons</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> 
    <span class="n">x0</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">generate_moons</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x0</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># sample Gaussians
</span><span class="k">def</span> <span class="nf">sample_noise</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">sample_checkerboard_data</span><span class="p">(</span><span class="n">n_points</span><span class="p">,</span> <span class="n">n_squares</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="c1"># Create a grid
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_squares</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_squares</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Create the checkerboard pattern
</span>    <span class="n">pattern</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_squares</span><span class="p">,</span> <span class="n">n_squares</span><span class="p">))</span>
    <span class="n">pattern</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">pattern</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Generate points
</span>    <span class="n">points</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_squares</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_squares</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pattern</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">n</span> <span class="o">=</span> <span class="n">n_points</span> <span class="o">//</span> <span class="p">(</span><span class="n">n_squares</span> <span class="o">*</span> <span class="n">n_squares</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">xx</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_squares</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">yy</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">yy</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">n_squares</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
                <span class="n">points</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>

    <span class="c1"># Convert to numpy array and add noise
</span>    <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
    <span class="n">points</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">points</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">points</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">points</span> <span class="o">*</span> <span class="n">scale</span>


<span class="c1"># plot the trajs
</span><span class="k">def</span> <span class="nf">plot_trajs</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">flow_line</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span> 
    
    <span class="n">n_traj</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">trajs</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_traj</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">traj</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">trajs</span><span class="p">):</span> 
        <span class="k">if</span> <span class="n">flow_line</span><span class="p">:</span> 
            <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">traj</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">olive</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">traj</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">traj</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">traj</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sh">'</span><span class="s">tab:red</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">legend</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Flow</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="n">flow_line</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="n">legend</span> <span class="o">+=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Prior sample ~ p0</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Data sample ~ p1</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">legend</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">checkpoint at step </span><span class="si">{</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_steps</span> <span class="o">//</span> <span class="n">n_traj</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
    
</code></pre></div></div> <p>Let’s take a look at what kind of data we are dealing with:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">g8</span><span class="p">,</span> <span class="n">mn</span><span class="p">,</span> <span class="n">cb</span> <span class="o">=</span> <span class="nf">sample_8_gaussians</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="nf">sample_moons</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="nf">sample_checkerboard_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">g8</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">g8</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Gaussians</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">mn</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mn</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">tab:orange</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Moons</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">cb</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cb</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">tab:green</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Checkerboard</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/distributions-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/distributions-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/distributions-1400.webp"/> <img src="/assets/img/posts/cfm/distributions.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Ok, now to the model, which is just a shallow MLP, taking \((x, t)\) and outputting the conditional vector fields.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">time_varying</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">time_varying</span> <span class="o">=</span> <span class="n">time_varying</span>
        <span class="k">if</span> <span class="n">out_dim</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">out_dim</span> <span class="o">=</span> <span class="n">dim</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">dim</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">time_varying</span><span class="p">),</span> <span class="n">hidden_dim</span><span class="p">),</span> 
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">SELU</span><span class="p">(),</span> 
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> 
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">SELU</span><span class="p">(),</span> 
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> 
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">SELU</span><span class="p">(),</span>
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
<span class="k">class</span> <span class="nc">torch_wrapper</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">Wraps model to torchdyn compatible format.</span><span class="sh">'''</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">torch_wrapper</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[...,</span> <span class="bp">None</span><span class="p">]],</span> <span class="mi">1</span><span class="p">))</span>
                                       
</code></pre></div></div> <p>The first 3 cases can be wrapped in a function, since they only differ in the design of \(p_t\) and \(u_t\).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># sampling wrapper 
</span><span class="k">def</span> <span class="nf">sampling</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">,</span> <span class="n">checkpoints</span><span class="p">):</span> 
    <span class="n">trajs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">checkpoint</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">'</span><span class="s">sampling from checkpoint</span><span class="sh">'</span><span class="p">):</span> 
        <span class="n">node</span> <span class="o">=</span> <span class="nc">NeuralODE</span><span class="p">(</span><span class="nf">torch_wrapper</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">),</span> <span class="n">solver</span><span class="o">=</span><span class="sh">"</span><span class="s">dopri5</span><span class="sh">"</span><span class="p">,</span> <span class="n">sensitivity</span><span class="o">=</span><span class="sh">"</span><span class="s">adjoint</span><span class="sh">"</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">traj</span> <span class="o">=</span> <span class="n">node</span><span class="p">.</span><span class="nf">trajectory</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">,</span> <span class="n">t_span</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span> <span class="c1"># integrating from 0 to 1 in 100 steps
</span>            <span class="n">trajs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">traj</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">trajs</span>

<span class="c1"># cfm training wrapper:
</span><span class="k">def</span> <span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">p0_sampler</span><span class="p">,</span> <span class="n">p1_sampler</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="p">,</span> <span class="n">vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span> 
    
    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">n_checkpoints</span> <span class="o">=</span> <span class="mi">5</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">time_varying</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>

    <span class="n">checkpoints</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span> 
        
        <span class="c1"># sample x0 ~ p0 and x1 ~ p1
</span>        <span class="n">x0</span> <span class="o">=</span> <span class="nf">p0_sampler</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="nf">p1_sampler</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        
        <span class="c1"># minibatch Optimal Transport
</span>        <span class="c1"># match rows using OT plan
</span>        <span class="k">if</span> <span class="n">ot_sampler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">ot_sampler</span><span class="p">.</span><span class="nf">sample_plan</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>

        <span class="c1"># sample time
</span>        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x0</span><span class="p">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
        
        <span class="c1"># sample xt ~ pt conditional probability path
</span>        <span class="n">xt</span> <span class="o">=</span> <span class="nf">pt_sampler</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
        
        <span class="c1"># compute the conditional vector field
</span>        <span class="n">ut</span> <span class="o">=</span> <span class="nf">vector_field</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
        
         <span class="c1"># the model input is the noisy point xt and time 
</span>        <span class="c1"># the model output is the flow to matching that of ut
</span>        <span class="n">vt</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># loss is the conditional flow matching loss, L_CFM
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">vt</span> <span class="o">-</span> <span class="n">ut</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
        
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">k</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Training step </span><span class="si">{</span><span class="n">k</span><span class="si">:</span><span class="mi">06</span><span class="n">d</span><span class="si">}</span><span class="s">, loss = </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="nf">if </span><span class="p">(</span><span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">k</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_steps</span> <span class="o">//</span> <span class="n">n_checkpoints</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span> <span class="n">checkpoints</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>

    <span class="c1"># sampling 
</span>    <span class="c1"># Generating samples x0' ~ p0
</span>    <span class="n">prior_samples</span> <span class="o">=</span> <span class="nf">p0_sampler</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    
    <span class="c1"># use the model to get estimate of ut and use it to transform the x0' iteratively (integrate) 
</span>    <span class="n">trajs</span> <span class="o">=</span> <span class="nf">sampling</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">,</span> <span class="n">checkpoints</span><span class="p">)</span>
    
    <span class="c1"># plotting
</span>    <span class="nf">plot_trajs</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">flow_line</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="c1"># compute likelihood
</span>    <span class="k">if</span> <span class="n">likelihood</span><span class="p">:</span> 
        <span class="n">x_1</span><span class="p">,</span> <span class="n">lls</span> <span class="o">=</span> <span class="nf">compute_likelihood_checkpoints</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">exact_divergence</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="nf">plot_likelihood</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">lls</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">None</span>
</code></pre></div></div> <p>Here we will define the <code class="language-plaintext highlighter-rouge">compute_likelihood_checkpoints</code> and <code class="language-plaintext highlighter-rouge">plot_likelihood</code> functions:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compute the gradient for the divergence calculation
</span><span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">output</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Compute the gradient of the inner product of output and grad_outputs w.r.t :math:`x`.

    Args:
        output (Tensor): [N, D] Output of the function.
        x (Tensor): [N, d_1, d_2, ... ] input
        grad_outputs (Optional[Tensor]): [N, D] Gradient of outputs, if `None`,
            then will use a tensor of ones
        create_graph (bool): If True, graph of the derivative will be constructed, allowing
            to compute higher order derivative products. Defaults to False.
    Returns:
        Tensor: [N, d_1, d_2, ... ]. the gradient w.r.t x.
    </span><span class="sh">"""</span>

    <span class="k">if</span> <span class="n">grad_outputs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">grad_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">output</span><span class="p">).</span><span class="nf">detach</span><span class="p">()</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">grad_outputs</span><span class="o">=</span><span class="n">grad_outputs</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="n">create_graph</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">grad</span>


<span class="k">def</span> <span class="nf">compute_likelihood</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">log_p0</span><span class="p">,</span> <span class="n">exact_divergence</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">n_evals</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">solver_method</span><span class="o">=</span><span class="sh">'</span><span class="s">dopri5</span><span class="sh">'</span><span class="p">,</span> <span class="n">solver_opts</span><span class="o">=</span><span class="p">{}):</span> 
    
    <span class="k">assert</span> <span class="n">x_1</span><span class="p">.</span><span class="n">device</span> <span class="o">==</span> <span class="nf">next</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">x_1</span><span class="p">.</span><span class="n">device</span>
    
    <span class="c1"># fixed time range from 1.0 to 0.0
</span>    <span class="n">time_range</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    
    
    <span class="c1"># random projection vectors for the Hutchinson divergence, constant w.r.t x
</span>    <span class="c1"># we should use the same z at any given time point, faster doing so as well
</span>    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">2.0</span> <span class="o">-</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">exact_divergence</span> <span class="k">else</span> <span class="bp">None</span>

    
    <span class="c1"># === ODE System ===
</span>    <span class="c1"># set up the ODE equations for the likelihood calculation
</span>    <span class="k">def</span> <span class="nf">ode_system</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">states</span><span class="p">):</span> 
        <span class="sh">'''</span><span class="s">
        states = (x_t, log p_t(x_t))
        </span><span class="sh">'''</span>

        <span class="n">x_t</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">set_grad_enabled</span><span class="p">(</span><span class="bp">True</span><span class="p">):</span>
            <span class="n">x_t</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">()</span>
            <span class="n">u_t</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="p">)</span>

            <span class="c1"># compute the exact divergence one by one
</span>            <span class="k">if</span> <span class="n">exact_divergence</span><span class="p">:</span> 
                <span class="k">assert</span> <span class="n">z</span> <span class="ow">is</span> <span class="bp">None</span>
                <span class="n">div</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">u_t</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span> 
                    <span class="c1"># definition of divergence of a neural network 
</span>                    <span class="c1"># using autograd through NN and sum over du_i/dx_i
</span>                    <span class="n">div</span> <span class="o">+=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">u_t</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:,</span> <span class="n">i</span><span class="p">]</span>

            <span class="c1"># compute the divergence estimator using Hutchinson's formula
</span>            <span class="k">else</span><span class="p">:</span> 
                <span class="k">assert</span> <span class="n">z</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
                
                <span class="c1"># ut * z
</span>                <span class="n">ut_dot_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">ij,ij-&gt;i</span><span class="sh">'</span><span class="p">,</span> <span class="n">u_t</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">z</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

                <span class="c1"># [d (ut)/ dx] * z = d (ut * z) / dx
</span>                <span class="n">grad_ut_dot_z</span> <span class="o">=</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">ut_dot_z</span><span class="p">,</span> <span class="n">x_t</span><span class="p">)</span>

                <span class="c1"># z^T * [d (ut)/ dx] * z = z^T * d (ut * z) / dx
</span>                <span class="n">div</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">ij,ij-&gt;i</span><span class="sh">'</span><span class="p">,</span> <span class="n">grad_ut_dot_z</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">z</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># just keep the values not the computational graph
</span>        <span class="k">return</span> <span class="n">u_t</span><span class="p">.</span><span class="nf">detach</span><span class="p">(),</span> <span class="n">div</span><span class="p">.</span><span class="nf">detach</span><span class="p">()</span>
    <span class="c1"># === End of ODE System === 
</span>    
    <span class="c1"># init state
</span>    <span class="n">state_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">x_1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
    
    <span class="c1"># doing the integration back in time from 1.0 to 0.0
</span>    <span class="n">likelihoods</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_evals</span><span class="p">):</span> 
        <span class="c1"># do reverse in time
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">set_grad_enabled</span><span class="p">(</span><span class="bp">False</span><span class="p">):</span> 
            <span class="n">sol</span><span class="p">,</span> <span class="n">log_det</span> <span class="o">=</span> <span class="n">torchdiffeq</span><span class="p">.</span><span class="nf">odeint</span><span class="p">(</span><span class="n">ode_system</span><span class="p">,</span> <span class="n">state_init</span><span class="p">,</span> <span class="n">time_range</span><span class="p">,</span> 
                                              <span class="n">method</span><span class="o">=</span><span class="n">solver_method</span><span class="p">,</span> 
                                              <span class="n">options</span><span class="o">=</span><span class="n">solver_opts</span><span class="p">,</span>
                                              <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> 
                                              <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
        <span class="c1"># x_0 and g_0
</span>        <span class="n">x_0</span><span class="p">,</span> <span class="n">g_0</span> <span class="o">=</span> <span class="n">sol</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">log_det</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">log_p0_x0</span> <span class="o">=</span> <span class="nf">log_p0</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
        <span class="n">log_p1_x1</span> <span class="o">=</span> <span class="n">log_p0_x0</span> <span class="o">+</span> <span class="n">g_0</span>
        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">log_p1_x1</span><span class="p">).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
        <span class="n">likelihoods</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">likelihood</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">likelihoods</span><span class="p">).</span><span class="nf">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># compute likelihood for all checkpoints: 
</span><span class="k">def</span> <span class="nf">compute_likelihood_checkpoints</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">grid_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">exact_divergence</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">n_evals</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">solver_method</span><span class="o">=</span><span class="sh">'</span><span class="s">dopri5</span><span class="sh">'</span><span class="p">,</span> <span class="n">solver_opts</span><span class="o">=</span><span class="p">{}):</span> 
    
    <span class="c1"># compute likelihood for the grid x_1
</span>    <span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">xy</span><span class="p">,</span> <span class="n">xy</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">xy</span><span class="p">,</span> <span class="n">xy</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">))</span>
    <span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">x_1</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">flatten</span><span class="p">(),</span> <span class="n">x_1</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">flatten</span><span class="p">()],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    
    <span class="c1"># log_p0
</span>    <span class="n">log_p0</span> <span class="o">=</span> <span class="nc">Independent</span><span class="p">(</span><span class="nc">Normal</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)),</span> <span class="mi">1</span><span class="p">).</span><span class="n">log_prob</span>
    
    <span class="c1"># likelihoods
</span>    <span class="n">likelihoods</span> <span class="o">=</span> <span class="p">[</span><span class="nf">compute_likelihood</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="nf">torch_wrapper</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">),</span> <span class="n">log_p0</span><span class="p">,</span> <span class="n">exact_divergence</span><span class="o">=</span><span class="n">exact_divergence</span><span class="p">,</span> <span class="n">n_evals</span><span class="o">=</span><span class="n">n_evals</span><span class="p">,</span> <span class="n">solver_method</span><span class="o">=</span><span class="n">solver_method</span><span class="p">,</span> <span class="n">solver_opts</span><span class="o">=</span><span class="n">solver_opts</span><span class="p">)</span> <span class="k">for</span> <span class="n">checkpoint</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">checkpoints</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sh">'</span><span class="s">Computing Likelihood</span><span class="sh">'</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">x_1</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">likelihoods</span>
    
<span class="c1"># plot the likelihoods
</span><span class="k">def</span> <span class="nf">plot_likelihood</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">likelihoods</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span> 
    
    <span class="n">n_likelihoods</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">likelihoods</span><span class="p">)</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_likelihoods</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ll</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">likelihoods</span><span class="p">):</span> 
        <span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">ll</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.8</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">ll</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">coolwarm</span><span class="sh">'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
    
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">checkpoint at step </span><span class="si">{</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_steps</span> <span class="o">//</span> <span class="n">n_likelihoods</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <h4 id="1-i-cfm">1. I-CFM</h4> <p><br/> 1-1. 8-Gaussian to Moon:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="c1"># loss ~ 7.572
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-1s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-1s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-1s-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-1s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>1-2. Generating Moon</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 2.839
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-2s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-2s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-2s-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-2s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-2l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-2l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-2l-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-2l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>1-3. Generating Checkerboard</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_checkerboard_data</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 2.113
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-3s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-3s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-3s-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-3s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-3l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-3l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-3l-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-3l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>1-4. Generating 8-Gaussians</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 4.999
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-4s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-4s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-4s-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-4s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-4l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-4l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-4l-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-4l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <h4 id="2-minibatch-ot-cfm">2. Minibatch OT-CFM</h4> <p>For Minibatch OT, we aim to straighten or tidy up the flow line so that they don’t cross for that specific minibatch to make the learning easily</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">OTPlanSampler</span><span class="p">:</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">exact</span><span class="sh">'</span><span class="p">,</span> <span class="n">normalize_cost</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span> 
        
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="sh">'</span><span class="s">exact</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">ot_fn</span> <span class="o">=</span> <span class="nf">partial</span><span class="p">(</span><span class="n">pot</span><span class="p">.</span><span class="n">emd</span><span class="p">,</span> <span class="n">numThreads</span><span class="o">=</span><span class="n">num_threads</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="sh">'</span><span class="s">sinkhorn</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">ot_fn</span> <span class="o">=</span> <span class="nf">partial</span><span class="p">(</span><span class="n">pot</span><span class="p">.</span><span class="n">sinkhorn</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="nc">NotImplementedError</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">normalize_cost</span> <span class="o">=</span> <span class="n">normalize_cost</span>
        
    <span class="k">def</span> <span class="nf">get_map</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">):</span> 
        
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">pot</span><span class="p">.</span><span class="nf">unif</span><span class="p">(</span><span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">pot</span><span class="p">.</span><span class="nf">unif</span><span class="p">(</span><span class="n">x1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="k">if</span> <span class="n">x0</span><span class="p">.</span><span class="nf">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span> <span class="n">x0</span> <span class="o">=</span> <span class="n">x0</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">x1</span><span class="p">.</span><span class="nf">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">x1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cdist</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">normalize_cost</span><span class="p">:</span> <span class="n">M</span> <span class="o">=</span> <span class="n">M</span> <span class="o">/</span> <span class="n">M</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span>  <span class="c1"># should not be normalized when using minibatches
</span>        
        <span class="n">p</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">ot_fn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="p">.</span><span class="nf">all</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">isfinite</span><span class="p">(</span><span class="n">p</span><span class="p">)):</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">ERROR: p is not finite</span><span class="sh">"</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Cost mean, max</span><span class="sh">"</span><span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">M</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
            <span class="nf">print</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">sum</span><span class="p">())</span> <span class="o">&lt;</span> <span class="mf">1e-8</span><span class="p">:</span> <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">p</span><span class="p">.</span><span class="n">size</span>
        <span class="k">return</span> <span class="n">p</span>
    
    <span class="k">def</span> <span class="nf">sample_map</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span> 
        <span class="n">p</span> <span class="o">=</span> <span class="n">pi</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">p</span> <span class="o">/</span> <span class="n">p</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span>
        <span class="n">choices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">pi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="n">replace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">divmod</span><span class="p">(</span><span class="n">choices</span><span class="p">,</span> <span class="n">pi</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="k">def</span> <span class="nf">sample_plan</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span> 
        <span class="n">pi</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">get_map</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sample_map</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="n">replace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x0</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x1</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
</code></pre></div></div> <p>Let’s see what OT did for the data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># generate samples from p0 and p1
</span><span class="n">tmp0</span><span class="p">,</span> <span class="n">tmp1</span> <span class="o">=</span> <span class="nf">sample_8_gaussians</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="nf">sample_moons</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># the data p0 and p1 is generated randomly, so in minibatch, we try to match first row of p0 to first row of p1
# this results in crossing of the flow paths or the vector fields
</span>
<span class="n">ot_sampler</span> <span class="o">=</span> <span class="nc">OTPlanSampler</span><span class="p">()</span>
<span class="n">tmp0ot</span><span class="p">,</span> <span class="n">tmp1ot</span> <span class="o">=</span> <span class="n">ot_sampler</span><span class="p">.</span><span class="nf">sample_plan</span><span class="p">(</span><span class="n">tmp0</span><span class="p">,</span> <span class="n">tmp1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">tmp0</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tmp0</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">p0</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">tmp1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tmp1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">p1</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">([</span><span class="n">tmp0</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tmp1</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">tmp0</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">tmp1</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Original</span><span class="sh">'</span><span class="p">)</span>
    
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">tmp0ot</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tmp0ot</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">p0</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">scatter</span><span class="p">(</span><span class="n">tmp1ot</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tmp1ot</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">p1</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">([</span><span class="n">tmp0ot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">tmp1ot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">tmp0ot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">tmp1ot</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">OT</span><span class="sh">'</span><span class="p">)</span>
    
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/ot-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/ot-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/ot-1400.webp"/> <img src="/assets/img/posts/cfm/ot.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>2-1. 8-Gaussian to Moon:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># loss ~ 0.053
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig1-1s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig1-1s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig1-1s-1400.webp"/> <img src="/assets/img/posts/cfm/fig1-1s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>2-2. Generating Moon</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 0.014
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig2-2s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig2-2s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig2-2s-1400.webp"/> <img src="/assets/img/posts/cfm/fig2-2s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig2-2l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig2-2l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig2-2l-1400.webp"/> <img src="/assets/img/posts/cfm/fig2-2l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>2-3. Generating Checkerboard</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_checkerboard_data</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 0.013
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig2-3s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig2-3s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig2-3s-1400.webp"/> <img src="/assets/img/posts/cfm/fig2-3s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig2-3l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig2-3l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig2-3l-1400.webp"/> <img src="/assets/img/posts/cfm/fig2-3l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>2-4. Generating 8-Gaussians</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 0.020
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig2-4s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig2-4s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig2-4s-1400.webp"/> <img src="/assets/img/posts/cfm/fig2-4s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig2-4l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig2-4l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig2-4l-1400.webp"/> <img src="/assets/img/posts/cfm/fig2-4l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <h4 id="3-schrodinger-bridge">3. Schrodinger Bridge</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Let's try using Schrodinger Bridge
</span>
<span class="c1"># for SB, We keep the mu as previous but change variance to be time-dependent: var = t(1-t)sigma^2
# this changes the flow vector field so we need to rewrite "sample_conditional_pt" and "conditional_vector_field" functions
</span>
<span class="k">def</span> <span class="nf">sample_conditional_pt_SB</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    
    <span class="sh">'''</span><span class="s">
    Draw a sample from N(mu_t(x0, x1), sigma), where
    mu_t(x0, x1) = t * x1 + (1 - t) * x0 being the interpolation between x0 and x1
    sigma_t^2 = t * (1-t) * sigma^2
    </span><span class="sh">'''</span>
    
    <span class="k">assert</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x1</span><span class="p">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">mu_t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x0</span>
    <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">t</span><span class="p">))</span>
    
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu_t</span> <span class="o">+</span> <span class="n">sigma_t</span> <span class="o">*</span> <span class="n">epsilon</span>

<span class="k">def</span> <span class="nf">conditional_vector_field_SB</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">xt</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Compute the conditional vector fields u_t(x| x0, x1) = sigma_t</span><span class="sh">'</span><span class="s"> (x - mu_t) / sigma_t + mu_t</span><span class="sh">'</span><span class="s">
    Since sigma_t = sigma is a constant, sigma_t</span><span class="sh">'</span><span class="s"> = 0 in the above scenerio
    u_t(x| x0, x1) = mu_t</span><span class="sh">'</span><span class="s"> = x1 - x0
    </span><span class="sh">'''</span>
    
    <span class="k">assert</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x1</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">xt</span><span class="p">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">mu_t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x0</span>
    <span class="n">sigma_t_prime_over_sigma_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">t</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
    <span class="n">ut</span> <span class="o">=</span> <span class="n">sigma_t_prime_over_sigma_t</span> <span class="o">*</span> <span class="p">(</span><span class="n">xt</span> <span class="o">-</span> <span class="n">mu_t</span><span class="p">)</span> <span class="o">+</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">x0</span>

    <span class="k">return</span> <span class="n">ut</span>
</code></pre></div></div> <p><br/></p> <p>3-1. 8-Gaussian to Moon:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt_SB</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field_SB</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># loss ~ 0.044
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig3-1s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig3-1s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig3-1s-1400.webp"/> <img src="/assets/img/posts/cfm/fig3-1s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>3-2. Generating Moon:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt_SB</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field_SB</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 0.012
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig3-2s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig3-2s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig3-2s-1400.webp"/> <img src="/assets/img/posts/cfm/fig3-2s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig3-2l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig3-2l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig3-2l-1400.webp"/> <img src="/assets/img/posts/cfm/fig3-2l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>3-3. Generating Checkerboard</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_checkerboard_data</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt_SB</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field_SB</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 0.011
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig3-3s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig3-3s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig3-3s-1400.webp"/> <img src="/assets/img/posts/cfm/fig3-3s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig3-3l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig3-3l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig3-3l-1400.webp"/> <img src="/assets/img/posts/cfm/fig3-3l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>3.4 Generating 8-Gaussians</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">cfm_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">pt_sampler</span><span class="o">=</span><span class="n">sample_conditional_pt_SB</span><span class="p">,</span> <span class="n">vector_field</span><span class="o">=</span><span class="n">conditional_vector_field_SB</span><span class="p">,</span> <span class="n">ot_sampler</span><span class="o">=</span><span class="nc">OTPlanSampler</span><span class="p">(),</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># loss ~ 0.023
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig3-4s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig3-4s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig3-4s-1400.webp"/> <img src="/assets/img/posts/cfm/fig3-4s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig3-4l-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig3-4l-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig3-4l-1400.webp"/> <img src="/assets/img/posts/cfm/fig3-4l.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>So, we can see that OT improves the training with much smaller loss converged and the probability calculation stabilizes in 2 checkpoints (4000 epochs).</p> <h4 id="4-score--flow-matching-sf2m">4. Score + Flow Matching, SF2M</h4> <p>Here, we cannot use <code class="language-plaintext highlighter-rouge">cfm_wrapper</code> but the difference is minimal, just add a score matching term.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Let's try using SF2M: Score + Flow matching
</span>
<span class="kn">import</span> <span class="n">torchsde</span>

<span class="c1"># the pt and flow field are the same as the SB case but here we add a score model to fit the scores from pt
# additionally, we will need a lambda(t) for the score scaling
</span>
<span class="k">def</span> <span class="nf">sample_conditional_pt_SB_noise</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    
    <span class="sh">'''</span><span class="s">
    Draw a sample from N(mu_t(x0, x1), sigma), where
    mu_t(x0, x1) = t * x1 + (1 - t) * x0 being the interpolation between x0 and x1
    sigma_t^2 = t * (1-t) * sigma^2
    </span><span class="sh">'''</span>
    
    <span class="k">assert</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x1</span><span class="p">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">mu_t</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x0</span>
    <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">t</span><span class="p">))</span>
    
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu_t</span> <span class="o">+</span> <span class="n">sigma_t</span> <span class="o">*</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">epsilon</span>

<span class="c1"># lambda(t)
</span><span class="k">def</span> <span class="nf">lamb</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span> 
    
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">t</span><span class="p">))</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sigma_t</span> <span class="o">/</span> <span class="p">(</span><span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>


<span class="c1"># wrap the flow and score in a module
</span><span class="k">class</span> <span class="nc">SDE</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="n">noise_type</span> <span class="o">=</span> <span class="sh">'</span><span class="s">diagonal</span><span class="sh">'</span>
    <span class="n">sde_type</span> <span class="o">=</span> <span class="sh">'</span><span class="s">ito</span><span class="sh">'</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">flow</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">SDE</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flow</span> <span class="o">=</span> <span class="n">flow</span>
        <span class="n">self</span><span class="p">.</span><span class="n">score</span> <span class="o">=</span> <span class="n">score</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        
    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span> 
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">input_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">):</span> 
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:,</span> <span class="bp">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">flow</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span> 
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="mf">5.0</span> <span class="c1"># can be used to tune the noise, like diffusion
</span></code></pre></div></div> <p>And we construct a <code class="language-plaintext highlighter-rouge">SF2M</code> wrapper:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sf2m_wrapper</span><span class="p">(</span><span class="n">p0_sampler</span><span class="p">,</span> <span class="n">p1_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span> 

    <span class="c1"># Everything the same, just add score matching part
</span>    <span class="n">ot_sampler</span> <span class="o">=</span> <span class="nc">OTPlanSampler</span><span class="p">()</span>

    <span class="c1"># some parameters
</span>    <span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># sigma_t = sigma = 0.1 a small constant value
</span>    <span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">n_checkpoints</span> <span class="o">=</span> <span class="mi">5</span>

    <span class="n">model</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">time_varying</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">score_model</span> <span class="o">=</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">time_varying</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    
    <span class="c1"># using both model weights, equivalent to training them individually
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nf">list</span><span class="p">(</span><span class="n">score_model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()))</span> 

    <span class="n">flow_checkpoints</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">score_checkpoints</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span> 

        <span class="c1"># sample prior = gaussian, posterior = moons
</span>        <span class="n">x0</span> <span class="o">=</span> <span class="nf">p0_sampler</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="nf">p1_sampler</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># match rows using OT plan
</span>        <span class="n">x0</span><span class="p">,</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">ot_sampler</span><span class="p">.</span><span class="nf">sample_plan</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">)</span>

        <span class="c1"># sample time
</span>        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x0</span><span class="p">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># generate some noisy x_t in between 
</span>        <span class="n">xt</span><span class="p">,</span> <span class="n">ep</span> <span class="o">=</span> <span class="nf">sample_conditional_pt_SB_noise</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>

        <span class="c1"># conditional flow vector field
</span>        <span class="n">ut</span> <span class="o">=</span> <span class="nf">conditional_vector_field_SB</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>

        <span class="c1"># the model input is the noisy point xt and time 
</span>        <span class="c1"># the model output is the flow to matching that of ut
</span>        <span class="n">vt</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">st</span> <span class="o">=</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># score
</span>
        <span class="c1"># loss is the flow matching loss
</span>        <span class="n">flow_loss</span> <span class="o">=</span> <span class="p">((</span><span class="n">vt</span> <span class="o">-</span> <span class="n">ut</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="n">score_loss</span> <span class="o">=</span> <span class="p">((</span><span class="nf">lamb</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">*</span> <span class="n">st</span> <span class="o">+</span> <span class="n">ep</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">flow_loss</span> <span class="o">+</span> <span class="n">score_loss</span>

        <span class="c1"># normal pytorch stuff
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">k</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Training step </span><span class="si">{</span><span class="n">k</span><span class="si">:</span><span class="mi">06</span><span class="n">d</span><span class="si">}</span><span class="s">, loss = </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
        <span class="nf">if </span><span class="p">(</span><span class="n">k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">k</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_steps</span> <span class="o">//</span> <span class="n">n_checkpoints</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span> 
            <span class="n">flow_checkpoints</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
            <span class="n">score_checkpoints</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">copy</span><span class="p">.</span><span class="nf">deepcopy</span><span class="p">(</span><span class="n">score_model</span><span class="p">))</span>


    <span class="c1">## sample using the flow model only: 
</span>    <span class="n">prior_samples</span> <span class="o">=</span> <span class="nf">p0_sampler</span><span class="p">(</span><span class="mi">1024</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">trajs</span> <span class="o">=</span> <span class="nf">sampling</span><span class="p">(</span><span class="n">prior_samples</span><span class="p">,</span> <span class="n">flow_checkpoints</span><span class="p">)</span>
    <span class="nf">plot_trajs</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">)</span>

    <span class="c1">## Sample using flow + score models
</span>    <span class="n">trajs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">flow_checkpoint</span><span class="p">,</span> <span class="n">score_checkpoint</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">flow_checkpoints</span><span class="p">,</span> <span class="n">score_checkpoints</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sh">'</span><span class="s">sample from checkpoint</span><span class="sh">'</span><span class="p">):</span>

        <span class="n">sde</span> <span class="o">=</span> <span class="nc">SDE</span><span class="p">(</span><span class="n">flow_checkpoint</span><span class="p">,</span> <span class="n">score_checkpoint</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,),</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">ts</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">traj</span> <span class="o">=</span> <span class="n">torchsde</span><span class="p">.</span><span class="nf">sdeint</span><span class="p">(</span><span class="n">sde</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">ts</span><span class="o">=</span><span class="n">ts</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">srk</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">trajs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">traj</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>

    <span class="nf">plot_trajs</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">None</span>
</code></pre></div></div> <p><br/></p> <p>4-1. 8-Gaussian to Moon</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">sf2m_wrapper</span><span class="p">(</span><span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># loss ~ 1.074
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-1s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-1s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-1s-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-1s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-1ss-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-1ss-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-1ss-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-1ss.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>4-2. Generating Moon</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">sf2m_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_moons</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># loss ~ 1.037
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-2s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-2s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-2s-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-2s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-2ss-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-2ss-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-2ss-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-2ss.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>4-3. Generating Checkerboard</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">sf2m_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_checkerboard_data</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># loss ~ 1.031
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-3s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-3s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-3s-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-3s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-3ss-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-3ss-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-3ss-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-3ss.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>4-4. Generating 8-Gaussians</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">sf2m_wrapper</span><span class="p">(</span><span class="n">sample_noise</span><span class="p">,</span> <span class="n">sample_8_gaussians</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1"># loss ~ 1.051
</span></code></pre></div></div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-4s-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-4s-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-4s-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-4s.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/cfm/fig4-4ss-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/cfm/fig4-4ss-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/cfm/fig4-4ss-1400.webp"/> <img src="/assets/img/posts/cfm/fig4-4ss.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>This gets a bit longer that expected. The image case will be in a separate post.</p> <h3 id="references">References</h3> <ol> <li>Lipman et al, Flow Matching for Generative Modeling, (<a href="https://arxiv.org/abs/2210.02747">link</a>)</li> <li>Lipman et al, Flow Matching Guide and Code, (<a href="https://arxiv.org/abs/2412.06264">link</a>)</li> <li>Tong et al, Improving and generalizing flow-based generative models with minibatch optimal transport (<a href="https://arxiv.org/abs/2302.00482">link</a>)</li> <li>Tong et al, Simulation-free Schrodinger bridges via score and flow matching (<a href="https://arxiv.org/abs/2307.03672">link</a>)</li> <li><a href="https://github.com/atong01/conditional-flow-matching?tab=readme-ov-file">TorchCFM</a></li> <li><a href="https://github.com/facebookresearch/flow_matching">Flow-Matching</a></li> </ol>]]></content><author><name></name></author><category term="models"/><category term="reading"/><category term="generating"/><category term="coding"/><summary type="html"><![CDATA[Flow matching learning notes on continuous data, 2D and Image]]></summary></entry><entry><title type="html">SE(3) Score-Matching Diffusion Model</title><link href="https://jipq6175.github.io/blog/2024/se3_diffusion/" rel="alternate" type="text/html" title="SE(3) Score-Matching Diffusion Model"/><published>2024-06-27T14:24:00+00:00</published><updated>2024-06-27T14:24:00+00:00</updated><id>https://jipq6175.github.io/blog/2024/se3_diffusion</id><content type="html" xml:base="https://jipq6175.github.io/blog/2024/se3_diffusion/"><![CDATA[<p>Not all data live in the Euclidean vector space. Respecting underlying symmetries of the data generally limits the model space, allowing more efficient learning and use of the data. In particular, the SE(3) group is important for modeling positions and orientations of systems ranging from protein backbones, rotamers, drones and robot arms.</p> <p>This SE(3) diffusion tutorial aims to build a score-based diffusion generative models for the SE(3) roto-translational data. We will utilize <code class="language-plaintext highlighter-rouge">trimesh</code> and <code class="language-plaintext highlighter-rouge">plotly</code> packages for visualization, <code class="language-plaintext highlighter-rouge">theseus</code> package for SO(3) group operations because of its seamless support on <code class="language-plaintext highlighter-rouge">pytorch</code>’s auto-differentiation.</p> <h3 id="table-of-content">Table of Content</h3> <ol> <li>Lie group, Lie algebra and Vector Space representations</li> <li>Recap on score-based diffusion model with an image example</li> <li>Components for diffusion in SE(3)</li> <li>Train diffusion models for 3 examples</li> </ol> <h3 id="0-libraries-and-helper-functions">0. Libraries and helper functions</h3> <p>Libraries:</p> <figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt-get <span class="nt">-qq</span> <span class="nb">install </span>libsuitesparse-dev
pip <span class="nb">install</span> <span class="nt">-qq</span> trimesh plotly theseus-ai</code></pre></figure> <p>Helpful functions:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># import the required packages
</span><span class="kn">import</span> <span class="n">torch</span><span class="p">,</span> <span class="n">trimesh</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="n">trimesh</span> <span class="kn">import</span> <span class="n">viewer</span>
<span class="kn">from</span> <span class="n">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="n">torch.autograd</span> <span class="kn">import</span> <span class="n">grad</span>
<span class="kn">from</span> <span class="n">theseus.geometry.so3</span> <span class="kn">import</span> <span class="n">SO3</span>

<span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>
<span class="kn">from</span> <span class="n">plotly.express.colors</span> <span class="kn">import</span> <span class="n">sample_colorscale</span>


<span class="c1"># plot the SO(3) distributions
</span><span class="n">X0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span> <span class="c1"># using the z axis to show the rotations
</span><span class="k">def</span> <span class="nf">plot_rotations</span><span class="p">(</span><span class="n">rotmats</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">X0</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">jet</span><span class="sh">'</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">Plot the rotation matrices contained in a list: rotmats
    colored coded by the order in the list
    </span><span class="sh">'''</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">rotmats</span><span class="p">))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="nf">sample_colorscale</span><span class="p">(</span><span class="n">cmap</span><span class="p">,</span> <span class="nf">list</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="n">d</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">rotmat</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">rotmats</span><span class="p">):</span>
        <span class="n">rotated_x0</span> <span class="o">=</span> <span class="n">rotmat</span> <span class="o">@</span> <span class="n">x0</span>
        <span class="n">d</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scatter3d</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span>
                              <span class="n">x</span><span class="o">=</span><span class="n">rotated_x0</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                              <span class="n">y</span><span class="o">=</span><span class="n">rotated_x0</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                              <span class="n">z</span><span class="o">=</span><span class="n">rotated_x0</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span>
                              <span class="n">marker</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">markers</span><span class="sh">'</span><span class="p">,</span> <span class="p">))</span>

    <span class="n">d</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="nc">Scatter3d</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">x0</span><span class="sh">'</span><span class="p">,</span>
                          <span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">],</span>
                          <span class="n">y</span><span class="o">=</span><span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span>
                          <span class="n">z</span><span class="o">=</span><span class="n">x0</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span>
                          <span class="n">marker</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">markers</span><span class="sh">'</span><span class="p">))</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="nc">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">.</span><span class="nf">update_layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">None</span>


<span class="c1"># visualize the angle and positions of SE(3) as robot grasps or forks
</span><span class="k">def</span> <span class="nf">create_gripper_marker</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span> <span class="n">tube_radius</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">sections</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Create a 3D mesh visualizing a parallel yaw gripper. It consists of four cylinders.

    Args:
        color (list, optional): RGB values of marker. Defaults to [0, 0, 255].
        tube_radius (float, optional): Radius of cylinders. Defaults to 0.001.
        sections (int, optional): Number of sections of each cylinder. Defaults to 6.

    Returns:
        trimesh.Trimesh: A mesh that represents a simple parallel yaw gripper.
    </span><span class="sh">"""</span>
    <span class="n">cfl</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="n">creation</span><span class="p">.</span><span class="nf">cylinder</span><span class="p">(</span>
        <span class="n">radius</span><span class="o">=</span><span class="mf">0.002</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span>
        <span class="n">sections</span><span class="o">=</span><span class="n">sections</span><span class="p">,</span>
        <span class="n">segment</span><span class="o">=</span><span class="p">[</span>
            <span class="p">[</span><span class="mf">4.10000000e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.27595772e-12</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="mf">6.59999996e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">4.10000000e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.27595772e-12</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="mf">1.12169998e-01</span><span class="o">*</span><span class="n">scale</span><span class="p">],</span>
        <span class="p">],</span>
    <span class="p">)</span>
    <span class="n">cfr</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="n">creation</span><span class="p">.</span><span class="nf">cylinder</span><span class="p">(</span>
        <span class="n">radius</span><span class="o">=</span><span class="mf">0.002</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span>
        <span class="n">sections</span><span class="o">=</span><span class="n">sections</span><span class="p">,</span>
        <span class="n">segment</span><span class="o">=</span><span class="p">[</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">4.100000e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.27595772e-12</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="mf">6.59999996e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">4.100000e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.27595772e-12</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="mf">1.12169998e-01</span><span class="o">*</span><span class="n">scale</span><span class="p">],</span>
        <span class="p">],</span>
    <span class="p">)</span>
    <span class="n">cb1</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="n">creation</span><span class="p">.</span><span class="nf">cylinder</span><span class="p">(</span>
        <span class="n">radius</span><span class="o">=</span><span class="mf">0.002</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="n">sections</span><span class="o">=</span><span class="n">sections</span><span class="p">,</span> <span class="n">segment</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">6.59999996e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="n">cb2</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="n">creation</span><span class="p">.</span><span class="nf">cylinder</span><span class="p">(</span>
        <span class="n">radius</span><span class="o">=</span><span class="mf">0.002</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span>
        <span class="n">sections</span><span class="o">=</span><span class="n">sections</span><span class="p">,</span>
        <span class="n">segment</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mf">4.100000e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">6.59999996e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.100000e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">6.59999996e-02</span><span class="o">*</span><span class="n">scale</span><span class="p">]],</span>
    <span class="p">)</span>

    <span class="n">tmp</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">cb1</span><span class="p">,</span> <span class="n">cb2</span><span class="p">,</span> <span class="n">cfr</span><span class="p">,</span> <span class="n">cfl</span><span class="p">])</span>
    <span class="n">tmp</span><span class="p">.</span><span class="n">visual</span><span class="p">.</span><span class="n">face_colors</span> <span class="o">=</span> <span class="n">color</span>
    <span class="n">tmp</span><span class="p">.</span><span class="n">visual</span><span class="p">.</span><span class="n">vertex_colors</span> <span class="o">=</span> <span class="n">color</span>

    <span class="k">return</span> <span class="n">tmp</span>

<span class="c1"># Visualize a set of SE(3) elements H (..., 4, 4)
# by creating forks for each fork from the above function
</span><span class="k">def</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">Hs</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">p_cloud</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">energies</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">mesh</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>

    <span class="c1"># Set color list
</span>    <span class="k">if</span> <span class="n">colors</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">energies</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">color</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">Hs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">min_energy</span> <span class="o">=</span> <span class="n">energies</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span>
            <span class="n">energies</span> <span class="o">-=</span><span class="n">min_energy</span>
            <span class="n">color</span> <span class="o">=</span> <span class="n">energies</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">energies</span><span class="p">)</span><span class="o">+</span><span class="mf">1e-6</span><span class="p">)</span>

    <span class="c1"># Grips
</span>    <span class="n">grips</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">Hs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">Hs</span><span class="p">[</span><span class="n">k</span><span class="p">,...]</span>

        <span class="k">if</span> <span class="n">colors</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">color</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">c_vis</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">c</span><span class="o">*</span><span class="mi">254</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">c_vis</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">colors</span><span class="p">[</span><span class="n">k</span><span class="p">,...]))</span>

        <span class="n">grips</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
            <span class="nf">create_gripper_marker</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">c_vis</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">).</span><span class="nf">apply_transform</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Visualize grips and the object
</span>    <span class="k">if</span> <span class="n">mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">scene</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="nc">Scene</span><span class="p">([</span><span class="n">mesh</span><span class="p">]</span><span class="o">+</span> <span class="n">grips</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">p_cloud</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">p_cloud_tri</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="n">points</span><span class="p">.</span><span class="nc">PointCloud</span><span class="p">(</span><span class="n">p_cloud</span><span class="p">)</span>
        <span class="n">scene</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="nc">Scene</span><span class="p">([</span><span class="n">p_cloud_tri</span><span class="p">]</span><span class="o">+</span> <span class="n">grips</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scene</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="nc">Scene</span><span class="p">(</span><span class="n">grips</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
        <span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scene</span></code></pre></figure> <h3 id="1-lie-group-lie-algebra-and-vector-space-representations-for-so3">1. Lie Group, Lie Algebra and Vector space representations for SO(3)</h3> <p>In this section, we will explore the SO(3) group using the following operations. The figures are from <a href="https://arxiv.org/pdf/1812.01537">A micro Lie theory for state estimation in robotics</a>.</p> <p><img title="" alt="Alt text" src="https://d3i71xaburhd42.cloudfront.net/3a75252bab18250b8de8be28ec376db6cfc04084/4-TableI-1.png"/></p> <p>Here is a more visual or conceptual conversions.</p> <p><img title="" alt="Alt text" src="https://d3i71xaburhd42.cloudfront.net/3a75252bab18250b8de8be28ec376db6cfc04084/5-Figure5-1.png"/></p> <p>For SO(3), group elements are 3x3 rotation matrices on the right, belonging to the manifold.</p> <p>For the Lie Algebra and axis-angle representations are vectors (or can be represented as vectors) on the left, belonging to the tangent space at Identity.</p> <ul> <li> <p>The <code class="language-plaintext highlighter-rouge">exp</code> and <code class="language-plaintext highlighter-rouge">log</code> are algebric operations that convert from SO(3) to so(3).</p> </li> <li> <p>The <code class="language-plaintext highlighter-rouge">vee</code> and <code class="language-plaintext highlighter-rouge">hat</code> are trivial operations, extracting or constructing between axis-angle vector to skew-symmetric matrices.</p> </li> <li> <p>The <code class="language-plaintext highlighter-rouge">Exp</code> and <code class="language-plaintext highlighter-rouge">Log</code> are shortcut transformations that conveniently map between SO(3) to axis-angle vectors.</p> </li> </ul> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
<span class="n">ATOL</span><span class="p">,</span> <span class="n">RTOL</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-5</span>

<span class="c1"># Dummy rotations for visualization of a sphere
</span><span class="n">R_dummy</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">3</span><span class="p">)).</span><span class="nf">to_matrix</span><span class="p">()</span>

<span class="c1"># v or v_vee is the axis-angle vector representation, in R^3
# v_hat is the lie algebra, in so(3) or skew symmetric matrix
# R is the 3D rotation matrix, in SO(3)
</span>
<span class="c1"># initialize vector or axis angle representation
</span><span class="n">v1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># rotation matrices from Exp
</span><span class="n">R1</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">v1</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>
<span class="n">R2</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">v2</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>

<span class="c1"># skew symmetric matrix in so(3)
</span><span class="n">v1_hat</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">hat</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span>
<span class="n">v2_hat</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">hat</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Example of the so3 skew symmetric matrix:</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">v1_hat</span><span class="p">)</span>


<span class="c1"># check the consistency between vector and rotation
# 1 + 2 cos(theta) = trace(R), where theta is the length of the vector
</span><span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">v1</span><span class="p">.</span><span class="nf">norm</span><span class="p">()),</span>
                      <span class="n">torch</span><span class="p">.</span><span class="nf">diagonal</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">v2</span><span class="p">.</span><span class="nf">norm</span><span class="p">()),</span>
                      <span class="n">torch</span><span class="p">.</span><span class="nf">diagonal</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">)</span>


<span class="c1"># 1. check the vee operator
</span><span class="n">v1_vee</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">vee</span><span class="p">(</span><span class="n">v1_hat</span><span class="p">)</span>
<span class="n">v2_vee</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">vee</span><span class="p">(</span><span class="n">v2_hat</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v1_vee</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v2_vee</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>

<span class="c1"># 2. the lowercase exp is the matrix exponential from so3 to SO3
</span><span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matrix_exp</span><span class="p">(</span><span class="n">v1_hat</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matrix_exp</span><span class="p">(</span><span class="n">v2_hat</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>

<span class="c1"># 3. the exp_map is the uppercase Exp, from R^3 to SO3
#    we used the SO3().exp_map previously but let's check
#    Exp[.] = exp( hat(.) )
</span><span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matrix_exp</span><span class="p">(</span><span class="nc">SO3</span><span class="p">().</span><span class="nf">hat</span><span class="p">(</span><span class="n">v1</span><span class="p">)),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">matrix_exp</span><span class="p">(</span><span class="nc">SO3</span><span class="p">().</span><span class="nf">hat</span><span class="p">(</span><span class="n">v2</span><span class="p">)),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>

<span class="c1"># 4. the log_map is the uppercase Log_map from SO(3) to R^3
</span><span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="nc">SO3</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">R1</span><span class="p">).</span><span class="nf">log_map</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="nc">SO3</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">R2</span><span class="p">).</span><span class="nf">log_map</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>

<span class="c1"># 5. the log operation: log R = v_hat = theta * (R - R^T) / (2 sin(theta))
</span><span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v1_hat</span><span class="p">,</span> <span class="n">v1</span><span class="p">.</span><span class="nf">norm</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="n">R1</span> <span class="o">-</span> <span class="n">R1</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">v1</span><span class="p">.</span><span class="nf">norm</span><span class="p">()),</span>
                      <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v2_hat</span><span class="p">,</span> <span class="n">v2</span><span class="p">.</span><span class="nf">norm</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="n">R2</span> <span class="o">-</span> <span class="n">R2</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">v2</span><span class="p">.</span><span class="nf">norm</span><span class="p">()),</span>
                      <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>

<span class="c1"># Outputs: 
# Example of the so3 skew symmetric matrix:
# tensor([[[ 0.0000, -0.5821,  1.2653],
#          [ 0.5821,  0.0000, -0.7207],
#          [-1.2653,  0.7207,  0.0000]]])</span></code></pre></figure> <p>Next, we will define and check operations in the SO(3) group.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Operation for the SO(3) group
</span>
<span class="c1"># 1. hat(v1 + v2) = hat(v1) + hat(v2)
#    because v and v_hat are in the same vector space
</span><span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v1_hat</span> <span class="o">+</span> <span class="n">v2_hat</span><span class="p">,</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">hat</span><span class="p">(</span><span class="n">v1</span> <span class="o">+</span> <span class="n">v2</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>


<span class="c1"># 2. compose the rotation by right multiplication
</span><span class="n">R3</span> <span class="o">=</span> <span class="n">R1</span> <span class="o">@</span> <span class="n">R2</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R3</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">...ij,...jk-&gt;...ik</span><span class="sh">'</span><span class="p">,</span> <span class="n">R1</span><span class="p">,</span> <span class="n">R2</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>



<span class="c1"># 3. compose the vector:
#    The rotation composition is not commutative, i.e. R1 @ R2 != R2 @ R1
#    so apparently, Exp_map(v1 + v2) != R1 @ R2.
#    The reason is that the geodesic of Exp_map(v1) is different from geodesic of Exp_map(v2)
#    To get the vector representation from v1 and v2, we will need to
#    - compose the corresponding rotations
#    - transform it back by taking the Log_map
</span><span class="k">def</span> <span class="nf">compose_rotvec</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">):</span>
  <span class="n">R1</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">v1</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>
  <span class="n">R2</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">v2</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>
  <span class="n">R3</span> <span class="o">=</span> <span class="n">R1</span> <span class="o">@</span> <span class="n">R2</span>
  <span class="k">return</span> <span class="nc">SO3</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">R3</span><span class="p">).</span><span class="nf">log_map</span><span class="p">()</span>

<span class="n">v3_a</span> <span class="o">=</span> <span class="nf">compose_rotvec</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
<span class="n">v3_b</span> <span class="o">=</span> <span class="nf">compose_rotvec</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>

<span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">v3_a</span><span class="p">,</span> <span class="n">v3_b</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R1</span> <span class="o">@</span> <span class="n">R2</span><span class="p">,</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">v3_a</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R2</span> <span class="o">@</span> <span class="n">R1</span><span class="p">,</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">v3_b</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>



<span class="c1"># 4. Interpolations between two rotations on the SO3 geodesic
#    See: https://en.wikipedia.org/wiki/Slerp
</span><span class="k">def</span> <span class="nf">slerp</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">R2</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">R1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">R2</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="nf">assert </span><span class="p">(</span><span class="n">weights</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">).</span><span class="nf">any</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">weights</span> <span class="o">&gt;=</span> <span class="mf">0.0</span><span class="p">).</span><span class="nf">any</span><span class="p">()</span>

  <span class="n">R1_norm</span> <span class="o">=</span> <span class="n">R1</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">R2_norm</span> <span class="o">=</span> <span class="n">R2</span> <span class="o">/</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">omega</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">acos</span><span class="p">((</span><span class="n">R1_norm</span> <span class="o">*</span> <span class="n">R2_norm</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">so</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">omega</span><span class="p">)</span>
  <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">((</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">weights</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">])</span> <span class="o">*</span> <span class="n">omega</span><span class="p">)</span> <span class="o">/</span> <span class="n">so</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">R1</span> <span class="o">+</span> <span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">weights</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">omega</span><span class="p">)</span> <span class="o">/</span> <span class="n">so</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">R2</span>
  <span class="k">return</span> <span class="n">res</span>

<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="nf">slerp</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">R2</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])),</span> <span class="n">R2</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="nf">slerp</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">R2</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">])),</span> <span class="n">R1</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="nf">slerp</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">R2</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="nf">slerp</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">R1</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">w</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>



<span class="c1"># 5. "Scale" a rotation by geodesic interpolation
#    Scaling operator can be done with a weighted interpolation between identity and the rotation
#    0 &lt;= scale &lt;= 1
</span><span class="k">def</span> <span class="nf">scale_rotations</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
  <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
  <span class="k">assert</span> <span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">scale</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="nf">assert </span><span class="p">(</span><span class="n">scale</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">).</span><span class="nf">any</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">scale</span> <span class="o">&gt;=</span> <span class="mf">0.0</span><span class="p">).</span><span class="nf">any</span><span class="p">()</span>
  <span class="n">batch</span> <span class="o">=</span> <span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">return</span> <span class="nf">slerp</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="bp">None</span><span class="p">,</span> <span class="p">...].</span><span class="nf">repeat</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">R</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span> <span class="c1"># just use SLERP
</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="nf">scale_rotations</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[</span><span class="bp">None</span><span class="p">,</span> <span class="p">...],</span> <span class="nf">scale_rotations</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">atol</span><span class="o">=</span><span class="n">ATOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">RTOL</span><span class="p">)</span>


<span class="c1"># 5. "Scale" a rotation by scaling the angle while fixing the axis
#    Scaling a rotation by 0 = Identity (zero degree)
#    Scaling a rotation by 0.5 = rotate (0.5 * theta) wrt the same axis
#    Scaling a rotation by 1.0 = the same ratation
#    Therefore, again, 0 &lt;= scale &lt;= 1
</span><span class="k">def</span> <span class="nf">scale_rotations_by_angle</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
  <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
  <span class="k">assert</span> <span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">scale</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="nf">assert </span><span class="p">(</span><span class="n">scale</span> <span class="o">&lt;=</span> <span class="mf">1.0</span><span class="p">).</span><span class="nf">any</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">scale</span> <span class="o">&gt;=</span> <span class="mf">0.0</span><span class="p">).</span><span class="nf">any</span><span class="p">()</span>

  <span class="n">v</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">R</span><span class="p">).</span><span class="nf">log_map</span><span class="p">()</span> <span class="c1"># convert from R to v
</span>  <span class="n">scaled_v</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">scale</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span> <span class="c1"># scale v, changing the theta while keeping the axis the same
</span>  <span class="k">return</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">scaled_v</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span> <span class="c1"># convert it back to the rotation matrix by Exp
</span>

<span class="c1"># 6. Visualizing scaled rotations and interpolated rotations
</span><span class="n">n_scale</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">scales</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_scale</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># scaling
</span><span class="n">rots</span> <span class="o">=</span> <span class="p">[</span><span class="nf">scale_rotations</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">scale</span><span class="p">]))</span> <span class="k">for</span> <span class="n">scale</span> <span class="ow">in</span> <span class="n">scales</span><span class="p">]</span>
<span class="nf">plot_rotations</span><span class="p">([</span><span class="n">R_dummy</span><span class="p">]</span> <span class="o">+</span> <span class="n">rots</span><span class="p">)</span>

<span class="c1"># interpolating R1 -&gt; R2
</span><span class="n">rots</span> <span class="o">=</span> <span class="p">[</span><span class="nf">slerp</span><span class="p">(</span><span class="n">R1</span><span class="p">,</span> <span class="n">R2</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">scale</span><span class="p">]))</span> <span class="k">for</span> <span class="n">scale</span> <span class="ow">in</span> <span class="n">scales</span><span class="p">]</span>
<span class="nf">plot_rotations</span><span class="p">([</span><span class="n">R_dummy</span><span class="p">]</span> <span class="o">+</span> <span class="n">rots</span><span class="p">)</span>

<span class="c1"># interpolating R2 -&gt; R1
</span><span class="n">rots</span> <span class="o">=</span> <span class="p">[</span><span class="nf">slerp</span><span class="p">(</span><span class="n">R2</span><span class="p">,</span> <span class="n">R1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">scale</span><span class="p">]))</span> <span class="k">for</span> <span class="n">scale</span> <span class="ow">in</span> <span class="n">scales</span><span class="p">]</span>
<span class="nf">plot_rotations</span><span class="p">([</span><span class="n">R_dummy</span><span class="p">]</span> <span class="o">+</span> <span class="n">rots</span><span class="p">)</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/scaling.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <p>The scaling is from 0.0 to 1.0, corresponding to an interpolation on the sphere from <code class="language-plaintext highlighter-rouge">I</code> to <code class="language-plaintext highlighter-rouge">R</code> (blue to red).</p> <p>The interpolations between <code class="language-plaintext highlighter-rouge">R1</code> and <code class="language-plaintext highlighter-rouge">R2</code> are as follows:</p> <iframe src="/assets/img/posts/se3diff/r1_r2_interp.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/r2_r1_interp.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <p>The trajectories are the same but flipped in direction.</p> <h3 id="2-recap-on-score-based-generative-models">2. Recap on Score-based generative models</h3> <p>Given a ground truth \(x(0)\) and some data at time t \(x(t) \sim p_t \sim N(m(t)x(0), v(t)I)\), we can compute the score, or</p> \[\nabla_{x(t)}\log p_t = -\frac{x(t)-m(t)x(0)}{v(t)}\] <p>In many of the score-matching models, the problem was designing \(m(t)\) and \(v(t)\). Here just for the demo of the score concept, we chose \(m(t) = 1\) and linear scheduling for the variance \(v(t)\).</p> <p>We will use the Langevin dynamics for generation or sampling:</p> \[x(t+dt) = x(t) + [\nabla_{x(t)}\log p_t]dt + \sqrt{2dt}z\] <p>where \(z\sim N(0, I)\).</p> <ul> <li>The annealed Langevin dynamics corresponds to varying \(v(t)\)</li> <li>The ODE-like sampling is the process where \(z=0\). Note that this is not the ODE-flow that aims to approximate the NLL of the data.</li> </ul> <p>Some researches used SDE to design the mean and variance because there are exact form other than Langevin dynamics when we are doing the generation, which some nice properties might arise. This is out of the scope of this notebook.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="n">torchvision.transforms</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">ToTensor</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">ToPILImage</span><span class="p">,</span> <span class="n">CenterCrop</span><span class="p">,</span> <span class="n">Resize</span>

<span class="n">url</span> <span class="o">=</span> <span class="sh">'</span><span class="s">http://images.cocodataset.org/val2017/000000039769.jpg</span><span class="sh">'</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">raw</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Original Image size = </span><span class="sh">'</span><span class="p">,</span> <span class="nc">ToTensor</span><span class="p">()(</span><span class="n">image</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>

<span class="n">image_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># a series of transformations
</span><span class="n">transform</span> <span class="o">=</span> <span class="nc">Compose</span><span class="p">([</span><span class="nc">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
                     <span class="nc">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
                     <span class="nc">ToTensor</span><span class="p">(),</span> <span class="c1"># turn into torch tensor of shape (Height x Width x Channel), divide by 255 in RGB
</span>                     <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)])</span>

<span class="c1"># inverse transform
</span><span class="n">reverse_transform</span> <span class="o">=</span> <span class="nc">Compose</span><span class="p">([</span><span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
                             <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="nf">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="c1"># C x H x W to H x W x C
</span>                             <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="o">*</span> <span class="mf">255.0</span><span class="p">),</span>
                             <span class="nc">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)),</span>
                             <span class="nc">ToPILImage</span><span class="p">()])</span>

<span class="n">x_start</span> <span class="o">=</span> <span class="nf">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">New Image Size = </span><span class="sh">'</span><span class="p">,</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">x_start</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">...]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Batched New Image Size = </span><span class="sh">'</span><span class="p">,</span> <span class="n">x_start</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nf">reverse_transform</span><span class="p">(</span><span class="n">x_start</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 2 sleeping cats : )
</span>
<span class="c1"># Outputs:
# Original Image size =  torch.Size([3, 480, 640])
# New Image Size =  torch.Size([3, 128, 128])
# Batched New Image Size =  torch.Size([1, 3, 128, 128])</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/original-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/original-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/original-1400.webp"/> <img src="/assets/img/posts/se3diff/original.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># compute the scores
# here because we have access to the single ground truth, we can calculate it directly
# But in the ML problem, we want a NN to learn this
# Note that the function or model inputs are noised_x and time (or std) (we won't have ground truth during sampling)
# and output is an image of vector fields or the score
</span><span class="k">def</span> <span class="nf">compute_score_image</span><span class="p">(</span><span class="n">x_noised</span><span class="p">,</span> <span class="n">x_truth</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">x_noised</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x_truth</span><span class="p">.</span><span class="n">shape</span>
  <span class="k">assert</span> <span class="n">x_noised</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">std</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">dist</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_noised</span> <span class="o">-</span> <span class="n">x_truth</span><span class="p">)</span> <span class="c1"># (b, c, w, h)
</span>  <span class="k">return</span> <span class="o">-</span> <span class="n">dist</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>


<span class="c1"># following the score back to the sample using Langevin dynamics
# noise_on = False: ODE-like or noise-free
# std_min = std_max: unannealed
</span><span class="k">def</span> <span class="nf">follow_score_image</span><span class="p">(</span><span class="n">x_truth</span><span class="p">,</span> <span class="n">std_min</span><span class="p">,</span> <span class="n">std_max</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">1500</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1001</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">std_min</span> <span class="o">&lt;=</span> <span class="n">std_max</span>
  <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">std_max</span><span class="p">,</span> <span class="n">std_min</span><span class="p">,</span> <span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

  <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">x_noised</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_truth</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">x_noised</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">score</span> <span class="o">=</span> <span class="nf">compute_score_image</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_truth</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">std</span><span class="p">[</span><span class="n">i</span><span class="p">]]))</span> <span class="c1"># this will be where the NN model comes in
</span>    <span class="n">x</span> <span class="o">+=</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">score</span>
    <span class="k">if</span> <span class="n">noise_on</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">T</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x</span>


<span class="c1"># some visualizations
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Un-annealed ODE-like</span><span class="sh">'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">follow_score_image</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="nf">reverse_transform</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Annealed ODE-like</span><span class="sh">'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">follow_score_image</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="nf">reverse_transform</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Un-annealed Langevin dynamics</span><span class="sh">'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">follow_score_image</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="nf">reverse_transform</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Annealed Langevin dynamics</span><span class="sh">'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">follow_score_image</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="nf">reverse_transform</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Note: this just a demo and does not suggest which sampling is superior</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/o1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/o1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/o1-1400.webp"/> <img src="/assets/img/posts/se3diff/o1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/o2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/o2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/o2-1400.webp"/> <img src="/assets/img/posts/se3diff/o2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/o3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/o3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/o3-1400.webp"/> <img src="/assets/img/posts/se3diff/o3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/o4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/o4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/o4-1400.webp"/> <img src="/assets/img/posts/se3diff/o4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In the figures above from left to right, they are generated from Un-annealed ODE-like, Annealed ODE-like, Un-annealed Langevin dynamics and Annealed Langevin dynamics.</p> <p>Note: this just a demo and does not suggest which sampling is superior.</p> <h3 id="3-critical-components-for-score-based-diffusion-in-se3">3. Critical components for score-based diffusion in SE(3)</h3> <p>In the previous example, we use a (ground truth) score model <code class="language-plaintext highlighter-rouge">compute_score_image</code> to generate (the same) images by following the score. This example implies that if we want to generalize score-matching diffusion model, we need to define the following on SO(3):</p> <ol> <li>Scale, <code class="language-plaintext highlighter-rouge">scale_rotations</code></li> <li>Add, composition of rotations, <code class="language-plaintext highlighter-rouge">R1 @ R2</code> or <code class="language-plaintext highlighter-rouge">compose_rotvec(v1, v2)</code></li> <li>Gaussian. IGSO3</li> </ol> <p>Further, it also depends on the representation we are working on. We will working with the vector or axis-angle representation for rotation in SO(3) and translation vector in \(R^3\). Together, we have a 6-degree-of-freedom representation for SE(3) data. T</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Sampling from a SE-3 Gaussian Distribution
</span><span class="k">def</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x_tar</span><span class="p">,</span> <span class="n">R_tar</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  x_tar: translational mean, (..., 3)
  R_tar: rotational mean, (..., 3, 3)
  std: standard deviation, (..., )
  </span><span class="sh">'''</span>

  <span class="n">x_eps</span> <span class="o">=</span> <span class="n">std</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_tar</span><span class="p">)</span>

  <span class="n">theta_eps</span> <span class="o">=</span> <span class="n">std</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_tar</span><span class="p">)</span>
  <span class="n">rot_eps</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">theta_eps</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>

  <span class="n">_x</span> <span class="o">=</span> <span class="n">x_tar</span> <span class="o">+</span> <span class="n">x_eps</span> <span class="c1"># compose the translation
</span>  <span class="n">_R</span> <span class="o">=</span> <span class="n">R_tar</span> <span class="o">@</span> <span class="n">rot_eps</span> <span class="c1"># compose the rotation by matrix mutiplication
</span>  <span class="k">return</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_R</span>


<span class="c1"># another implementation using theseus built-in randn
</span><span class="k">def</span> <span class="nf">sample_from_se3_gaussian_with_theseus</span><span class="p">(</span><span class="n">x_tar</span><span class="p">,</span> <span class="n">R_tar</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  x_tar: translational mean, (..., 3)
  R_tar: rotational mean, (..., 3, 3)
  std: standard deviation, (..., )
  </span><span class="sh">'''</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">std</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">x_eps</span> <span class="o">=</span> <span class="n">std</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x_tar</span><span class="p">)</span>
  <span class="n">rot_eps</span> <span class="o">=</span> <span class="nf">scale_rotations</span><span class="p">(</span><span class="n">SO3</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">(),</span> <span class="n">std</span><span class="p">)</span>

  <span class="n">_x</span> <span class="o">=</span> <span class="n">x_tar</span> <span class="o">+</span> <span class="n">x_eps</span> <span class="c1"># compose the translation
</span>  <span class="n">_R</span> <span class="o">=</span> <span class="n">R_tar</span> <span class="o">@</span> <span class="n">rot_eps</span> <span class="c1"># compose the rotation
</span>  <span class="k">return</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_R</span>


<span class="c1"># using the complicated formula of IGSO3
</span>

<span class="c1"># A helper function construct H from x and R
# H = [[R, x],
#      [0, 1]]
</span><span class="k">def</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">):</span>
  <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
  <span class="k">assert</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="mi">4</span><span class="p">)[</span><span class="bp">None</span><span class="p">,</span> <span class="p">...].</span><span class="nf">repeat</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">H</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">R</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
  <span class="n">H</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">H</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">R_mu</span> <span class="o">=</span> <span class="n">SO3</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">().</span><span class="nf">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># mean rotation
</span><span class="n">x_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># mean translation
</span>
<span class="c1"># rotation and translation combined in the H tensor (..., 4, 4)
</span><span class="n">H_mu</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">x_mu</span><span class="p">,</span> <span class="n">R_mu</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">An example of SE(3) group element:</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">H_mu</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Visualizations of Gaussians on SO(3) centering at mean rotation with different std
</span><span class="n">stds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">]</span>
<span class="n">rots</span><span class="p">,</span> <span class="n">rots_with_theseus</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">std</span> <span class="ow">in</span> <span class="n">stds</span><span class="p">:</span>

  <span class="n">__</span><span class="p">,</span> <span class="n">R_samples</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x_mu</span><span class="p">,</span> <span class="n">R_mu</span><span class="p">,</span> <span class="n">std</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
  <span class="n">__</span><span class="p">,</span> <span class="n">R_samples_with_theseus</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian_with_theseus</span><span class="p">(</span><span class="n">x_mu</span><span class="p">,</span> <span class="n">R_mu</span><span class="p">,</span> <span class="n">std</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
  <span class="n">rots</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">R_samples</span><span class="p">)</span>
  <span class="n">rots_with_theseus</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">R_samples_with_theseus</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">sample_from_se3_gaussian</span><span class="sh">'</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="nf">plot_rotations</span><span class="p">(</span><span class="n">rots</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">stds</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">to_html</span><span class="p">(</span><span class="sh">'</span><span class="s">se3_gaussian.html</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">sample_from_se3_gaussian_with_theseus</span><span class="sh">'</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="nf">plot_rotations</span><span class="p">(</span><span class="n">rots_with_theseus</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">stds</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">to_html</span><span class="p">(</span><span class="sh">'</span><span class="s">se3_gaussian_th.html</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Outputs: 
# An example of SE(3) group element:
# tensor([[[-0.7645,  0.1293, -0.6315, -0.8293],
#          [ 0.6156, -0.1438, -0.7748, -1.6137],
#          [-0.1910, -0.9811,  0.0303, -0.2147],
#          [ 0.0000,  0.0000,  0.0000,  1.0000]]])</span></code></pre></figure> <p>sample_from_se3_gaussian:</p> <iframe src="/assets/img/posts/se3diff/se3_gaussian.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <p>sample_from_se3_gaussian_with_theseus</p> <iframe src="/assets/img/posts/se3diff/se3_gaussian_th.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># A spreadout SE(3) Gaussian, std = 0.4
</span><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">x_samples</span><span class="p">,</span> <span class="n">R_samples</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x_mu</span><span class="p">,</span> <span class="n">R_mu</span><span class="p">,</span> <span class="mf">0.4</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>

<span class="n">H</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">R_samples</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">H</span><span class="p">,</span> <span class="n">H_mu</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">H</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">colors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">Hs</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>


<span class="c1"># A tight SE(3) Gaussian, std = 0.25
</span><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">x_samples</span><span class="p">,</span> <span class="n">R_samples</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x_mu</span><span class="p">,</span> <span class="n">R_mu</span><span class="p">,</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>

<span class="n">H</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">R_samples</span><span class="p">)</span>
<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">H</span><span class="p">,</span> <span class="n">H_mu</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">H</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">colors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">Hs</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Note that each fork is of the same size!</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>\(\sigma = 0.40\)</p> <iframe src="/assets/img/posts/se3diff/se3_gaussian1.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <p>\(\sigma = 0.25\)</p> <iframe src="/assets/img/posts/se3diff/se3_gaussian2.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <p>Note that each fork is of the same size!</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Evaluate log probability of SE(3) poses in SE(3) Gaussian distribution
</span><span class="k">def</span> <span class="nf">se3_log_probability_normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">x_tar</span><span class="p">,</span> <span class="n">R_tar</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  x: translation samples
  R: rotation samples

  x_tar: mean translation of SE-3 gaussian
  R_tar: mean rotation of SE-3 gaussian
  std: standard deviation of the SE-3 gaussian
  </span><span class="sh">'''</span>
  <span class="k">assert</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x_tar</span><span class="p">.</span><span class="n">shape</span>
  <span class="k">assert</span> <span class="n">R</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">R_tar</span><span class="p">.</span><span class="n">shape</span>

  <span class="c1"># Mean rotation as theseus object
</span>  <span class="n">_R_tar</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">()</span>
  <span class="n">_R_tar</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">R_tar</span><span class="p">)</span>

  <span class="c1"># rotation samples as theseus object
</span>  <span class="n">_R</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">()</span>
  <span class="n">_R</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">_R</span>

  <span class="c1"># Compute distance in R^3 + SO(3)
</span>  <span class="c1"># Rotation distance
</span>  <span class="n">R_tar_inv</span> <span class="o">=</span> <span class="n">_R_tar</span><span class="p">.</span><span class="nf">inverse</span><span class="p">()</span>
  <span class="n">dR</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">()</span>
  <span class="n">dR_rot</span> <span class="o">=</span> <span class="n">R_tar_inv</span><span class="p">.</span><span class="nf">to_matrix</span><span class="p">()</span> <span class="o">@</span> <span class="n">R</span><span class="p">.</span><span class="nf">to_matrix</span><span class="p">()</span>
  <span class="n">dR</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">dR_rot</span><span class="p">)</span>
  <span class="n">dv</span> <span class="o">=</span> <span class="n">dR</span><span class="p">.</span><span class="nf">log_map</span><span class="p">()</span> <span class="c1"># the vector representation for the rotation difference
</span>
  <span class="c1"># translation distance
</span>  <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_tar</span><span class="p">)</span>

  <span class="c1"># 6D distance
</span>  <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">dx</span><span class="p">,</span> <span class="n">dv</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="c1"># compute the log probability up to a constant term, which we don't care
</span>  <span class="k">return</span> <span class="o">-</span><span class="p">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">dist</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span><span class="p">.</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>


<span class="n">std</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">log_prob</span> <span class="o">=</span> <span class="nf">se3_log_probability_normal</span><span class="p">(</span><span class="n">x_samples</span><span class="p">,</span> <span class="n">R_samples</span><span class="p">,</span> <span class="n">x_mu</span><span class="p">,</span> <span class="n">R_mu</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

<span class="c1"># probability of each sample comping from the SE-3 samples
</span><span class="n">colors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">colors</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_prob</span> <span class="o">-</span> <span class="n">log_prob</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">log_prob</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">log_prob</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span>
<span class="n">colors</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="p">(</span><span class="n">log_prob</span> <span class="o">-</span> <span class="n">log_prob</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">log_prob</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">log_prob</span><span class="p">.</span><span class="nf">min</span><span class="p">())</span>

<span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">Hs</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">These forks are colored by the log probability, the greener the greater the logp &lt; 0</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/se3_gaussian_prob-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/se3_gaussian_prob-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/se3_gaussian_prob-1400.webp"/> <img src="/assets/img/posts/se3diff/se3_gaussian_prob.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>These forks are colored by the log probability, the greener the greater the \(logp &lt; 0\)</p> <p>We have calculated the SE(3) log probability density evaluated at \(x(t)\) or trans: \(x(t)\) and rot: \(R(t)\), up to a constant term. We now want to do 2 things:</p> <ol> <li>Compute the score, i.e. take the gradient of log probability wrt \(x(t)\) and \(R(t)\)</li> </ol> <p>This can be done analytically with the IGSO3 formula and the quotient rule as done in FrameDiff (Yim et al ICLR 2023). Or can be done via <code class="language-plaintext highlighter-rouge">theseus</code>’s compatibility with autodiff. We will use the latter in this notebook.</p> <p>The score is of the same dimension of the data, which has 6 degrees of freedom. We will denote as \(v = (x, y, z, w_x, w_y, w_z)\).</p> <ol> <li>Move one step in the direction of the score.</li> </ol> <p>This involves doing integration of small steps on the SO(3) manifold, converting the small axis-angle vector (in so(3)) to rotation matrix (in SO(3)) step by step as illustrated in the following figure.</p> <p><img title="" alt="Alt text" src="https://d3i71xaburhd42.cloudfront.net/3a75252bab18250b8de8be28ec376db6cfc04084/10-Figure10-1.png"/></p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Move an SE(3) pose given the score of a Gaussian Distribution in SE(3)
</span>
<span class="c1"># compute the SE(3) scores
</span><span class="k">def</span> <span class="nf">se3_score_normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">x_tar</span><span class="p">,</span> <span class="n">R_tar</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">
  x: translational samples. (..., 3)
  R: rotational samples. (..., 3, 3)

  v: se3 scores. (..., 6)
  </span><span class="sh">'''</span>

  <span class="c1"># theseus object
</span>  <span class="n">_R</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">()</span>
  <span class="n">_R</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">_R</span>

  <span class="c1"># construct trainable 6D vector
</span>  <span class="n">v</span> <span class="o">=</span> <span class="n">R</span><span class="p">.</span><span class="nf">log_map</span><span class="p">()</span>
  <span class="n">x_theta</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">x_theta</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

  <span class="c1"># assign components from 6D vector
</span>  <span class="c1"># looks redundant but this preserves the gradient hook and computation graph
</span>  <span class="n">x</span> <span class="o">=</span> <span class="n">x_theta</span><span class="p">[...,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">SO3</span><span class="p">.</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">x_theta</span><span class="p">[...,</span> <span class="mi">3</span><span class="p">:])</span>

  <span class="c1"># compute log probability with gradient hooked tensors
</span>  <span class="n">d</span> <span class="o">=</span> <span class="nf">se3_log_probability_normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">x_tar</span><span class="p">,</span> <span class="n">R_tar</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
  <span class="n">v</span> <span class="o">=</span> <span class="nf">grad</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="nf">sum</span><span class="p">(),</span> <span class="n">x_theta</span><span class="p">,</span> <span class="n">only_inputs</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">v</span>

<span class="c1"># (x, R) + v
</span><span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="c1"># compose rotations
</span>    <span class="n">rot</span> <span class="o">=</span> <span class="n">SO3</span><span class="p">.</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">v</span><span class="p">[...,</span> <span class="mi">3</span><span class="p">:]).</span><span class="nf">to_matrix</span><span class="p">()</span>
    <span class="n">R_1</span> <span class="o">=</span> <span class="n">R</span> <span class="o">@</span> <span class="n">rot</span>

    <span class="c1"># compose translations
</span>    <span class="n">x_1</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">v</span><span class="p">[...,:</span><span class="mi">3</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x_1</span><span class="p">,</span> <span class="n">R_1</span>


<span class="c1"># a helper function for scaling the roto-translation vector
# using the proper scaling of rotations
</span><span class="k">def</span> <span class="nf">scale_roto_trans_vec</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">scale</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">trans</span><span class="p">,</span> <span class="n">roto</span> <span class="o">=</span> <span class="n">v</span><span class="p">[...,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">v</span><span class="p">[...,</span> <span class="mi">3</span><span class="p">:]</span>

  <span class="c1"># roto vector scaling
</span>  <span class="n">R</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">roto</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>
  <span class="n">R</span> <span class="o">=</span> <span class="nf">scale_rotations</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
  <span class="n">roto</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">R</span><span class="p">).</span><span class="nf">log_map</span><span class="p">()</span>

  <span class="c1"># trans vector scaling
</span>  <span class="n">trans</span> <span class="o">=</span> <span class="n">trans</span> <span class="o">*</span> <span class="n">scale</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">trans</span><span class="p">,</span> <span class="n">roto</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># follow se3 scores, keeping intermediate states and outputs the scene
</span><span class="k">def</span> <span class="nf">follow_score_se3</span><span class="p">(</span><span class="n">x_truth</span><span class="p">,</span> <span class="n">R_truth</span><span class="p">,</span> <span class="n">std_min</span><span class="p">,</span> <span class="n">std_max</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">naive_scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">41</span><span class="p">):</span>

  <span class="k">assert</span> <span class="n">x_truth</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">R_truth</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
  <span class="n">H_truth</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">x_truth</span><span class="p">,</span> <span class="n">R_truth</span><span class="p">)</span>

  <span class="c1"># start with some random position and rotation in SE(3)
</span>  <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">SO3</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span> <span class="c1"># the prior is USO3
</span>  <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># the prior is Normal
</span>
  <span class="c1"># std schedules
</span>  <span class="n">stds</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">std_max</span><span class="p">,</span> <span class="n">std_min</span><span class="p">,</span> <span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">sqrt2_dt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span><span class="p">)</span>

  <span class="c1"># init SE3 components
</span>  <span class="n">H_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

  <span class="c1"># following the scores
</span>  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
    <span class="n">H0</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">detach</span><span class="p">(),</span> <span class="n">R</span><span class="p">.</span><span class="nf">detach</span><span class="p">())</span>
    <span class="n">H_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">H_trj</span><span class="p">,</span> <span class="n">H0</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">v</span> <span class="o">=</span> <span class="nf">se3_score_normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">x_truth</span><span class="p">,</span> <span class="n">R_truth</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">stds</span><span class="p">[</span><span class="n">i</span><span class="p">]]))</span>

    <span class="n">_s</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">dt</span> <span class="k">if</span> <span class="n">naive_scale</span> <span class="k">else</span> <span class="nf">scale_roto_trans_vec</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">dt</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">noise_on</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">T</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
      <span class="n">_s</span> <span class="o">+=</span> <span class="n">sqrt2_dt</span> <span class="o">*</span> <span class="n">z</span> <span class="k">if</span> <span class="n">naive_scale</span> <span class="k">else</span> <span class="nf">scale_roto_trans_vec</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">sqrt2_dt</span><span class="p">]))</span>

    <span class="c1"># one step following the score
</span>    <span class="n">x</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="nf">step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">_s</span><span class="p">)</span>

  <span class="c1"># for vis
</span>  <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">H_trj</span><span class="p">,</span> <span class="n">H_truth</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">colors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">H</span><span class="p">[:,:</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">colors</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H_trj</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">colors</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H_trj</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">colors</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">Hs</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">H</span><span class="p">,</span> <span class="n">scene</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Un-annealed ODE-like with large std...</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">follow_score_se3</span><span class="p">(</span><span class="n">x_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">R_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Un-annealed ODE-like with small std...</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">follow_score_se3</span><span class="p">(</span><span class="n">x_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">R_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Annealed ODE-like</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">follow_score_se3</span><span class="p">(</span><span class="n">x_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">R_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>


<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Un-annealed Langevin dyanmics with large std...</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">follow_score_se3</span><span class="p">(</span><span class="n">x_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">R_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Un-annealed Langevin dyanmics with small std...</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">follow_score_se3</span><span class="p">(</span><span class="n">x_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">R_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Annealed Langevin dyanmics</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">follow_score_se3</span><span class="p">(</span><span class="n">x_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">R_mu</span><span class="p">[:</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/follow1.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/follow2.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/follow3.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/follow4.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/follow5.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/follow6.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <h3 id="4-training-se3-diffusion-model">4. Training SE(3) Diffusion model</h3> <h4 id="toy-example-1">Toy example 1</h4> <p>Here we want to train a model that generates a 2 SE(3) elements.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Training a Toy SE(3) Diffusion Model
</span>
<span class="c1"># getting the data
</span><span class="k">def</span> <span class="nf">get_sample_from_data</span><span class="p">(</span><span class="n">B</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
  <span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                          <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">]])</span>
  <span class="n">theta_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">]])</span>
  <span class="n">R_data</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">theta_data</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="p">))</span>
  <span class="n">_x</span> <span class="o">=</span> <span class="n">x_data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">...]</span>
  <span class="n">_R</span> <span class="o">=</span> <span class="n">R_data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">...]</span>
  <span class="k">return</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_R</span>


<span class="c1"># defines the scheduling of std schedule with SDE with no drift
# this is the variance schedule we chose
</span><span class="k">def</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">((</span><span class="n">sigma</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)))</span>


<span class="c1"># Define the layer and model
</span>
<span class="c1"># Time step embedding
</span><span class="k">class</span> <span class="nc">GaussianFourierProjection</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">Gaussian random features for encoding time steps.
  </span><span class="sh">'''</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">30.</span><span class="p">):</span>
    <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
    <span class="n">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">embed_dim</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># fixed random projection
</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x_proj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">...,b-&gt;...b</span><span class="sh">'</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">pi</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">x_proj</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">x_proj</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># Naive all linears
</span><span class="k">class</span> <span class="nc">NaiveSE3DiffusionModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sh">'''</span><span class="s">Basic NN with linears
  input the noised x (B, 3) and R (B, 3, 3) at time t (B, )
  output the predicted scores v (B, 6)
  </span><span class="sh">'''</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
    <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

    <span class="n">input_size</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># we take a translation and flattened rotation
</span>                    <span class="c1"># one can do a 6-dim where we take the Log of the rotation
</span>    <span class="n">enc_dim</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">output_size</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="n">self</span><span class="p">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">enc_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Time Embedings Encoder
</span>    <span class="n">self</span><span class="p">.</span><span class="n">time_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
        <span class="nc">GaussianFourierProjection</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="n">enc_dim</span><span class="p">),</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">enc_dim</span><span class="p">,</span> <span class="n">enc_dim</span><span class="p">),</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="n">self</span><span class="p">.</span><span class="n">x_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">enc_dim</span><span class="p">),</span>
        <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
    <span class="p">)</span>


  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">std</span> <span class="o">=</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">x_R_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">x_embed</span><span class="p">(</span><span class="n">x_R_input</span><span class="p">)</span>
    <span class="n">z_time</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">time_embed</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">z_in</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">z</span><span class="p">,</span> <span class="n">z_time</span><span class="p">),</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">z_in</span><span class="p">)</span>

    <span class="c1"># the 1/v scaling is necessary for numerical stability
</span>    <span class="c1"># as we don't want the NN to predict scores say, from 0.001 to 100.0
</span>    <span class="k">return</span> <span class="n">v</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span><span class="p">[...,</span> <span class="bp">None</span><span class="p">].</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>


<span class="c1"># Training
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">NaiveSE3DiffusionModel</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>

<span class="n">K</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">EPS</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">K</span><span class="p">)):</span>

    <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">EPS</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">+</span> <span class="n">EPS</span> <span class="c1"># t ~ 0 will cause numerical instability
</span>    <span class="n">std</span> <span class="o">=</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="c1"># compute scheuling of std at t=t, increasing with t
</span>    <span class="n">x</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="nf">get_sample_from_data</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="c1"># batch samples
</span>    <span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span> <span class="c1"># noised samples
</span>
    <span class="n">v_tar</span> <span class="o">=</span> <span class="nf">se3_score_normal</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">x_tar</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">R_tar</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span> <span class="c1"># estimate scores of noised samples
</span>    <span class="n">v_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># predicted scores from model
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">std</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(((</span><span class="n">v_pred</span> <span class="o">-</span> <span class="n">v_tar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># score matching loss
</span>    <span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">loss_trj</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">detach</span><span class="p">()[</span><span class="bp">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Backward pass and optimization
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">loss_trj</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/training1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/training1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/training1-1400.webp"/> <img src="/assets/img/posts/se3diff/training1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Given the model run reverse sampling using the step function we defined
</span><span class="k">def</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">naive_scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">37</span><span class="p">):</span>

  <span class="c1"># random starting point
</span>  <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">R0</span> <span class="o">=</span> <span class="n">SO3</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">B</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>
  <span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="n">T</span> <span class="o">+</span> <span class="n">eps</span>

    <span class="n">v</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">R0</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">k</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">))</span>
    <span class="n">_s</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">dt</span> <span class="k">if</span> <span class="n">naive_scale</span> <span class="k">else</span> <span class="nf">scale_roto_trans_vec</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="p">))</span>

    <span class="k">if</span> <span class="n">noise_on</span> <span class="ow">and</span> <span class="n">t</span> <span class="o">!=</span> <span class="n">T</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
      <span class="n">_s</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span><span class="p">)</span> <span class="o">*</span> <span class="n">z</span> <span class="k">if</span> <span class="n">naive_scale</span> <span class="k">else</span> <span class="nf">scale_roto_trans_vec</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="p">))</span>

    <span class="n">x0</span><span class="p">,</span> <span class="n">R0</span> <span class="o">=</span> <span class="nf">step</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">R0</span><span class="p">,</span> <span class="n">_s</span><span class="p">)</span>

  <span class="c1"># generated samples (red)
</span>  <span class="n">H_gen</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">x0</span><span class="p">.</span><span class="nf">detach</span><span class="p">(),</span> <span class="n">R0</span><span class="p">.</span><span class="nf">detach</span><span class="p">())</span>
  <span class="n">colors_gen</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">colors_gen</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="c1"># real samples (green)
</span>  <span class="n">xd</span><span class="p">,</span> <span class="n">Rd</span> <span class="o">=</span> <span class="nf">data_gen</span><span class="p">(</span><span class="n">B</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
  <span class="n">H_dat</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">Rd</span><span class="p">)</span>
  <span class="n">colors_dat</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">colors_dat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">H_gen</span><span class="p">,</span> <span class="n">H_dat</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">colors_gen</span><span class="p">,</span> <span class="n">colors_dat</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">Hs</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="n">c</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">H_gen</span><span class="p">,</span> <span class="n">scene</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Sampling from trained model by following score prediction</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">get_sample_from_data</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Sampling from trained model by Langevin dynamics</span><span class="sh">'</span><span class="p">)</span>
<span class="n">H</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">get_sample_from_data</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>
<span class="nf">plot_rotations</span><span class="p">([</span><span class="n">R_dummy</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">H</span><span class="p">[...,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="nf">get_sample_from_data</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="mi">1</span><span class="p">]])</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/ex1sample1.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/ex1sample2.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/ex1so3.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <h4 id="2-toy-example-2">2. Toy example 2</h4> <p>Here we want to train a model that generates a 4 SE(3) elements.</p> <p>We’ll later see that the translation part defines unbalanced sampling and tricks to overcome it.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># try different distributions
</span><span class="k">def</span> <span class="nf">get_sample_from_data_2</span><span class="p">(</span><span class="n">B</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                           <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7</span><span class="p">],</span>
                           <span class="p">[</span><span class="mf">3.1</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.4</span><span class="p">],</span> <span class="c1"># this one is significantly more further away
</span>                           <span class="p">[</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]])</span>
    <span class="n">theta_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                               <span class="p">[</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">],</span>
                               <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4</span><span class="p">],</span>
                               <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]])</span>

    <span class="n">R_data</span> <span class="o">=</span> <span class="nc">SO3</span><span class="p">().</span><span class="nf">exp_map</span><span class="p">(</span><span class="n">theta_data</span><span class="p">).</span><span class="nf">to_matrix</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="p">(</span><span class="n">B</span><span class="p">,))</span>
    <span class="n">_x</span> <span class="o">=</span> <span class="n">x_data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">_R</span> <span class="o">=</span> <span class="n">R_data</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">...]</span>
    <span class="k">return</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_R</span>


<span class="c1"># the same training, just copied and pasted here
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">NaiveSE3DiffusionModel</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>


<span class="n">K</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">K</span><span class="p">)):</span>

    <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">EPS</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">+</span> <span class="n">EPS</span>
    <span class="n">std</span> <span class="o">=</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="nf">get_sample_from_data_2</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

    <span class="n">v_tar</span> <span class="o">=</span> <span class="nf">se3_score_normal</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">x_tar</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">R_tar</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span>
    <span class="n">v_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">std</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span><span class="p">(((</span><span class="n">v_pred</span> <span class="o">-</span> <span class="n">v_tar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">loss_trj</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">detach</span><span class="p">()[</span><span class="bp">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">loss_trj</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/training2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/training2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/training2-1400.webp"/> <img src="/assets/img/posts/se3diff/training2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Sampling from trained model by following score prediction</span><span class="sh">'</span><span class="p">)</span>
<span class="n">__</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">get_sample_from_data_2</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>


<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Sampling from trained model by Langevin dynamics</span><span class="sh">'</span><span class="p">)</span>
<span class="n">H</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">get_sample_from_data_2</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>

<span class="nf">plot_rotations</span><span class="p">([</span><span class="n">R_dummy</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">H</span><span class="p">[...,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="nf">get_sample_from_data_2</span><span class="p">(</span><span class="mi">20</span><span class="p">)[</span><span class="mi">1</span><span class="p">]])</span>

<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Notice there is a relative sampling bias with respective to the more distant point</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">This is because for translational sampling, the more distance from the original, the less likely it will be achieved</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">One can simply make the system of zero COM.</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/ex2sample1.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/ex2sample2.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/ex2so3.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <p>Notice there is a relative sampling bias with respective to the more distant point This is because for translational sampling, the more distance from the original, the less likely it will be achieved One can simply make the system of zero COM.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Let's redo th training by centering the SE(3) distribution at origin
</span>
<span class="n">offset</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.6500</span><span class="p">,</span> <span class="mf">1.0000</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6000</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">NaiveSE3DiffusionModel</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>

<span class="c1"># again copied and pasted
# should've put this into a function but well..
</span><span class="n">K</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">K</span><span class="p">)):</span>

    <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">EPS</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">+</span> <span class="n">EPS</span>
    <span class="n">std</span> <span class="o">=</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="nf">get_sample_from_data_2</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

    <span class="c1"># the only difference is the centering
</span>    <span class="n">x</span> <span class="o">-=</span> <span class="n">offset</span>

    <span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
    <span class="n">v_tar</span> <span class="o">=</span> <span class="nf">se3_score_normal</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">x_tar</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">R_tar</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span>
    <span class="n">v_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">std</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span><span class="p">(((</span><span class="n">v_pred</span> <span class="o">-</span> <span class="n">v_tar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">loss_trj</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">detach</span><span class="p">()[</span><span class="bp">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Backward pass and optimization
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">loss_trj</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/se3diff/training3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/se3diff/training3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/se3diff/training3-1400.webp"/> <img src="/assets/img/posts/se3diff/training3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Sampling from trained model by Langevin dynamics</span><span class="sh">'</span><span class="p">)</span>
<span class="n">H</span><span class="p">,</span> <span class="n">scene</span> <span class="o">=</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">get_sample_from_data_2</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>
<span class="nf">plot_rotations</span><span class="p">([</span><span class="n">R_dummy</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">H</span><span class="p">[...,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="nf">get_sample_from_data_2</span><span class="p">(</span><span class="mi">20</span><span class="p">)[</span><span class="mi">1</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">The green forks are from un-centered distribution</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Notice that the sampling becomes more balanced by just centering the distribution</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">There are ways to improve the sampling, like scaling.</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Because the roto-translation are coupled, now we have a more balanced samples for the orientation as well.</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">There are many ways to overcome this, like scaling, sample and recentering, decoupling</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/ex2sample3.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <iframe src="/assets/img/posts/se3diff/ex2so3_2.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <p>The green forks are from un-centered distribution Notice that the sampling becomes more balanced by just centering the distribution There are ways to improve the sampling, like scaling. Because the roto-translation are coupled, now we have a more balanced samples for the orientation as well.</p> <p>There are many ways to overcome this, like scaling, sample and recentering, decoupling</p> <h4 id="3-real-example-a-protein">3. Real example: A protein!</h4> <p>Here, we will use a protein’s backbone frames as ONE single SE(3) distribution and see if our NN and framework can learn it.</p> <p>We’ll probably define a more complex / deeper model for this task as we know that the underlying distribution is very complicated.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Let's use a more complicated SE(3) distribution - protein
</span>
<span class="kn">import</span> <span class="n">pickle</span>

<span class="n">retrain</span> <span class="o">=</span> <span class="bp">False</span> <span class="c1"># turn this on if you want to train it yourself
</span>
<span class="c1"># rotation from 3 points using Gram–Schmidt to construct local basis
# a protein local frame can be constructed using C-alpha, N and C
</span><span class="k">def</span> <span class="nf">from_3_points</span><span class="p">(</span>
        <span class="n">p_neg_x_axis</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">origin</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_xy_plane</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
            Implements algorithm 21. Constructs transformations from sets of 3
            points using the Gram-Schmidt algorithm.

            Args:
                p_neg_x_axis: [*, 3] coordinates
                origin: [*, 3] coordinates used as frame origins
                p_xy_plane: [*, 3] coordinates
                eps: Small epsilon value
            Returns:
                A transformation object of shape [*]
        </span><span class="sh">"""</span>
        <span class="n">p_neg_x_axis</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">unbind</span><span class="p">(</span><span class="n">p_neg_x_axis</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">origin</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">unbind</span><span class="p">(</span><span class="n">origin</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">p_xy_plane</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">unbind</span><span class="p">(</span><span class="n">p_xy_plane</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">e0</span> <span class="o">=</span> <span class="p">[</span><span class="n">c1</span> <span class="o">-</span> <span class="n">c2</span> <span class="k">for</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">origin</span><span class="p">,</span> <span class="n">p_neg_x_axis</span><span class="p">)]</span>
        <span class="n">e1</span> <span class="o">=</span> <span class="p">[</span><span class="n">c1</span> <span class="o">-</span> <span class="n">c2</span> <span class="k">for</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">p_xy_plane</span><span class="p">,</span> <span class="n">origin</span><span class="p">)]</span>

        <span class="n">denom</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum</span><span class="p">((</span><span class="n">c</span> <span class="o">*</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">e0</span><span class="p">))</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">e0</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="o">/</span> <span class="n">denom</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">e0</span><span class="p">]</span>
        <span class="n">dot</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">((</span><span class="n">c1</span> <span class="o">*</span> <span class="n">c2</span> <span class="k">for</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">e0</span><span class="p">,</span> <span class="n">e1</span><span class="p">)))</span>
        <span class="n">e1</span> <span class="o">=</span> <span class="p">[</span><span class="n">c2</span> <span class="o">-</span> <span class="n">c1</span> <span class="o">*</span> <span class="n">dot</span> <span class="k">for</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">e0</span><span class="p">,</span> <span class="n">e1</span><span class="p">)]</span>
        <span class="n">denom</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">sum</span><span class="p">((</span><span class="n">c</span> <span class="o">*</span> <span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">e1</span><span class="p">))</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">e1</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="o">/</span> <span class="n">denom</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">e1</span><span class="p">]</span>
        <span class="n">e2</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">e0</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">e1</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">e0</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">e1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">e0</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">e1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">e0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">e1</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">e0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">e1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">e0</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">e1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">]</span>

        <span class="n">rots</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">c</span> <span class="k">for</span> <span class="n">tup</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">e0</span><span class="p">,</span> <span class="n">e1</span><span class="p">,</span> <span class="n">e2</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tup</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">rots</span> <span class="o">=</span> <span class="n">rots</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">rots</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">rots</span>

<span class="c1"># an in-house preprocessed antibody structure
# this should be provided with the notebook
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">./AFQ82415.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">))</span>
<span class="n">coordinates</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">atom_positions</span><span class="sh">'</span><span class="p">][:</span><span class="mi">101</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># N, Ca, C
</span>
<span class="n">rots</span> <span class="o">=</span> <span class="nf">from_3_points</span><span class="p">(</span><span class="n">coordinates</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">coordinates</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">coordinates</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">trans</span> <span class="o">=</span> <span class="n">coordinates</span><span class="p">[...,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/</span> <span class="mf">10.</span> <span class="c1"># we need to scale this in order to get a more balanced samples
</span><span class="n">p</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">trans</span><span class="p">,</span> <span class="n">rots</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># interpolate between residues to augment the data
</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">trans</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">trans</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">...]</span>
<span class="n">r1</span><span class="p">,</span> <span class="n">r2</span> <span class="o">=</span> <span class="n">rots</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">...],</span> <span class="n">rots</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">...]</span>

<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">20</span><span class="p">):</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">t1</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="n">t2</span>
  <span class="n">r</span> <span class="o">=</span> <span class="nf">slerp</span><span class="p">(</span><span class="n">r2</span><span class="p">,</span> <span class="n">r1</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> <span class="o">*</span> <span class="n">w</span><span class="p">)</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">r</span><span class="p">)))</span>

<span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/prot.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># get samples from backbone
</span><span class="n">prot</span> <span class="o">=</span> <span class="nf">construct_roto_trans</span><span class="p">(</span><span class="n">trans</span><span class="p">,</span> <span class="n">rots</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">prot</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_sample_from_protein</span><span class="p">(</span><span class="n">prot</span><span class="o">=</span><span class="n">prot</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>

  <span class="n">n</span> <span class="o">=</span> <span class="n">prot</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="p">))</span>
  <span class="n">H</span> <span class="o">=</span> <span class="n">prot</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">...]</span>
  <span class="n">_x</span> <span class="o">=</span> <span class="n">H</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">_R</span> <span class="o">=</span> <span class="n">H</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_R</span>


<span class="c1"># a deeper model
# We just naively stacked more Linears in between
</span><span class="k">class</span> <span class="nc">NaiveSE3DiffusionModel2</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">input_size</span> <span class="o">=</span> <span class="mi">12</span>
        <span class="n">enc_dim</span> <span class="o">=</span> <span class="mi">128</span>
        <span class="n">output_size</span> <span class="o">=</span> <span class="mi">6</span>

        <span class="n">self</span><span class="p">.</span><span class="n">network1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">enc_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">enc_dim</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">network2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">enc_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1">## Time Embedings Encoder ##
</span>        <span class="n">self</span><span class="p">.</span><span class="n">time_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="nc">GaussianFourierProjection</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="n">enc_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">enc_dim</span><span class="p">,</span> <span class="n">enc_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">x_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">enc_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">((</span><span class="n">sigma</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="n">x_R_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">R</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">x_embed</span><span class="p">(</span><span class="n">x_R_input</span><span class="p">)</span>
        <span class="n">z_time</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">time_embed</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
        <span class="n">z_in</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">z</span><span class="p">,</span> <span class="n">z_time</span><span class="p">),</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network1</span><span class="p">(</span><span class="n">z_in</span><span class="p">)</span>
        <span class="n">z_in</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">z</span><span class="p">,</span> <span class="n">z_time</span><span class="p">),</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network2</span><span class="p">(</span><span class="n">z_in</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">v</span><span class="o">/</span><span class="p">(</span><span class="n">std</span><span class="p">[:,</span><span class="bp">None</span><span class="p">].</span><span class="nf">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">if</span> <span class="n">retrain</span><span class="p">:</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="nc">NaiveSE3DiffusionModel2</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>

    <span class="n">K</span> <span class="o">=</span> <span class="mi">30000</span>
    <span class="n">B</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">K</span><span class="p">)):</span>

        <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">EPS</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">+</span> <span class="n">EPS</span> <span class="c1"># t ~ 0 will cause numerical instability
</span>        <span class="n">std</span> <span class="o">=</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="c1"># compute scheuling of std at t=t, increasing with t
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="nf">get_sample_from_protein</span><span class="p">(</span><span class="n">B</span><span class="o">=</span><span class="n">B</span><span class="p">)</span> <span class="c1"># batch samples
</span>
        <span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span> <span class="o">=</span> <span class="nf">sample_from_se3_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span> <span class="c1"># noised samples
</span>
        <span class="n">v_tar</span> <span class="o">=</span> <span class="nf">se3_score_normal</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">x_tar</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">R_tar</span><span class="o">=</span><span class="n">R</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std</span><span class="p">)</span> <span class="c1"># estimate scores of noised samples
</span>
        <span class="n">v_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x_eps</span><span class="p">,</span> <span class="n">R_eps</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># predicted scores from model
</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">std</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(((</span><span class="n">v_pred</span> <span class="o">-</span> <span class="n">v_tar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># score matching loss
</span>        <span class="n">loss_trj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">loss_trj</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">detach</span><span class="p">()[</span><span class="bp">None</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Backward pass and optimization
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">loss_trj</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

    <span class="c1"># torch.save(model.state_dict(), 'model.pt')</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">if</span> <span class="ow">not</span> <span class="n">retrain</span><span class="p">:</span>
  <span class="n">model</span> <span class="o">=</span> <span class="nc">NaiveSE3DiffusionModel2</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">model.pt</span><span class="sh">'</span><span class="p">))</span>
<span class="n">H</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">get_sample_from_protein</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">H2</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="nf">sample_se3</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">get_sample_from_protein</span><span class="p">,</span> <span class="n">noise_on</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">H</span><span class="p">,</span> <span class="n">H2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1101</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">colors</span><span class="p">[:</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">colors</span><span class="p">[</span><span class="mi">1000</span><span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">H</span><span class="p">,</span> <span class="n">prot</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/ex3sample1.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">colors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">H</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">p</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">colors</span><span class="p">[:</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">colors</span><span class="p">[</span><span class="mi">1000</span><span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">scene</span> <span class="o">=</span> <span class="nf">visualize_grasps</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">H</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="n">colors</span><span class="p">.</span><span class="nf">numpy</span><span class="p">(),</span><span class="n">show</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">.</span><span class="nf">display</span><span class="p">(</span><span class="n">scene</span><span class="p">.</span><span class="nf">show</span><span class="p">())</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Green is the grund truth</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <iframe src="/assets/img/posts/se3diff/ex3sample2.html" frameborder="0" scrolling="yes" height="800px" width="100%" style="border: 1px dashed grey;"></iframe> <h3 id="5-final-remarks">5. Final remarks</h3> <hr/> <p>The SO(3) data can be transformed to the corresponding vector (axis angle) representation via the Log_map. Approximating SO(3) is equivalent to approximating the vector representation, at least in this notebook.</p> <p>Note here that we were doing a single SE(3) distribution, instead of modeling a set or an ordered set of SE(3) distributions, like proteins, robot joints. Therefore, the model is just a bunch of Linear layers. If that’s the problem we are interested, we are modeling the SE(3)\(^N\) distribution, where the interactions between each SE(3) will be critical, the model needs to be SE(3)-equivariant to respect the relative roto-translational information between SE(3)\(^N\). Such model was used in AlphaFold2 (IPA) or Rosettafold (SE(3)-Transformer).</p> <p>Hope you find this tutorial interesting and useful.</p> <h3 id="6-references">6. References</h3> <ol> <li>Urain et al, Learning Diffusion Models in SE(3) for 6DoF Grasp Pose Generation, (<a href="https://www.mirmi.tum.de/fileadmin/w00byb/mirmi/_my_direct_uploads/ICRA2023_Geometry_workshop.pdf">link</a>)</li> <li>Sola et al, A micro Lie theory for state estimation in robotics, (<a href="https://arxiv.org/abs/1812.01537">link</a>)</li> <li>Yim et al, SE(3) diffusion model with application to protein backbone generation, (<a href="https://arxiv.org/abs/2302.02277">link</a>)</li> </ol>]]></content><author><name></name></author><category term="models"/><category term="coding"/><summary type="html"><![CDATA[Approximating ANY SE(3) distributions]]></summary></entry><entry><title type="html">Walking through score-based diffusion with SDE</title><link href="https://jipq6175.github.io/blog/2023/score_diffusion/" rel="alternate" type="text/html" title="Walking through score-based diffusion with SDE"/><published>2023-09-09T21:45:00+00:00</published><updated>2023-09-09T21:45:00+00:00</updated><id>https://jipq6175.github.io/blog/2023/score_diffusion</id><content type="html" xml:base="https://jipq6175.github.io/blog/2023/score_diffusion/"><![CDATA[<h3 id="0-diffusion-model-using-score-matching-and-sde">0. Diffusion Model using Score Matching and SDE</h3> <p>Score matching is a technique that is used for the score-based genertive models, which regress on the scores, \(\nabla_x\log p(x)\) instead of modeling the original data distribution \(p(x)\). The score is the gradient of the data distribution so if we can access this gradient on every point of the data space, we can just follow this gradient and achieve the points with large probability density. This can be achieved by gradient ascend or Langevin dynamics which is similar to the stochastic gradient ascend.</p> \[x_{t+1} = x_t + \epsilon\nabla_x\log p(x) + \sqrt{2\epsilon} z\] <p>where \(z~N(0, I)\). The goal of training the score-based generative model is to approximate the scores using a neural network \(s_\theta(x) \approx \epsilon\nabla_x\log p(x)\) everywhere on \(x\). If we have such model, we can use the above Langevin dynamics for sampling, just replacing the score with model estimates:</p> \[x_{t+1} = x_t + \epsilon s_\theta(x) + \sqrt{2\epsilon} z\] <p>The score-matching objectve (or loss function) is the Fischer divergence between \(s_\theta(x)\) and \(\nabla_x\log p(x)\), weighted by \(p(x)\).</p> \[\mathbb{E}_{p(x)}||s_\theta(x) - \nabla_x\log p(x)||_2^2 = \int p(x)||s_\theta(x) - \nabla_x\log p(x)||_2^2\] <p>The main issue with this simple score-matching is that in regions where \(p(x) \approx 0\), the score extimate will be inaccurate due to the zero weighting in these regions. So if we start our sample in such region and try to follow the score (or gradient), we are doing some random walk and will never get closer to the modes of data distribution. This is more severe in the high-dimensional case where data distribution is like a bunch of spikes (delta functions) in the data space.</p> <p>The trick to solve this if to introduce noise to the data distribution, trying to widen the distribution and cover as much space as possible. The introduction of the noise will result in non-zero \(p_{\sigma_i}(\tilde{x}\mid x)\), where \(\tilde{x}\) is the noised data controlled by variance \(\sigma_i^2\), and cover larger data space for more accurate score estimate.</p> <p><br/></p> <h4 id="score-matching-with-langevin-dynamics-smld">Score Matching with Langevin Dynamics (SMLD)</h4> <p>One way is to add different noises with increasing variances \(\{\sigma_0^2, \sigma_1^2, ..., \sigma_N^2\}\), as proposed in the Noise Conditional Score Network (NCSN). The network \(s_\theta(x)\) now need to be noise-conditioned, \(s_\theta(x, \sigma)\) in order to match the scores at diferent variances. The NSCN objective is now</p> \[\sum_{i=1}^N \sigma_i^2 \mathbb{E}_{p(x)}\mathbb{E}_{p_{\sigma_i}(\tilde{x} \mid x)} || s(\tilde{x}, \sigma_i) - \nabla_{\tilde{x}}\log p_{\sigma_i}(\tilde{x}\mid x) ||_2^2\] <h4 id="denoising-diffusion-probabilistic-model-ddpm">Denoising Diffusion Probabilistic Model (DDPM)</h4> <p>Another way is to add noise via a discrete Markov chain, \(p(x_i \mid x_{i-1}) = \mathcal{N}(x_i, \sqrt{1-\beta_i}x_{i-1}, \beta_i I)\). Notice that this Markov chain attenuates the signal and adds noise, instead of just adding noise to overwhelm the signal as done in SMLD. The DDPM objective is now</p> \[\sum_{i=1}^N (1-\alpha_i) \mathbb{E}_{p(x)}\mathbb{E}_{p_{\alpha_i}(\tilde{x}\mid x)} || s(\tilde{x}, i) - \nabla_{\tilde{x}}\log p_{\alpha_i}(\tilde{x}\mid x) ||_2^2\] <p>Notice the similarity between the objectives of SMLD and DDPM.</p> <p><br/></p> <h3 id="1-general-continuous-time-diffusion">1. General Continuous-Time Diffusion</h3> <p>The SMLD and DDPM were descrete-time, with a pre-defined variance schedule: \(\sigma_i^2\) for SMLD and \(\beta_i\) for DDPM. A general case of adding noise to data is to use stochastic differential equations (SDEs), which involves adding gaussian noise (or Brownian motion).</p> \[dx = f(x, t)dt + g(t)dw\] <p>where \(f(x, t)\) is the drift term that depends on current \(x\) and time \(t\). \(g(t)\) is the diffusion term, controlling how much noise to add to the data at certain time \(t\) and \(dw\) is the infinitesimal Brownian motion. With this predefined stochastic process, the time reveral of the SDE has close form</p> \[dx = [f(x, t) - g^2(t) \nabla_x\log p_t(x)]dt + g(t)dw\] <p>Note that here, in the time reversal, \(dt &lt; 0\), so we are actually reversing the drift and following along the gradient (in the same direction of the score). We now just need to have a time-conditioned score model \(s_\theta(x, t)\) that matches \(\nabla_x\log p_t(x)\) everywhere, everytime.</p> <p>There is also a guarantee that the distribution of \(x(t)\) following this SDE, is a normal distribution with mean \(m(t)\) and variance \(v(t)\). So we can write down the perturbation kernel or transitional kernel from data \(x(0)\) to noised data \(x(t)\):</p> \[p_{0t}\left(x(t) | x(0) \right) = \mathcal{N}\left(x(t); m(t), v(t)I \right)\] <p>We are just writing this down for derivation of \(m(t)\) and \(v(t)\) later. Note here that the data is actually multi-dimensional, but each dimensional is treated as independent, so we can just treat everything in scalar form and write $I$ for the variance.</p> <p>The denoising score matching objective is now</p> \[\mathcal{L}_{dsm} = \mathbb{E}_t \lambda(t) \mathbb{E}_{x(0)} \mathbb{E}_{x(t)\mid x(0)} || s_\theta(x(t), t) - \nabla_{x(t)}\log p_{0t}\left(x(t) \mid x(0) \right)||_2^2\] <p>\(\lambda(t)\) is the positive time-dependent weighting and is proportional to the variance squared \(v^2(t)\) as done in SMLD and DDPM. In the maximum likelihood training proposed later, \(\lambda(t)\) is proportional to the diffusion term squared \(g^2(t)\).</p> <p>The gradient term can be easily calculated in exact form since \(p_{0t}\) is a gaussian:</p> \[\nabla_{x(t)}\log p_{0t}\left(x(t) \mid x(0) \right) = \nabla_{x(t)}\log \mathcal{N}\left(x(t); m(t), v(t)I \right) = -\frac{x(t) - m(t)}{v(t)}\] <p>How do we compute \(x(t)\) in practice? Again, using \(p_{0t}\):</p> \[x(t) = m(t) + \sqrt{v(t)}z; z\sim \mathcal{N}(z; 0, I)\] <p>Plug \(x(t) - m(t) = \sqrt{v(t)}z\) above and then \(\mathcal{L}_{dsm}\) yields:</p> \[\mathcal{L}_{dsm} = \mathbb{E}_t \lambda(t) \mathbb{E}_{x(0)} \mathbb{E}_{x(t)\mid x(0)} \left|\left| s_\theta(x(t), t) + \frac{z}{\sqrt{v(t)}}\right|\right|_2^2\] <p>The critical components are \(m(t)\) and \(v(t)\). Once we have them, we can compute the loss and train the score model.</p> <p><br/></p> <h4 id="sde-for-smld-ve-sde">SDE for SMLD (VE-SDE)</h4> <p>The discrete-time Markov chain for SMLD is \(x_i = x_{i-1} + \sqrt{\sigma_i^2 - \sigma_{i-1}^2} z_{i-1}\). In the continuous-time generalization:</p> \[x(t+\Delta t) = x(t) + \sqrt{\sigma^2(t+\Delta t) - \sigma^2(t)}z(t) \approx x(t) + \sqrt{\frac{d\sigma^2(t)}{dt}\Delta t}z(t)\] <p>We combine \(\sqrt{\Delta t}z(t) = dw\). The continuous-time SMLD is then</p> \[dx = \sqrt{\frac{d\sigma^2(t)}{dt}}dw\] <p>which is also called variance-exploding SDE (VE-SDE).</p> <h4 id="sde-for-ddpm-vp-sde">SDE for DDPM (VP-SDE)</h4> <p>The discrete-time Markov chain for DDPM is \(x_i = \sqrt{1-\beta_i}x_{i-1} + \sqrt{\beta_i}z_{i-1}\). In the continuous-time generalization:</p> \[x(t+\Delta t) = \sqrt{1-\beta(t+\Delta t)\Delta t}x(t) + \sqrt{\beta(t+\Delta t)\Delta t}z(t) \approx x(t) - \frac{1}{2}\beta(t+\Delta t)\Delta t x(t) + \sqrt{\beta(t)\Delta t}z(t)\] <p>We combine \(\sqrt{\Delta t}z(t) = dw\). The continuous0time DDPM is then</p> \[dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)}dw\] <p>which is also called variance-preserving SDE (VP-SDE).</p> <p><br/></p> <h3 id="2-marginal-mean-and-variance-from-sde">2. Marginal mean and variance from SDE</h3> <p>Now we will use the SDEs to derive \(m(t)\) and \(v(t)\) for the mean and variance of the perturbation kernel \(p_{0t}\)</p> <p>Given an SDE with affine continuous function $f$ and $g$,</p> \[dx = f(x, t)dt + g(x, t)dw\] <p>Let</p> \[f(x, t) = A(t)x(t) + a(t)\] \[g(x, t) = B(t)x(t) + b(t)\] <p>and</p> \[\mathbb{E}[x(t)] = m(t)\] \[\mathbb{Var}[x(t)] = v(t)\] <p>will satisfy the following ODEs with initial conditions:</p> \[m'(t) = A(t)m(t) + a(t); m(0) = m_0\] \[v'(t) = 2A(t)v(t) + b^2(t); v(0) = v_0\] <p><br/></p> <h3 id="3-solving-variable-coefficient-odes">3. Solving variable coefficient ODEs</h3> <p>The above ODEs are variable coefficient ODEs and have general solution. The general ODE \(y'(t) = a(t)y(t) + b(t)\) has solution</p> \[y(t) = Ce^{A(t)} + e^{A(t)}\int e^{-A(t)}b(t)dt\] <p>where</p> \[A(t) = \int a(t)dt\] <p><br/></p> <h3 id="4-deriving-perturbation-kernels-from-sde">4. Deriving perturbation kernels from SDE</h3> <p>The perturbation kernel \(p_{0t}\) for SDE here is Gaussian. We are after the mean \(m(t)\) and variance \(v(t)\) for the distribution of \(x(t)\) given initial data point \(x(0)\). Note that because \(x(0)\) is out data point and we treat its distribution as a delta function, or a super tight gaussian with mean \(x(0)\) and variance \(v(0)=0I\).</p> <p><br/></p> <h3 id="ve-sde">VE-SDE</h3> \[dx = \sqrt{\frac{d\sigma^2(t)}{dt}}dw\] <p>Using the above notation, \(A(t) = a(t) = B(t) = 0\) and \(b(t) = \sqrt{d\sigma^2(t)/dt}\).</p> \[m'(t) = 0 \Rightarrow m(t) = c = x(0)\] \[v'(t) = b^2(t) = \frac{d\sigma^2(t)}{dt} \Rightarrow v(t) = \sigma^2(t) + c = \sigma^2(t)\] <p>Therefore,</p> \[p_{0t}(x(t) | x(0)) = \mathcal{N}\left(x(t); x(0), \sigma^2(t)I \right)\] <p><br/></p> <h3 id="vp-sde">VP-SDE</h3> \[dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)}dw\] <p>\(a(t) = B(t) = 0\), \(A(t) = -\beta(t)/2\) and \(b(t) = \sqrt{\beta(t)}\). Plug in the ODEs:</p> \[m'(t) = -\frac{1}{2} \beta(t)m(t) \Rightarrow m(t) = Ce^{\int_0^t-\frac{1}{2}\beta(s)ds} = x(0)e^{\int_0^t-\frac{1}{2}\beta(s)ds}\] \[v'(t) = -\beta(t)v(t)+\beta(t)\] \[v(t) = Ce^{-\int\beta(t)dt} + e^{-\int\beta(t)dt}\int e^{\int\beta(t)dt}\beta(t)dt = Ce^{-\int\beta(t)dt} + 1; v(0)=0 \Rightarrow C=-1\] \[v(t) = 1 - e^{-\int\beta(t)dt}\] <p>Therefore,</p> \[p_{0t}(x(t) | x(0)) = \mathcal{N}\left(x(t); x(0)e^{\int_0^t-\frac{1}{2}\beta(s)ds}, (1 - e^{-\int_0^t\beta(s)ds})I \right)\] <p><br/></p> <h3 id="sub-vp-sde">sub VP-SDE</h3> <p>In the score-based SDE model, the author introduces another SDE called sub-VP SDE</p> \[dx = -\frac{1}{2}\beta(t)dt + \sqrt{\beta(t)\left(1-e^{-2\int_0^t\beta(s)ds} \right)}dw\] <p>Now we only change the \(b(t)\) so \(m(t)\) remains the same as VP-SDE.</p> \[v'(t) = -\beta(t)v(t) + \beta(t)\left(1-e^{-2\int_0^t\beta(s)ds} \right)\] \[v(t) = Ce^{-\int\beta(t)dt} + e^{-\int\beta(t)dt}\int e^{\int\beta(t)dt}\beta(t)dt + e^{-\int\beta(t)dt}\int e^{-\int\beta(t)dt}\beta(t)dt\] <p>The first two terms are the same as before:</p> \[v(t) =Ce^{-\int_0^t\beta(s)ds} + 1 + e^{-\int_0^t\beta(s)ds}e^{-\int_0^t\beta(s)ds} = Ce^{-\int_0^t\beta(s)ds} + 1 + e^{-2\int_0^t\beta(s)ds}\] <p>With $v(0) = 0 \Rightarrow C = -2$</p> \[v(t) = -2e^{-\int_0^t\beta(s)ds} + 1 + e^{-2\int_0^t\beta(s)ds} = \left(1-e^{-\int_0^t\beta(s)ds}\right)^2\] <p>Therefore,</p> \[p_{0t}(x(t) | x(0)) = \mathcal{N}\left(x(t); x(0)e^{\int_0^t-\frac{1}{2}\beta(s)ds}, \left(1 - e^{-\int_0^t\beta(s)ds}\right)^2I \right)\] <p>Note that the variance of sub VP-SDE is bounded by (or always less than) the variance of VP-SDE.</p> \[\forall t &gt; 0; \left(1 - e^{-\int_0^t\beta(s)ds}\right)^2 \le 1 - e^{-\int_0^t\beta(s)ds}\] <p>These 3 SDEs appear in Eq.(29) of [1] and Table 1 of [2]. In the following code, we will use VE-SDE as an example.</p> <h3 id="5-notebook">5. Notebook</h3> <p>The original notebook is provided by the author: <a href="https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing">Google Colab</a>.</p> <p>Most of the cells contain similar code to the DDPM, especially the time-conditional UNet model. I’ll just pick the cells I did not grasp during the first pass. If I have time after work, I might implement all the training and sampling for the above 3 SDEs.</p> <p><br/></p> <h4 id="cell-5">Cell #5</h4> <p>Cell #5 sets up the VE-SDE scheduling for the diffusion coefficient \(g(t)\) and standard deviation \(\sqrt{v(t)}\). Note that in VE-SDE \(f(x, t) = 0\) so the mean of \(x(t)\): \(m(t) = 0\).</p> <p>We set up the Stochastic Differential Equation (VE-SDE) as the following</p> \[dx = \sigma^t dw\] <p>where \(\sigma &gt; 1.0\) is the standard deviation by design and \(dw\) is the Wiener process.</p> <p>This setup is not unique. The marginal probability standard deviation can be customized. The marginal probability variance is then</p> \[v(t) = \int_0^t g(s)^2ds\] <p>One can try different type of SDEs. One can verify that if \(g(t) = \sigma^t\) then</p> \[v(t) = \frac{\sigma^{2t} - 1}{2\log{\sigma}}\] <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Set up the VE-SDE: dx = sigma^t dw
</span>
<span class="k">def</span> <span class="nf">diffusion_coeff</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Compute the diffusion coefficient of our SDE.

    Args:
        t: A vector of time steps.
        sigma: The $\sigma$ in our SDE.

    Returns:
        The vector of diffusion coefficients.
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="n">t</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Compute the standard deviation of $p_{0t}(x(t) | x(0))$.

    Args:    
        t: A vector of time steps.
        sigma: The $\sigma$ in our SDE.  

    Returns:
        The standard deviation.
    </span><span class="sh">"""</span>    
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="nf">clone</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">((</span><span class="n">sigma</span><span class="o">**</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">))</span>


<span class="n">sigma</span> <span class="o">=</span> <span class="mf">25.</span>
<span class="n">marginal_prob_std_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">marginal_prob_std</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
<span class="n">diffusion_coeff_fn</span> <span class="o">=</span> <span class="n">functools</span><span class="p">.</span><span class="nf">partial</span><span class="p">(</span><span class="n">diffusion_coeff</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span></code></pre></figure> <p><br/></p> <h4 id="cell-6">Cell #6</h4> <p>Cell #6 sets up the loss function for the training objective. Recall that the score-function \(s_\theta(x, t)\) has to match \(\nabla_{x(t)}\log p_t(x(t))\) at everytime for every training data \(x(0)\). The DSM loss is then the regression loss.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Loss function: similar to the MSE loss 3
</span><span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">marginal_prob_std</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">The loss function for training score-based generative models.

    Args:
        model: A PyTorch model instance that represents a time-dependent score-based model.
        x: A mini-batch of training data.    
        marginal_prob_std: A function that gives the standard deviation of the perturbation kernel.
        eps: A tolerance value for numerical stability.
    </span><span class="sh">"""</span>
    <span class="c1"># x is the original signal, without purturbation or noising
</span>
    <span class="c1"># uniformly sample random_t in [0, 1] using the batch dimension
</span>    <span class="n">random_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span> 

    <span class="c1"># Random Gaussian Noises
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 

    <span class="c1"># Compute the std at these time points
</span>    <span class="n">std</span> <span class="o">=</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">random_t</span><span class="p">)</span> 

    <span class="c1"># forward computation p(x(t) | x(0)) = N(x(0), v(t))
</span>    <span class="n">perturbed_x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">z</span> <span class="o">*</span> <span class="n">std</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> 

    <span class="c1"># compute the score 
</span>    <span class="n">score</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">perturbed_x</span><span class="p">,</span> <span class="n">random_t</span><span class="p">)</span> 

    <span class="c1"># true_score = - (x(t) - x(0)) / (std_t ^ 2)
</span>    <span class="c1">#            = - z_t / std_t
</span>    <span class="c1"># L_dsm = (pred_score - true_score) ^ 2 = (pred_score + z_t / std_t) ^ 2
</span>    <span class="c1"># scaled_L_dsm = (pred_score * std_t + z_t) ^ 2
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">score</span> <span class="o">*</span> <span class="n">std</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span> 
    <span class="k">return</span> <span class="n">loss</span></code></pre></figure> <p><br/></p> <h4 id="cell-8">Cell #8</h4> <p>Cell #8 prepares sampling with 3 different methods: Euler-Maruyama, Predictor-Corrector and ODE.</p> <h5 id="euler-maruyama">Euler-Maruyama</h5> <p>Recall that SDE of the form</p> \[dx = f(x, t)dt + g(t)dw\] <p>has the reverse-time SDE:</p> \[dx = \left[f(x, t) - g^2(t)\nabla_{x(t)}\log p_t(x(t)) \right]dt + g(t)dw\] \[dx = -\sigma^{2t} s_\theta(x, t) dt + \sigma^t dw; dt &lt; 0\] \[x_{t-\Delta t} = \mathbf{x}_t + \sigma^{2t} s_\theta(x_t, t)\Delta t + \sigma^t\sqrt{\Delta t} z_t\] <p>where \(z_t \sim \mathcal{N}(0, I)\).</p> <p>Euler-Maruyama applies \(dt \sim \Delta t\) discretization.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">500</span>
<span class="k">def</span> <span class="nf">Euler_Maruyama_sampler</span><span class="p">(</span><span class="n">score_model</span><span class="p">,</span> 
                           <span class="n">marginal_prob_std</span><span class="p">,</span>
                           <span class="n">diffusion_coeff</span><span class="p">,</span> 
                           <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
                           <span class="n">num_steps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span> 
                           <span class="n">device</span><span class="o">=</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">,</span> 
                           <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Generate samples from score-based models with the Euler-Maruyama solver.

    Args:
        score_model: A PyTorch model that represents the time-dependent score-based model.
        marginal_prob_std: A function that gives the standard deviation of the perturbation kernel.
        diffusion_coeff: A function that gives the diffusion coefficient of the SDE.
        batch_size: The number of samplers to generate by calling this function once.
        num_steps: The number of sampling steps. Equivalent to the number of discretized time steps.
        device: </span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="s"> for running on GPUs, and </span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="s"> for running on CPUs.
        eps: The smallest time step for numerical stability.
    
    Returns:
        Samples.
    </span><span class="sh">"""</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">init_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="n">time_steps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">time_steps</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">init_x</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">time_step</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">time_steps</span><span class="p">):</span>      
            <span class="n">batch_time_step</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">time_step</span>
            <span class="n">g</span> <span class="o">=</span> <span class="nf">diffusion_coeff</span><span class="p">(</span><span class="n">batch_time_step</span><span class="p">)</span>
            
            <span class="c1"># mean_x = x + g^2(t) s(x, t) dt
</span>            <span class="n">mean_x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="n">g</span><span class="o">**</span><span class="mi">2</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_time_step</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_size</span> 
            
            <span class="c1"># x = mean_x + g(t) \sqrt{dt} z; z ~ N(0, I)
</span>            <span class="n">x</span> <span class="o">=</span> <span class="n">mean_x</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">step_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">g</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
    
    <span class="c1"># Do not include any noise in the last sampling step.
</span>    <span class="k">return</span> <span class="n">mean_x</span></code></pre></figure> <p><br/></p> <h5 id="predictor-corrector">Predictor-Corrector</h5> <p>Recall that given the score function \(s_\theta(x, t)\), we can sample via Langevin dynamics:</p> \[x_{i+1} = x_i + \epsilon \nabla_{x_i} \log p(x_i) + \sqrt{2\epsilon} z_i\] <p>The PC sampling combines the ODE/SDE solver (Predictor) with $N$ steps of local Langevin dynamics (Correcor).</p> <ol> <li>Predictor: Use ODE/SDE solver for the next time step $x(t-dt)$ using $s(x(t), t)$</li> <li>Corrector: Still using the score $s(x(t-dt), t-dt)$ and Langevin dynamics to correct for $x(t-dt)$ for $N$ steps</li> </ol> <p>The step size \(\epsilon\) is determined with predefined \(r\):</p> \[\epsilon = 2 \left(r \frac{\|z\|_2}{\|\nabla_{x} \log p(x)\|_2}\right)^2\] <p>which is determined by the norm of the score. The idea behind is like the adaptive step size in the stochastic gradient descent where we want to take a smaller (more careful) step when the score/gradient (slope) is steep to avoid overshoot (or sliding).</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">signal_to_noise_ratio</span> <span class="o">=</span> <span class="mf">0.16</span> 

<span class="c1">## The number of sampling steps.
</span><span class="n">num_steps</span> <span class="o">=</span>  <span class="mi">500</span>
<span class="k">def</span> <span class="nf">pc_sampler</span><span class="p">(</span><span class="n">score_model</span><span class="p">,</span> 
               <span class="n">marginal_prob_std</span><span class="p">,</span>
               <span class="n">diffusion_coeff</span><span class="p">,</span>
               <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
               <span class="n">num_steps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span> 
               <span class="n">snr</span><span class="o">=</span><span class="n">signal_to_noise_ratio</span><span class="p">,</span>                
               <span class="n">device</span><span class="o">=</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">,</span>
               <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Generate samples from score-based models with Predictor-Corrector method.

    Args:
    score_model: A PyTorch model that represents the time-dependent score-based model.
    marginal_prob_std: A function that gives the standard deviation
      of the perturbation kernel.
    diffusion_coeff: A function that gives the diffusion coefficient 
      of the SDE.
    batch_size: The number of samplers to generate by calling this function once.
    num_steps: The number of sampling steps. 
      Equivalent to the number of discretized time steps.    
    device: </span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="s"> for running on GPUs, and </span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="s"> for running on CPUs.
    eps: The smallest time step for numerical stability.

    Returns: 
    Samples.
    </span><span class="sh">"""</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">init_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="n">time_steps</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">time_steps</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">init_x</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">time_step</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">time_steps</span><span class="p">):</span>      
            <span class="n">batch_time_step</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">time_step</span>
            
            
            <span class="c1"># N = 1, Corrector step (Langevin MCMC)
</span>            <span class="c1"># for N &gt; 1, just wrap this part in a loop, but it will be expensive
</span>            <span class="n">grad</span> <span class="o">=</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_time_step</span><span class="p">)</span>
            <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">grad</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="n">grad</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
            <span class="n">noise_norm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">prod</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>

            <span class="c1"># eps = 2 (r |z| / |g|) ^ 2
</span>            <span class="n">langevin_step_size</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">snr</span> <span class="o">*</span> <span class="n">noise_norm</span> <span class="o">/</span> <span class="n">grad_norm</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> 
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">langevin_step_size</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">langevin_step_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


            <span class="c1"># Predictor step (Euler-Maruyama)
</span>            <span class="n">g</span> <span class="o">=</span> <span class="nf">diffusion_coeff</span><span class="p">(</span><span class="n">batch_time_step</span><span class="p">)</span>
            <span class="n">x_mean</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="n">g</span><span class="o">**</span><span class="mi">2</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_time_step</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_size</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x_mean</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">g</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      

    <span class="c1"># The last step does not include any noise
</span>    <span class="k">return</span> <span class="n">x_mean</span></code></pre></figure> <p><br/></p> <h5 id="probability-flow-ode">Probability flow ODE</h5> <p>For probability flow ODE, the reverse process:</p> \[dx = \left[f(x, t) - \frac{1}{2}g^2(t)\nabla_{x(t)}\log p_t(x(t)) \right]dt\] \[dx = -\frac{1}{2}\sigma^{2t} s_\theta(x, t) dt\] \[\frac{dx}{dt} = -\frac{1}{2}\sigma^{2t} s_\theta(x, t)\] <p>Now we need to integrate from \(t=T\) to \(t=0\)</p> \[x(t) = \int_T^t\frac{dx}{dt} dt + x(T) = \int_T^t -\frac{1}{2}\sigma^{2t} s_\theta(x, t) dt + x(T)\] \[x(0) = \int_T^0 -\frac{1}{2}\sigma^{2t} s_\theta(x, t) dt + x(T)\] <p>the above can be solved using existent ODE solver, such as Runge-Kutta.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">integrate</span>

<span class="c1">## The error tolerance for the black-box ODE solver
</span><span class="n">error_tolerance</span> <span class="o">=</span> <span class="mf">1e-5</span> 
<span class="k">def</span> <span class="nf">ode_sampler</span><span class="p">(</span><span class="n">score_model</span><span class="p">,</span>
                <span class="n">marginal_prob_std</span><span class="p">,</span>
                <span class="n">diffusion_coeff</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
                <span class="n">atol</span><span class="o">=</span><span class="n">error_tolerance</span><span class="p">,</span> 
                <span class="n">rtol</span><span class="o">=</span><span class="n">error_tolerance</span><span class="p">,</span> 
                <span class="n">device</span><span class="o">=</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">,</span> 
                <span class="n">z</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                <span class="n">eps</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Generate samples from score-based models with black-box ODE solvers.

    Args:
    score_model: A PyTorch model that represents the time-dependent score-based model.
    marginal_prob_std: A function that returns the standard deviation 
      of the perturbation kernel.
    diffusion_coeff: A function that returns the diffusion coefficient of the SDE.
    batch_size: The number of samplers to generate by calling this function once.
    atol: Tolerance of absolute errors.
    rtol: Tolerance of relative errors.
    device: </span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="s"> for running on GPUs, and </span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="s"> for running on CPUs.
    z: The latent code that governs the final sample. If None, we start from p_1;
      otherwise, we start from the given z.
    eps: The smallest time step for numerical stability.
    </span><span class="sh">"""</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># Create the latent code
</span>    <span class="k">if</span> <span class="n">z</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">init_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">t</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">init_x</span> <span class="o">=</span> <span class="n">z</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">init_x</span><span class="p">.</span><span class="n">shape</span>

    <span class="k">def</span> <span class="nf">score_eval_wrapper</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">A wrapper of the score-based model for use by the ODE solver.</span><span class="sh">"""</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">((</span><span class="n">sample</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">))</span>    
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> 
            <span class="n">score</span> <span class="o">=</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">ode_func</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>        
        <span class="sh">"""</span><span class="s">The ODE function for use by the ODE solver.
           dx = - 0.5 * g^2(x) * s(x, t) dt
        </span><span class="sh">"""</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span> <span class="o">*</span> <span class="n">t</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nf">diffusion_coeff</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)).</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
        <span class="k">return</span>  <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">g</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="nf">score_eval_wrapper</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">)</span>

    <span class="c1"># Run the black-box ODE solver.
</span>    <span class="c1"># solving x' = dx / dt = - 0.5 * g^2(x) * s(x, t); x(0) = x_0 = init_x
</span>    <span class="c1"># note solving from t = 1 to t = 0
</span>    <span class="n">res</span> <span class="o">=</span> <span class="n">integrate</span><span class="p">.</span><span class="nf">solve_ivp</span><span class="p">(</span><span class="n">ode_func</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">eps</span><span class="p">),</span> <span class="n">init_x</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">RK45</span><span class="sh">'</span><span class="p">)</span>  
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of function evaluations: </span><span class="si">{</span><span class="n">res</span><span class="p">.</span><span class="n">nfev</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span></code></pre></figure> <p><br/></p> <p>The results of the above sampling methods are shown below. From left to right are: Euler-Maruyama, Predictor-Corrector and Probability flow ODE.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/sde/em-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/sde/em-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/sde/em-1400.webp"/> <img src="/assets/img/posts/sde/em.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/sde/pc-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/sde/pc-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/sde/pc-1400.webp"/> <img src="/assets/img/posts/sde/pc.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/sde/ode-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/sde/ode-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/sde/ode-1400.webp"/> <img src="/assets/img/posts/sde/ode.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><br/></p> <h3 id="6-likelihood-computation">6. Likelihood Computation</h3> <p>We can compute the likelihood \(\log p_0(x(0))\) using</p> \[\log p_0(x(0)) = \log p_T(x(T)) + \int_0^T \nabla \cdot \left[ -\frac{1}{2}\sigma^{2t} s_\theta(x, t) \right] dt\] <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># likelihood
</span>
<span class="c1">#@title Define the likelihood function (double click to expand or collapse)
</span>
<span class="k">def</span> <span class="nf">prior_likelihood</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">The likelihood of a Gaussian distribution with mean zero and 
      standard deviation sigma.</span><span class="sh">"""</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">z</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">N</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ode_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> 
                   <span class="n">score_model</span><span class="p">,</span>
                   <span class="n">marginal_prob_std</span><span class="p">,</span> 
                   <span class="n">diffusion_coeff</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> 
                   <span class="n">device</span><span class="o">=</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">,</span>
                   <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Compute the likelihood with probability flow ODE.

    Args:
    x: Input data.
    score_model: A PyTorch model representing the score-based model.
    marginal_prob_std: A function that gives the standard deviation of the 
      perturbation kernel.
    diffusion_coeff: A function that gives the diffusion coefficient of the 
      forward SDE.
    batch_size: The batch size. Equals to the leading dimension of `x`.
    device: </span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="s"> for evaluation on GPUs, and </span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="s"> for evaluation on CPUs.
    eps: A `float` number. The smallest time step for numerical stability.

    Returns:
    z: The latent code for `x`.
    bpd: The log-likelihoods in bits/dim.
    </span><span class="sh">"""</span>

    <span class="c1"># Draw the random Gaussian sample for Skilling-Hutchinson's estimator.
</span>    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      
    <span class="k">def</span> <span class="nf">divergence_eval</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">):</span>      
        <span class="sh">"""</span><span class="s">Compute the divergence of the score-based model with Skilling-Hutchinson.</span><span class="sh">"""</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">enable_grad</span><span class="p">():</span>
            <span class="n">sample</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">score_e</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="nf">score_model</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">)</span> <span class="o">*</span> <span class="n">epsilon</span><span class="p">)</span>
            <span class="n">grad_score_e</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="n">score_e</span><span class="p">,</span> <span class="n">sample</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">grad_score_e</span> <span class="o">*</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>    

    <span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>

    <span class="k">def</span> <span class="nf">score_eval_wrapper</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">A wrapper for evaluating the score-based model for the black-box ODE solver.</span><span class="sh">"""</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">((</span><span class="n">sample</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">))</span>    
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>    
            <span class="n">score</span> <span class="o">=</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">divergence_eval_wrapper</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">A wrapper for evaluating the divergence of score for the black-box ODE solver.</span><span class="sh">"""</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="c1"># Obtain x(t) by solving the probability flow ODE.
</span>            <span class="n">sample</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">time_steps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">reshape</span><span class="p">((</span><span class="n">sample</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">))</span>    
            <span class="c1"># Compute likelihood.
</span>            <span class="n">div</span> <span class="o">=</span> <span class="nf">divergence_eval</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">div</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">ode_func</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">The ODE function for the black-box solver.</span><span class="sh">"""</span>
        <span class="n">time_steps</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span> <span class="o">*</span> <span class="n">t</span>    
        <span class="n">sample</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">logp</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:]</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nf">diffusion_coeff</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)).</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
        <span class="n">sample_grad</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">g</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="nf">score_eval_wrapper</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">)</span> <span class="c1"># dx / dt
</span>        <span class="n">logp_grad</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">g</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="nf">divergence_eval_wrapper</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">)</span> <span class="c1"># d logp / dt
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">sample_grad</span><span class="p">,</span> <span class="n">logp_grad</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># d[x, logp] / dt
</span>
    <span class="c1"># logp_0(x(0)) = logp_T(x(T)) + int_0^T \nabla f(x(t), t)
</span>    <span class="n">init</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">x</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Black-box ODE solver
</span>    <span class="c1"># note solving from t = 0 to t = 1, different from the reverse one
</span>    <span class="n">res</span> <span class="o">=</span> <span class="n">integrate</span><span class="p">.</span><span class="nf">solve_ivp</span><span class="p">(</span><span class="n">ode_func</span><span class="p">,</span> <span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">init</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">RK45</span><span class="sh">'</span><span class="p">)</span>  
    
    <span class="n">zp</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="c1"># [x(1), logp(1)]
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">zp</span><span class="p">[:</span><span class="o">-</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># x(1)
</span>    <span class="n">delta_logp</span> <span class="o">=</span> <span class="n">zp</span><span class="p">[</span><span class="o">-</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># logp(1)
</span>    <span class="n">sigma_max</span> <span class="o">=</span> <span class="nf">marginal_prob_std</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">]))</span>
    <span class="c1"># print(sigma_max)
</span>    
    <span class="c1"># compute likelihood of x(T)
</span>    <span class="n">prior_logp</span> <span class="o">=</span> <span class="nf">prior_likelihood</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sigma_max</span><span class="p">)</span> 
    
    <span class="c1"># bits per dimension
</span>    <span class="n">bpd</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">prior_logp</span> <span class="o">+</span> <span class="n">delta_logp</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># log_2 (x) = log(x) / log(2)
</span>    <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>

    <span class="c1"># we treat the gray scale [0, 1.] as [0., 256], so we have to add log_2(256) = 8 to each dimension
</span>    <span class="c1"># or according to the def: bpd = -(prior_logp + delta_logp - log(256)) / log(2)
</span>    <span class="c1">#                              = -(prior_logp + delta_logp) / log(2) + 8.
</span>    <span class="n">bpd</span> <span class="o">=</span> <span class="n">bpd</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="mf">8.</span> 
    
    <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">bpd</span></code></pre></figure> <p>We can use the above to compute the likelihood as bits per dimension, the lower the better.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="nc">MNIST</span><span class="p">(</span><span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>


<span class="n">all_bpds</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">all_items</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span> <span class="k">break</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># uniform dequantization
</span>        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="mf">255.</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="mf">256.</span>    
        <span class="n">_</span><span class="p">,</span> <span class="n">bpd</span> <span class="o">=</span> <span class="nf">ode_likelihood</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">score_model</span><span class="p">,</span> <span class="n">marginal_prob_std_fn</span><span class="p">,</span>
                                <span class="n">diffusion_coeff_fn</span><span class="p">,</span>
                                <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
        <span class="n">all_bpds</span> <span class="o">+=</span> <span class="n">bpd</span><span class="p">.</span><span class="nf">sum</span><span class="p">()</span>
        <span class="n">all_items</span> <span class="o">+=</span> <span class="n">bpd</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Average bits/dim: {:5f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">all_bpds</span> <span class="o">/</span> <span class="n">all_items</span><span class="p">))</span>

<span class="k">except</span> <span class="nb">KeyboardInterrupt</span><span class="p">:</span> <span class="k">raise</span>

<span class="c1"># Average bits/dim: 1.710447
# Average bits/dim: 1.658721</span></code></pre></figure> <p><br/></p> <h3 id="7-references">7. References</h3> <ol> <li>Song et al, Score-Based Generative Modeling through Stochastic Differential Equations, (<a href="https://openreview.net/forum?id=PxTIG12RRHS">link</a>)</li> <li>Song et al, Maximum Likelihood Training of Score-Based Diffusion Models, (<a href="https://arxiv.org/abs/2101.09258">link</a>)</li> <li>Original PyTorch Implementation: <a href="https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing">Google Colab</a></li> <li>Blog post on Score-Based SDE <a href="https://yang-song.net/blog/2021/score/">link</a></li> </ol>]]></content><author><name></name></author><category term="models"/><category term="reading"/><category term="solving"/><summary type="html"><![CDATA[Some derivations and calculations of DSM with SDE]]></summary></entry><entry><title type="html">Neural Networks with Euclidean Symmetries - 2</title><link href="https://jipq6175.github.io/blog/2023/e3nn_2/" rel="alternate" type="text/html" title="Neural Networks with Euclidean Symmetries - 2"/><published>2023-07-14T23:54:00+00:00</published><updated>2023-07-14T23:54:00+00:00</updated><id>https://jipq6175.github.io/blog/2023/e3nn_2</id><content type="html" xml:base="https://jipq6175.github.io/blog/2023/e3nn_2/"><![CDATA[<p>After playing with <code class="language-plaintext highlighter-rouge">e3nn</code> and a toy example with the tetris shape classification, I am going to move from the invariant model to equivariant model, which outputs type-1 (\(l=1\)) feature like 3D coordinates or even higher order tensors. This example is to predict the trajectories of the many-body dynamics, which is adopted from the <a href="https://dmol.pub/">dmol book</a> <a href="https://dmol.pub/applied/e3nn_traj.html">Ch. 19</a>.</p> <h1 id="2-trajectory-prediction">2. Trajectory Prediction</h1> <p>Given a position snapshot of a connected 12-body system at time \(t\), \(x(t)\), predict the positions of each particle at \(t+\Delta t\), i.e. \(x(t+\Delta t)\).</p> <p>The data can be found <a href="https://github.com/whitead/dmol-book/raw/main/data/paths.npz">here</a></p> <p>Let’s first take a look at the first frame, the second frame and later frames:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/body12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/body12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/body12-1400.webp"/> <img src="/assets/img/posts/e3nn/body12.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Given a snapshot, our equivariant model can be trained to predict the coordinates of the next frame \(x(t+\Delta t)\) or the displacement \(\Delta x = x(t + \Delta t) - x(t)\). These two objectives might have different 3D distributions. The later turns out to be easier to model and we will focus on predicting the delta.</p> <h2 id="21-packages">2.1 Packages</h2> <p>Here we load the required packages and set up global parameters:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># imports 
</span><span class="kn">import</span> <span class="n">torch</span><span class="p">,</span> <span class="n">e3nn</span><span class="p">,</span> <span class="n">urllib</span><span class="p">,</span> <span class="n">einops</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="n">torch_geometric</span> <span class="k">as</span> <span class="n">pyg</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="n">torch_cluster</span> <span class="kn">import</span> <span class="n">radius_graph</span>
<span class="kn">from</span> <span class="n">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GATConv</span>
<span class="kn">from</span> <span class="n">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter</span>

<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">import</span> <span class="n">scipy.spatial.transform</span> <span class="k">as</span> <span class="n">trans</span>

<span class="kn">from</span> <span class="n">e3nn</span> <span class="kn">import</span> <span class="n">o3</span>
<span class="kn">from</span> <span class="n">e3nn.o3</span> <span class="kn">import</span> <span class="n">FullyConnectedTensorProduct</span>
<span class="kn">from</span> <span class="n">e3nn.nn.models.gate_points_2101</span> <span class="kn">import</span> <span class="n">Network</span>

<span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">():</span> <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span> <span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">mps</span><span class="sh">'</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Using device: </span><span class="si">{</span><span class="n">DEVICE</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>Note that there are few functions in <code class="language-plaintext highlighter-rouge">torch_geometric</code> that are not compatible with Apple’s M1/M2 GPU, so if one is using <code class="language-plaintext highlighter-rouge">mps</code>, <code class="language-plaintext highlighter-rouge">e3nn</code> or functionalities in <code class="language-plaintext highlighter-rouge">torch_geometric</code> might raise low-level errors.</p> <h2 id="22-data">2.2 Data</h2> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Retrieving data from trajectory
</span>
<span class="n">urllib</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="nf">urlretrieve</span><span class="p">(</span><span class="sh">"</span><span class="s">https://github.com/whitead/dmol-book/raw/main/data/paths.npz</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">paths.npz</span><span class="sh">"</span><span class="p">)</span>
<span class="n">paths</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">paths.npz</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">arr</span><span class="sh">'</span><span class="p">]</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">path shape = </span><span class="sh">'</span><span class="p">,</span> <span class="n">paths</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># time stamp, particle, xy
</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">paths</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">paths</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">o-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">tab:blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">first frame</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">paths</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">paths</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">o-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">tab:green</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">second frame</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">paths</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">paths</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">o-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">tab:purple</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">third frame</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">paths</span><span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">paths</span><span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">o-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">tab:red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">tenth frame</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <p>path shape = (2048, 12, 2)</p> <p>The path contains 2048 frames of 2D coordinates for 12 particles. The output plot was shown above.</p> <p>The data is the \(x(t)\) and the label is either \(x(t + \Delta t)\) or \(\Delta x\). We will arrange the path accordingly. Additionally, we will prepare the data with and without <code class="language-plaintext highlighter-rouge">shuffling</code> the data.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Process the data into datasets and dataloaders
</span><span class="k">def</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span> 
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">frame</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pyg</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">Data</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">frame</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">y</span><span class="o">=</span><span class="n">label</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="c1"># make 3d trajectories
</span><span class="n">nt</span><span class="p">,</span> <span class="n">npoint</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="n">paths</span><span class="p">.</span><span class="n">shape</span>
<span class="n">traj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">paths</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">nt</span><span class="p">,</span> <span class="n">npoint</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># two types of data:
# 1. feature = x(t), label = x(t+1), prediction = label
# 2. feature = x(t), label = dx(t), prediction = x(t+1) = x(t) + dx(t)
</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">traj</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">traj</span><span class="p">[</span><span class="mi">1</span><span class="p">:]).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="n">dx</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">-</span> <span class="n">features</span>

<span class="c1"># training = 0:n, testing = n:2048, n = 1637
</span><span class="n">n</span> <span class="o">=</span> <span class="mi">1637</span>
<span class="n">pos_prediction_train_dataset</span> <span class="o">=</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">features</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">labels</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
<span class="n">pos_prediction_test_dataset</span> <span class="o">=</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">n</span><span class="p">:],</span> <span class="n">labels</span><span class="p">[</span><span class="n">n</span><span class="p">:])</span>

<span class="n">dx_prediction_train_dataset</span> <span class="o">=</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">features</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">dx</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
<span class="n">dx_prediction_test_dataset</span> <span class="o">=</span> <span class="nf">build_dataset</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">n</span><span class="p">:],</span> <span class="n">dx</span><span class="p">[</span><span class="n">n</span><span class="p">:])</span>

<span class="c1"># data loaders: [pos, dx] x [shuffle or not] x [train, test]
</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">pos</span><span class="sh">'</span><span class="p">:</span> <span class="nf">dict</span><span class="p">(),</span> <span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">:</span> <span class="nf">dict</span><span class="p">()})</span>

<span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">pos</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">pos_prediction_train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> 
                                         <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">pos_prediction_test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)})</span>
<span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">pos</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">shuffle</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">pos_prediction_train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> 
                                      <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">pos_prediction_test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)})</span>

<span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dx_prediction_train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> 
                                        <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)})</span>
<span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">shuffle</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dx_prediction_train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> 
                                     <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">:</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)})</span></code></pre></figure> <p>Take a look at what the minibatch is like:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">pos</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">]))</span> <span class="c1"># 52
</span><span class="n">batch_data</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="nf">iter</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">pos</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">]))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
<span class="c1"># DataBatch(y=[384, 3], pos=[384, 3], batch=[384], ptr=[33])
</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">batch_data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="mi">12</span><span class="p">:],</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="mi">12</span><span class="p">])</span></code></pre></figure> <h2 id="23-baseline-models">2.3 Baseline Models</h2> <p>With the dataloaders at hand, we can start to build the models. First, we will construct 2 baseline models for comparisons. The first one is just the normal MLP and the second one is the GNN baseline using the equivariant features (to make it comparable with models later).</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Baseline models: 
# 1. Just a MLP
# 2. GNN baseline
</span>
<span class="c1"># input = a set of 12 coordinates
# output = a set of 12 coordinates
</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">MLPBaseline</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">MLPBaseline</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">36</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">),</span>
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">),</span>
                                       <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">dim</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span> 
        <span class="n">pos</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="sh">'</span><span class="s">(t p) c -&gt; t (p c)</span><span class="sh">'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mlp</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="sh">'</span><span class="s">t (p c) -&gt; (t p) c</span><span class="sh">'</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pos</span>

   
<span class="c1"># Using spherical harmonics as featurizer
</span><span class="k">class</span> <span class="nc">GNNBaseline</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim_in</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dim_out</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">GNNBaseline</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim_in</span> <span class="o">=</span> <span class="n">dim_in</span>
        <span class="n">self</span><span class="p">.</span><span class="n">edge_dim</span> <span class="o">=</span> <span class="n">edge_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim_out</span> <span class="o">=</span> <span class="n">dim_out</span>
        <span class="n">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>

        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">gat1</span> <span class="o">=</span> <span class="nc">GATConv</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gat2</span> <span class="o">=</span> <span class="nc">GATConv</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">GELU</span><span class="p">(),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">num_neighbors</span> <span class="o">=</span> <span class="mi">6</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">12</span>
        
        <span class="c1"># tensors of indices representing the graph, using fully connected
</span>        <span class="n">edge_index</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        
        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># GNN message passing
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gat1</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_features</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gat2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_features</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Let’s try to feed in one minibatch.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">mlpbase</span> <span class="o">=</span> <span class="nc">MLPBaseline</span><span class="p">()</span>
<span class="n">pred</span> <span class="o">=</span> <span class="nf">mlpbase</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># torch.Size([384, 3])
</span><span class="nf">print</span><span class="p">(</span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">y</span><span class="p">))</span> <span class="c1"># tensor(253.8258, grad_fn=&lt;MseLossBackward0&gt;)
</span>
<span class="n">gnnbase</span> <span class="o">=</span> <span class="nc">GNNBaseline</span><span class="p">()</span>
<span class="n">pred</span> <span class="o">=</span> <span class="nf">gnnbase</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># torch.Size([384, 3])
</span><span class="nf">print</span><span class="p">(</span><span class="nf">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">y</span><span class="p">))</span> <span class="c1"># tensor(244.7130, grad_fn=&lt;MseLossBackward0&gt;)</span></code></pre></figure> <p>We need some helper functions for model training, evaluations and visualizations. These functions are straightforward.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># general training function 
</span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">1e-3</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">trainloader</span><span class="p">,</span> <span class="n">testloader</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">,</span> <span class="n">opt</span><span class="o">=</span><span class="sh">'</span><span class="s">Adam</span><span class="sh">'</span><span class="p">):</span> 

    <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span> <span class="k">if</span> <span class="n">opt</span> <span class="o">==</span> <span class="sh">'</span><span class="s">Adam</span><span class="sh">'</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>

    <span class="n">every_n</span> <span class="o">=</span> <span class="n">epochs</span> <span class="o">//</span> <span class="mi">100</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">train_loss</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="sh">'</span><span class="s">test_loss</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)})</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span> 
        
        <span class="n">train_loss</span><span class="p">,</span> <span class="n">test_loss</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

        <span class="c1"># training: 
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span> 
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

            <span class="n">train_loss</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
        
        <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">train_loss</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_loss</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>

        <span class="c1"># testing: 
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span> 
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>
                <span class="n">test_loss</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
        
        <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">test_loss</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_loss</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>

        <span class="n">trainl</span><span class="p">,</span> <span class="n">testl</span> <span class="o">=</span> <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">train_loss</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">],</span> <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">test_loss</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">]</span>
        <span class="n">s</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">epoch </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="mi">5</span><span class="n">d</span><span class="si">}</span><span class="s"> | Train MSE </span><span class="si">{</span><span class="n">trainl</span><span class="si">:</span><span class="o">&lt;</span><span class="mf">10.5</span><span class="n">f</span><span class="si">}</span><span class="s"> | Test MSE </span><span class="si">{</span><span class="n">testl</span><span class="si">:</span><span class="o">&lt;</span><span class="mf">10.5</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">every_n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">logs</span>


<span class="c1"># get forward pass for all testing set 
</span><span class="k">def</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span> 
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">delta</span><span class="p">:</span> 
            <span class="n">pred</span> <span class="o">=</span> <span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">))).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">]</span>
            <span class="n">truth</span> <span class="o">=</span> <span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span> <span class="o">+</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">pred</span> <span class="o">=</span> <span class="p">[</span><span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">]</span>
            <span class="n">truth</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">cpu</span><span class="p">(),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">truth</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">cpu</span><span class="p">()</span>


<span class="c1"># show correlations of center of mass, first particle center of mass, 7th particle x coord, last particle y coord
</span><span class="k">def</span> <span class="nf">show_correlation</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span> 
    <span class="k">assert</span> <span class="n">y_hat</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">y_hat_cm</span><span class="p">,</span> <span class="n">y_cm</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_hat_cmm</span><span class="p">,</span> <span class="n">y_cmm</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">.</span><span class="nf">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">y</span><span class="p">.</span><span class="nf">mean</span><span class="p">((</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_cmm</span><span class="p">,</span> <span class="n">y_cmm</span><span class="p">,</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_cmm</span><span class="p">,</span> <span class="n">y_hat_cmm</span><span class="p">,</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">COM, rsq = </span><span class="si">{</span><span class="nf">r2_score</span><span class="p">(</span><span class="n">y_cmm</span><span class="p">,</span> <span class="n">y_hat_cmm</span><span class="p">)</span><span class="si">:</span> <span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_cm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_cm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_cm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_hat_cm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">First COM, rsq = </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_cm</span><span class="p">[</span><span class="si">:</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_hat_cm</span><span class="p">[</span><span class="si">:</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="si">:</span> <span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">7th x, rsq = </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="si">:</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">[</span><span class="si">:</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="si">:</span> <span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">3</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">last y, rsq = </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="si">:</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">[</span><span class="si">:</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="si">:</span> <span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>


<span class="c1"># show and compare trajectories
</span><span class="k">def</span> <span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span> 
    <span class="k">assert</span> <span class="n">y_hat</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">nt</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Trajectory</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Trajectory</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">get_cmap</span><span class="p">(</span><span class="sh">"</span><span class="s">coolwarm</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nt</span><span class="p">,</span> <span class="n">interval</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">"</span><span class="s">.-</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="nf">cmap</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="n">nt</span><span class="p">))</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">"</span><span class="s">.-</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="nf">cmap</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="n">nt</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([])</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">set_yticks</span><span class="p">([])</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <p>For each model, we will train it, evaluate the trained model using testing data and visualize the testing trajectories. For evaluation, we select correlations of center of mass, first particle center of mass, 7th particle x coordinate, last particle y coordinate. Therefore, we will be able to see the small variations in a more granular way.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># test training 
</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">mlpbase</span><span class="p">,</span> <span class="n">mlpbase_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">MLPBaseline</span><span class="p">(),</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
<span class="n">gnnbase</span><span class="p">,</span> <span class="n">gnnbase_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">GNNBaseline</span><span class="p">(),</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>

<span class="n">mlp_y_hat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">mlpbase</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">mlp_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">mlp_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">gnn_y_hat</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">gnnbase</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">gnn_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">gnn_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">epoch</span>  <span class="mi">1000</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">0.00003</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.00003</span>   <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1001</span><span class="o">/</span><span class="mi">1001</span> <span class="p">[</span><span class="mi">01</span><span class="p">:</span><span class="mi">31</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">10.90</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">epoch</span>  <span class="mi">1000</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">0.00002</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.00003</span>   <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1001</span><span class="o">/</span><span class="mi">1001</span> <span class="p">[</span><span class="mi">05</span><span class="p">:</span><span class="mi">21</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">3.11</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">410</span><span class="o">/</span><span class="mi">410</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">5012.90</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">410</span><span class="o">/</span><span class="mi">410</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">01</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">393.63</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span></code></pre></figure> <p>For MLP no shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/mlpcorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/mlpcorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/mlpcorr-1400.webp"/> <img src="/assets/img/posts/e3nn/mlpcorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/mlptraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/mlptraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/mlptraj-1400.webp"/> <img src="/assets/img/posts/e3nn/mlptraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>For GNN no shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/gnncorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/gnncorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/gnncorr-1400.webp"/> <img src="/assets/img/posts/e3nn/gnncorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/gnntraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/gnntraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/gnntraj-1400.webp"/> <img src="/assets/img/posts/e3nn/gnntraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The baseline models have already good performances, which might be coming from the ordering of the data. Let’s try it again with shuffled dataloader.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">mlpbase_sh</span><span class="p">,</span> <span class="n">mlpbase_sh_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">MLPBaseline</span><span class="p">(),</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
<span class="n">gnnbase_sh</span><span class="p">,</span> <span class="n">gnnbase_sh_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">GNNBaseline</span><span class="p">(),</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>

<span class="n">mlp_y_hat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">mlpbase_sh</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">mlp_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">mlp_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">gnn_y_hat</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">gnnbase_sh</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">gnn_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">gnn_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">epoch</span>  <span class="mi">1000</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">0.00002</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.00004</span>   <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1001</span><span class="o">/</span><span class="mi">1001</span> <span class="p">[</span><span class="mi">01</span><span class="p">:</span><span class="mi">35</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">10.48</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">epoch</span>  <span class="mi">1000</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">0.00002</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.00003</span>   <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1001</span><span class="o">/</span><span class="mi">1001</span> <span class="p">[</span><span class="mi">05</span><span class="p">:</span><span class="mi">34</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">2.99</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">410</span><span class="o">/</span><span class="mi">410</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">7180.50</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">410</span><span class="o">/</span><span class="mi">410</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">01</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">389.29</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span></code></pre></figure> <p>For MLP shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/mlpshcorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/mlpshcorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/mlpshcorr-1400.webp"/> <img src="/assets/img/posts/e3nn/mlpshcorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/mlpshtraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/mlpshtraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/mlpshtraj-1400.webp"/> <img src="/assets/img/posts/e3nn/mlpshtraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>For GNN shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/gnnshcorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/gnnshcorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/gnnshcorr-1400.webp"/> <img src="/assets/img/posts/e3nn/gnnshcorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/gnnshtraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/gnnshtraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/gnnshtraj-1400.webp"/> <img src="/assets/img/posts/e3nn/gnnshtraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="24-e3nn-models">2.4 E3NN Models</h2> <p>Let’s try to build the equivariant model from <code class="language-plaintext highlighter-rouge">e3nn</code> and see if the models can achieve better predictions.</p> <p>We will recycle the model from the Tetris example except the final aggregation operation for the <code class="language-plaintext highlighter-rouge">e3nn_small</code> model. Similarly, we recycle the <code class="language-plaintext highlighter-rouge">Network</code> as the <code class="language-plaintext highlighter-rouge">e3nn_large</code> model. Explicitly:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># E3NN
</span><span class="k">class</span> <span class="nc">EquivariantPolynomial</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">3.5</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">EquivariantPolynomial</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> 
        <span class="n">irreps_mid</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">8x0e + 8x0o + 16x1e + 16x1o + 8x2e + 8x2o</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># add l = 3 to the hidden irreps
</span>        <span class="n">irreps_out</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">1x1o</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># each particle outputs a vector (1x1o)
</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tp1</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> 
                                               <span class="n">irreps_in2</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span>
                                               <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">tp2</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">,</span>
                                               <span class="n">irreps_in2</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span>
                                               <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_out</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tp2</span><span class="p">.</span><span class="n">irreps_out</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">num_neighbors</span> <span class="o">=</span> <span class="mi">11</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">12</span>
        
        <span class="c1"># tensors of indices representing the graph
</span>        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">r</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        <span class="n">edge_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
    
        <span class="c1"># For each node, the initial features are the sum of the spherical harmonics of the neighbors
</span>        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_sh</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># For each edge, tensor product the features on the source node with the spherical harmonics
</span>        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp1</span><span class="p">(</span><span class="n">node_features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_sh</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp2</span><span class="p">(</span><span class="n">node_features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_sh</span><span class="p">)</span>
        <span class="c1"># node_features = scatter(edge_features, edge_dst, dim=0).div(num_neighbors**0.5)
</span>        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">reduce</span><span class="o">=</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">node_features</span>
    

<span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">irreps_in</span><span class="sh">"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span> 
    <span class="sh">"</span><span class="s">irreps_hidden</span><span class="sh">"</span><span class="p">:</span> <span class="n">e3nn</span><span class="p">.</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">8x0e + 8x0o + 16x1e + 16x1o + 8x2e + 8x2o</span><span class="sh">'</span><span class="p">),</span>  <span class="c1"># hyperparameter
</span>    <span class="sh">"</span><span class="s">irreps_out</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">1x1o</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># 12 vectors out, but only 1 vector out per input
</span>    <span class="sh">"</span><span class="s">irreps_node_attr</span><span class="sh">"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">irreps_edge_attr</span><span class="sh">"</span><span class="p">:</span> <span class="n">e3nn</span><span class="p">.</span><span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
    <span class="sh">"</span><span class="s">layers</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> 
    <span class="sh">"</span><span class="s">max_radius</span><span class="sh">"</span><span class="p">:</span> <span class="mf">3.5</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">number_of_basis</span><span class="sh">"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">radial_layers</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">radial_neurons</span><span class="sh">"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">num_neighbors</span><span class="sh">"</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span>  
    <span class="sh">"</span><span class="s">num_nodes</span><span class="sh">"</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span> 
    <span class="sh">"</span><span class="s">reduce_output</span><span class="sh">"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>  <span class="c1"># setting this to true would give us one scalar as an output.
</span><span class="p">}</span></code></pre></figure> <p>After defining these models, let go ahead to reuse the training codes.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># test training 
</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">e3nn_small</span><span class="p">,</span> <span class="n">e3nn_small_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">EquivariantPolynomial</span><span class="p">(),</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">e3nn_large</span><span class="p">,</span> <span class="n">e3nn_large_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">Network</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">),</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="n">e3nn_small_y_hat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">e3nn_small</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">e3nn_small_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">e3nn_small_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">e3nn_large_y_hat</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">e3nn_large</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">e3nn_large_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">e3nn_large_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">epoch</span>  <span class="mi">1000</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">10.74854</span>   <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.36630</span>   <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1001</span><span class="o">/</span><span class="mi">1001</span> <span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">59</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">1.52</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">epoch</span>  <span class="mi">1000</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">0.00000</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.00006</span>   <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1001</span><span class="o">/</span><span class="mi">1001</span> <span class="p">[</span><span class="mi">51</span><span class="p">:</span><span class="mi">30</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">3.09</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">410</span><span class="o">/</span><span class="mi">410</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">02</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">147.40</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">410</span><span class="o">/</span><span class="mi">410</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">06</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">60.48</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span></code></pre></figure> <p>The training speed is significantly slower due to the expensive <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code> layer as it operates on higher order irreps.</p> <p>For E3NN small no shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3smallcorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3smallcorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3smallcorr-1400.webp"/> <img src="/assets/img/posts/e3nn/e3smallcorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3smalltraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3smalltraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3smalltraj-1400.webp"/> <img src="/assets/img/posts/e3nn/e3smalltraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>For E3NN large no shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3largecorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3largecorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3largecorr-1400.webp"/> <img src="/assets/img/posts/e3nn/e3largecorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3largetraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3largetraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3largetraj-1400.webp"/> <img src="/assets/img/posts/e3nn/e3largetraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Hmmm.. It does not seem like these equivariant models outperform non-equivariant ones but the larger model involving higher order irreps definitely helps. It is unclear whether these models require different learning rates or longer training epochs.</p> <p>I also tried to train them using the shuffled data sets but the results look similar without significant improvement.</p> <p>In our set-up, we have the option to predict \(x(t+\Delta t)\) directly. Let’s see if we can directly train the <code class="language-plaintext highlighter-rouge">e3nn_large</code> using the positions directly.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="c1"># e3nn_small, e3nn_small_logs = train(EquivariantPolynomial(), dataloaders['dx']['no_shuffle']['train'], dataloaders['dx']['no_shuffle']['test'], epochs=epochs, lr=lr, device='cpu', opt='AdamW')
</span><span class="n">e3nn_large2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">Network</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">),</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">pos</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">pos</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="c1"># e3nn_small_y_hat, y = forward_pass(e3nn_small, dx_prediction_test_dataset, delta=True)
# show_correlation(e3nn_small_y_hat, y)
# compare_trajectories(e3nn_small_y_hat, y)
</span>
<span class="n">e3nn_large_y_hat</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">e3nn_large2</span><span class="p">,</span> <span class="n">pos_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1"># assert torch.allclose(y, y2)
</span><span class="nf">show_correlation</span><span class="p">(</span><span class="n">e3nn_large_y_hat</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">e3nn_large_y_hat</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">epoch</span>  <span class="mi">1000</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">3.05509</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">698.58898</span> <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1001</span><span class="o">/</span><span class="mi">1001</span> <span class="p">[</span><span class="mi">53</span><span class="p">:</span><span class="mi">10</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span>  <span class="mf">3.19</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">410</span><span class="o">/</span><span class="mi">410</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">06</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">62.76</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/poscorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/poscorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/poscorr-1400.webp"/> <img src="/assets/img/posts/e3nn/poscorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/postraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/postraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/postraj-1400.webp"/> <img src="/assets/img/posts/e3nn/postraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>It does not seem to work. This might suggest that \(p(x(t + \Delta t) \| x(t))\) is different from \(p(\Delta x \| x(t))\) and is more diffucult to learn from the data in this setup.</p> <h2 id="25-testing-equivariance">2.5 Testing Equivariance</h2> <p>We will test equivariance of our 4 models so far.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># test se3 equivariance 
</span><span class="k">def</span> <span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">rot</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">rot</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">rot</span> <span class="o">=</span> <span class="n">trans</span><span class="p">.</span><span class="n">Rotation</span><span class="p">.</span><span class="nf">from_euler</span><span class="p">(</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="mi">37</span><span class="p">,</span> <span class="n">degrees</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="n">input_point</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">input_point_transformed</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">rot</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">input_point</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span> <span class="o">+</span> <span class="n">t</span>

    <span class="n">dset</span> <span class="o">=</span> <span class="p">[</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">input_point</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">input_point</span><span class="p">)]</span>
    <span class="n">dset_transformed</span> <span class="o">=</span> <span class="p">[</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">input_point_transformed</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">input_point_transformed</span><span class="p">)]</span>

    <span class="n">output_point</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dset</span><span class="p">)</span>
    <span class="n">output_point_transformed</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">rot</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">output_point</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">trandformed_output_point</span><span class="p">,</span> <span class="n">__</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dset_transformed</span><span class="p">)</span>

    <span class="n">err</span> <span class="o">=</span> <span class="p">(</span><span class="n">trandformed_output_point</span> <span class="o">-</span> <span class="n">output_point_transformed</span><span class="p">).</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Err = </span><span class="sh">'</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
    <span class="c1"># assert err &lt; tol
</span>
    <span class="k">return</span> <span class="bp">None</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">MLP Baseline: </span><span class="sh">'</span><span class="p">)</span>
<span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">mlpbase</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">GNN Baseline: </span><span class="sh">'</span><span class="p">)</span>
<span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">gnnbase</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">E3NN Small: </span><span class="sh">'</span><span class="p">)</span>
<span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">e3nn_small</span><span class="p">)</span>


<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">E3NN Large: </span><span class="sh">'</span><span class="p">)</span>
<span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">e3nn_large</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">MLP</span> <span class="n">Baseline</span><span class="p">:</span> 
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">1642.25</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">2750.36</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">Err</span> <span class="o">=</span>  <span class="mf">0.004440372344106436</span>
<span class="n">GNN</span> <span class="n">Baseline</span><span class="p">:</span> 
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">211.60</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">365.26</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">Err</span> <span class="o">=</span>  <span class="mf">0.013194178231060505</span>
<span class="n">E3NN</span> <span class="n">Small</span><span class="p">:</span> 
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">23.25</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">204.99</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">Err</span> <span class="o">=</span>  <span class="mf">0.0001068115234375</span>
<span class="n">E3NN</span> <span class="n">Large</span><span class="p">:</span> 
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">61.12</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">1</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">63.11</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">Err</span> <span class="o">=</span>  <span class="mf">2.8870999813079834e-08</span></code></pre></figure> <h2 id="26-simple-se3-transformer">2.6 Simple SE3-Transformer</h2> <p>Given that the <code class="language-plaintext highlighter-rouge">e3nn_large</code> model does not outperform the baselines, I was motivated to look into more complex models, such as the <a href="https://arxiv.org/abs/2006.10503">SE3-Transformer</a>. The <code class="language-plaintext highlighter-rouge">e3nn</code> document provides simple implementation of SE3-Transformer using the <code class="language-plaintext highlighter-rouge">e3nn</code> framework. I will use the implementation for <code class="language-plaintext highlighter-rouge">E3Attention</code> which grounds the <code class="language-plaintext highlighter-rouge">E3MultiHeadAttention</code>. We will use the layers to build a more complex <code class="language-plaintext highlighter-rouge">E3Network</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Build a SE-3 Transformer model
</span><span class="kn">import</span> <span class="n">e3nn</span>

<span class="k">class</span> <span class="nc">E3Attention</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="p">,</span> <span class="n">sh_order</span><span class="o">=</span><span class="mi">4</span><span class="p">,):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">E3Attention</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">irreps_in</span> <span class="o">=</span> <span class="n">irreps_in</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_q</span> <span class="o">=</span> <span class="n">irreps_q</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irresp_k</span> <span class="o">=</span> <span class="n">irreps_k</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_out</span> <span class="o">=</span> <span class="n">irreps_out</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">sh_order</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">num_bases</span> <span class="o">=</span> <span class="n">num_bases</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_radius</span> <span class="o">=</span> <span class="n">max_radius</span>

        <span class="c1"># input to query
</span>        <span class="n">self</span><span class="p">.</span><span class="n">to_q</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        
        <span class="c1"># input to key
</span>        <span class="n">self</span><span class="p">.</span><span class="n">tp_k</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">shared_weights</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc_k</span> <span class="o">=</span> <span class="n">e3nn</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">FullyConnectedNet</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">num_bases</span><span class="p">,</span> <span class="p">(</span><span class="n">sh_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">tp_k</span><span class="p">.</span><span class="n">weight_numel</span><span class="p">],</span> <span class="n">act</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">gelu</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># input to value
</span>        <span class="n">self</span><span class="p">.</span><span class="n">tp_v</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">shared_weights</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc_v</span> <span class="o">=</span> <span class="n">e3nn</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">FullyConnectedNet</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">num_bases</span><span class="p">,</span> <span class="p">(</span><span class="n">sh_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">tp_v</span><span class="p">.</span><span class="n">weight_numel</span><span class="p">],</span> <span class="n">act</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">gelu</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># dot product
</span>        <span class="n">self</span><span class="p">.</span><span class="n">dot_product</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="sh">'</span><span class="s">0e</span><span class="sh">'</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span> 
        <span class="n">num_neighbors</span> <span class="o">=</span> <span class="mi">11</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">12</span>
        
        <span class="n">pos</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span>
        <span class="c1"># features = torch.zeros(pos.shape[0], self.irreps_in.dim)
</span>        <span class="n">features</span> <span class="o">=</span> <span class="n">pos</span>
        

        <span class="c1"># edges
</span>        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">max_radius</span><span class="p">)</span>
        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        <span class="n">edge_length</span> <span class="o">=</span> <span class="n">edge_vec</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">edge_length_embedded</span> <span class="o">=</span> <span class="n">e3nn</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">soft_one_hot_linspace</span><span class="p">(</span><span class="n">edge_length</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">max_radius</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">num_bases</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="sh">'</span><span class="s">smooth_finite</span><span class="sh">'</span><span class="p">,</span> <span class="n">cutoff</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">num_bases</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="n">edge_weight_cutoff</span> <span class="o">=</span> <span class="n">e3nn</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">soft_unit_step</span><span class="p">(</span><span class="mi">10</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">edge_length</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">max_radius</span><span class="p">))</span>

        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">edge_vec</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">edge_length_embedded</span> <span class="o">=</span> <span class="n">edge_length_embedded</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

        <span class="c1"># qkv
</span>        <span class="n">q</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">to_q</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp_k</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_features</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc_k</span><span class="p">(</span><span class="n">edge_length_embedded</span><span class="p">))</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp_v</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_features</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc_v</span><span class="p">(</span><span class="n">edge_length_embedded</span><span class="p">))</span>

        <span class="n">exp</span> <span class="o">=</span> <span class="n">edge_weight_cutoff</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="nf">dot_product</span><span class="p">(</span><span class="n">q</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">],</span> <span class="n">k</span><span class="p">).</span><span class="nf">exp</span><span class="p">()</span>
        <span class="n">exp</span> <span class="o">=</span> <span class="n">exp</span><span class="p">.</span><span class="nf">clamp</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="n">z</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">features</span><span class="p">))</span>
        <span class="n">z</span><span class="p">[</span><span class="n">z</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">exp</span> <span class="o">/</span> <span class="n">z</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>

        <span class="n">out</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">alpha</span><span class="p">.</span><span class="nf">relu</span><span class="p">().</span><span class="nf">sqrt</span><span class="p">()</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="nb">reduce</span><span class="o">=</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>



<span class="k">class</span> <span class="nc">E3MultiHeadAttention</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="p">,</span> <span class="n">sh_order</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">E3MultiHeadAttention</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_in</span> <span class="o">=</span> <span class="n">irreps_in</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_q</span> <span class="o">=</span> <span class="n">irreps_q</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_k</span> <span class="o">=</span> <span class="n">irreps_k</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_mid</span> <span class="o">=</span> <span class="n">irreps_mid</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_out</span> <span class="o">=</span> <span class="n">irreps_out</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_bases</span> <span class="o">=</span> <span class="n">num_bases</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_radius</span> <span class="o">=</span> <span class="n">max_radius</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sh_order</span> <span class="o">=</span> <span class="n">sh_order</span>
        <span class="n">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span> 

        <span class="n">self</span><span class="p">.</span><span class="n">irreps_all_heads</span> <span class="o">=</span> <span class="n">irreps_mid</span> <span class="o">*</span> <span class="n">heads</span>
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">sh_order</span><span class="p">)</span>


        <span class="n">self</span><span class="p">.</span><span class="n">hs</span> <span class="o">=</span> <span class="p">[</span><span class="nc">E3Attention</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="p">,</span> <span class="n">num_bases</span><span class="o">=</span><span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="o">=</span><span class="n">max_radius</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">heads</span><span class="p">)]</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">tp1</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_all_heads</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">irreps_mid</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tp2</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_mid</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">irreps_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span> 

        <span class="n">pos</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span>
        <span class="c1"># features = torch.zeros(pos.shape[0], self.irreps_in.dim)
</span>        <span class="n">features</span> <span class="o">=</span> <span class="n">pos</span>
        
        <span class="c1"># edges
</span>        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">max_radius</span><span class="p">)</span>
        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">edge_vec</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>

        <span class="n">hs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="nf">f</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">hs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># print(hs)
</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp1</span><span class="p">(</span><span class="n">hs</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_features</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">reduce</span><span class="o">=</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        <span class="c1"># print(h.shape)
</span>        <span class="n">h</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp2</span><span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_features</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">reduce</span><span class="o">=</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
        <span class="c1"># print(h.shape)
</span>        <span class="k">return</span> <span class="n">h</span>



<span class="k">class</span> <span class="nc">E3Network</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="p">,</span> <span class="n">sh_order</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">E3Network</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">e3mhas</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span> 
            <span class="n">e3mhas</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">E3MultiHeadAttention</span><span class="p">(</span><span class="n">irreps_in</span><span class="o">=</span><span class="n">irreps_in</span><span class="p">,</span> <span class="c1"># if i == 0 else irreps_mid, 
</span>                                               <span class="n">irreps_q</span><span class="o">=</span><span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="o">=</span><span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">,</span>
                                               <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_out</span><span class="p">,</span> 
                                               <span class="n">num_bases</span><span class="o">=</span><span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="o">=</span><span class="n">max_radius</span><span class="p">,</span> <span class="n">sh_order</span><span class="o">=</span><span class="n">sh_order</span><span class="p">,</span> 
                                               <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">e3mhas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span><span class="n">e3mhas</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span> 
        <span class="n">tmp_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
        <span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">e3mha</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">e3mhas</span><span class="p">):</span> <span class="n">tmp_data</span><span class="p">.</span><span class="n">pos</span> <span class="o">=</span> <span class="nf">e3mha</span><span class="p">(</span><span class="n">tmp_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tmp_data</span><span class="p">.</span><span class="n">pos</span>
        </code></pre></figure> <p>Let’s get them trained. Note that GPU is required for training 1000 epochs here.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">irreps_in</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">"</span><span class="s">1x1o</span><span class="sh">"</span><span class="p">)</span>
<span class="n">irreps_q</span> <span class="o">=</span> <span class="n">e3nn</span><span class="p">.</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">8x0e + 8x0o + 16x1e + 16x1o + 8x2e + 8x2o</span><span class="sh">'</span><span class="p">)</span>
<span class="n">irreps_k</span> <span class="o">=</span> <span class="n">irreps_q</span>
<span class="n">irreps_mid</span> <span class="o">=</span> <span class="n">irreps_q</span>
<span class="n">irreps_out</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">"</span><span class="s">1x1o</span><span class="sh">"</span><span class="p">)</span>

<span class="n">num_bases</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">max_radius</span> <span class="o">=</span> <span class="mf">3.5</span>


<span class="n">epochs</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">e3mha</span> <span class="o">=</span> <span class="nc">E3MultiHeadAttention</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="o">=</span><span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="o">=</span><span class="n">max_radius</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">e3mha</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">e3mha</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="n">e3net</span> <span class="o">=</span> <span class="nc">E3Network</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="o">=</span><span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="o">=</span><span class="n">max_radius</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">e3net</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="n">e3net</span><span class="p">,</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">],</span> <span class="n">dataloaders</span><span class="p">[</span><span class="sh">'</span><span class="s">dx</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">no_shuffle</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>


<span class="n">e3mha_y_hat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">e3mha</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">e3mha_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">e3mha_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">e3net_y_hat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">e3net</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">e3net_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">e3net_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="mi">0</span><span class="o">%|</span>          <span class="o">|</span> <span class="mi">0</span><span class="o">/</span><span class="mi">1</span> <span class="p">[</span><span class="mi">01</span><span class="p">:</span><span class="mi">45</span><span class="o">&lt;</span><span class="err">?</span><span class="p">,</span> <span class="err">?</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
<span class="n">epoch</span>   <span class="mi">300</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">0.00029</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.00112</span>   <span class="p">:</span> <span class="mi">100</span><span class="o">%|</span><span class="err">██████████</span><span class="o">|</span> <span class="mi">301</span><span class="o">/</span><span class="mi">301</span> <span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mi">21</span><span class="o">&lt;</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">23.59</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span>
<span class="n">epoch</span>    <span class="mi">57</span> <span class="o">|</span> <span class="n">Train</span> <span class="n">MSE</span> <span class="mf">0.00002</span>    <span class="o">|</span> <span class="n">Test</span> <span class="n">MSE</span> <span class="mf">0.00002</span>   <span class="p">:</span>  <span class="mi">19</span><span class="o">%|</span><span class="err">█▉</span>        <span class="o">|</span> <span class="mi">58</span><span class="o">/</span><span class="mi">301</span> <span class="p">[</span><span class="mi">56</span><span class="p">:</span><span class="mi">27</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">:</span><span class="mi">56</span><span class="p">:</span><span class="mi">26</span><span class="p">,</span> <span class="mf">58.38</span><span class="n">s</span><span class="o">/</span><span class="n">it</span><span class="p">]</span></code></pre></figure> <p>(Note that the training was clipped due to disconnection from jupyter lab.)</p> <p>Let’s see how the trained models perform.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">e3mha_y_hat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">e3mha</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">e3mha_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">e3mha_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">e3net_y_hat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">e3net</span><span class="p">,</span> <span class="n">dx_prediction_test_dataset</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nf">show_correlation</span><span class="p">(</span><span class="n">e3net_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">compare_trajectories</span><span class="p">(</span><span class="n">e3net_y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code></pre></figure> <p>For SE3 MHA no shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3mhacorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3mhacorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3mhacorr-1400.webp"/> <img src="/assets/img/posts/e3nn/e3mhacorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3mhatraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3mhatraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3mhatraj-1400.webp"/> <img src="/assets/img/posts/e3nn/e3mhatraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>For SE3 Transformer no shuffle:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3netcorr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3netcorr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3netcorr-1400.webp"/> <img src="/assets/img/posts/e3nn/e3netcorr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/e3nettraj-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/e3nettraj-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/e3nettraj-1400.webp"/> <img src="/assets/img/posts/e3nn/e3nettraj.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Let’s test the equivariance again</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">e3att</span> <span class="o">=</span> <span class="nc">E3Attention</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">E3ATT: </span><span class="sh">'</span><span class="p">)</span>
<span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">e3att</span><span class="p">)</span>
<span class="c1"># print(sum(p.numel() for p in e3att.parameters() if p.requires_grad))
</span>
<span class="n">e3mha</span> <span class="o">=</span> <span class="nc">E3MultiHeadAttention</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="o">=</span><span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="o">=</span><span class="n">max_radius</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">E3MHA: </span><span class="sh">'</span><span class="p">)</span>
<span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">e3mha</span><span class="p">)</span>
<span class="c1"># print(sum(p.numel() for p in e3mha.parameters() if p.requires_grad))
</span>

<span class="n">e3net</span> <span class="o">=</span> <span class="nc">E3Network</span><span class="p">(</span><span class="n">irreps_in</span><span class="p">,</span> <span class="n">irreps_q</span><span class="p">,</span> <span class="n">irreps_k</span><span class="p">,</span> <span class="n">irreps_mid</span><span class="p">,</span> <span class="n">irreps_out</span><span class="p">,</span> <span class="n">num_bases</span><span class="o">=</span><span class="n">num_bases</span><span class="p">,</span> <span class="n">max_radius</span><span class="o">=</span><span class="n">max_radius</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">E3Net: </span><span class="sh">'</span><span class="p">)</span>
<span class="nf">se3_equivariance</span><span class="p">(</span><span class="n">e3net</span><span class="p">)</span>
<span class="c1"># print(sum(p.numel() for p in e3net.parameters() if p.requires_grad))</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">E3ATT</span><span class="p">:</span> 
<span class="mf">3.576e-7</span>

<span class="n">E3MHA</span><span class="p">:</span> 
<span class="mf">2.129e-7</span>

<span class="n">E3NET</span><span class="p">:</span>
<span class="mf">1.781e-8</span></code></pre></figure> <h2 id="27-summary">2.7 Summary</h2> <p>Here is the summary table of the experiments using the trajectory data.</p> <style type="text/css">.tg{border-collapse:collapse;border-spacing:0}.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial,sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal}.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial,sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal}.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}</style> <table class="tg"> <thead> <tr> <th class="tg-c3ow">model</th> <th class="tg-c3ow">trained on</th> <th class="tg-c3ow">shuffle</th> <th class="tg-c3ow">cm corr</th> <th class="tg-c3ow">p1 cm corr</th> <th class="tg-c3ow">p7 x corr</th> <th class="tg-c3ow">p12 y corr</th> <th class="tg-c3ow">equivariance err</th> </tr> </thead> <tbody> <tr> <td class="tg-c3ow">MLPBase</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">no</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.999</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.997</td> <td class="tg-c3ow">4.44e-3</td> </tr> <tr> <td class="tg-c3ow">MLPBase_SH</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">yes</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.998</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.997</td> <td class="tg-c3ow"></td> </tr> <tr> <td class="tg-c3ow">GNNBase</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">no</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.999</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.996</td> <td class="tg-c3ow">1.32e-2</td> </tr> <tr> <td class="tg-c3ow">GNNBase_SH</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">yes</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.999</td> <td class="tg-c3ow">0.999</td> <td class="tg-c3ow">0.997</td> <td class="tg-c3ow"></td> </tr> <tr> <td class="tg-c3ow">E3Small</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">no</td> <td class="tg-c3ow">-3.263</td> <td class="tg-c3ow">-10.729</td> <td class="tg-c3ow">-0.853</td> <td class="tg-c3ow">-214.437</td> <td class="tg-c3ow">1.07e-4</td> </tr> <tr> <td class="tg-c3ow">E3Small_SH</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">yes</td> <td class="tg-c3ow">0.998</td> <td class="tg-c3ow">0.830</td> <td class="tg-c3ow">0.992</td> <td class="tg-c3ow">0.772</td> <td class="tg-c3ow"></td> </tr> <tr> <td class="tg-c3ow">E3Large</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">no</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.997</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.993</td> <td class="tg-c3ow">2.89e-8</td> </tr> <tr> <td class="tg-c3ow">E3Large_SH</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">yes</td> <td class="tg-c3ow">0.999</td> <td class="tg-c3ow">0.993</td> <td class="tg-c3ow">0.999</td> <td class="tg-c3ow">0.990</td> <td class="tg-c3ow"></td> </tr> <tr> <td class="tg-c3ow">E3Large_Pos</td> <td class="tg-c3ow">x</td> <td class="tg-c3ow">no</td> <td class="tg-c3ow">-75086</td> <td class="tg-c3ow">-77477</td> <td class="tg-c3ow">-9814</td> <td class="tg-c3ow">-19929</td> <td class="tg-c3ow"></td> </tr> <tr> <td class="tg-c3ow">SE3MHA</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">no</td> <td class="tg-c3ow">0.513</td> <td class="tg-c3ow">0.321</td> <td class="tg-c3ow">0.937</td> <td class="tg-c3ow">0.788</td> <td class="tg-c3ow">2.13e-7</td> </tr> <tr> <td class="tg-c3ow">SE3Trans</td> <td class="tg-c3ow">dx</td> <td class="tg-c3ow">no</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.999</td> <td class="tg-c3ow">1.000</td> <td class="tg-c3ow">0.997</td> <td class="tg-c3ow">1.78e-8</td> </tr> </tbody> </table> <h2 id="28-notes">2.8 Notes</h2> <p>In the models that utilize <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code> from <code class="language-plaintext highlighter-rouge">e3nn</code>, it might be interesting to see the weights between different order of features. Intuitively, the coefficients of higher order interactions should be small compared to <code class="language-plaintext highlighter-rouge">l0</code> and <code class="language-plaintext highlighter-rouge">l1</code> features. However, I have not investigated it.</p> <p>The model was using <code class="language-plaintext highlighter-rouge">radius_graph</code> with a given radius range for constructing the message passing graphs. Whether this is good enough and how one should choose the radius are potential factors for model improvements.</p> <h2 id="references">References</h2> <ol> <li>Deep learning for molecules and materials: https://dmol.pub/index.html</li> <li>https://e3nn.org</li> <li>https://docs.e3nn.org/en/latest/guide/transformer.html</li> <li>SE3-Transformer: https://arxiv.org/abs/2006.10503</li> </ol>]]></content><author><name></name></author><category term="models"/><category term="coding"/><category term="reading"/><category term="solving"/><summary type="html"><![CDATA[Playing and benchmarking with E3NN (Continued)]]></summary></entry><entry><title type="html">Neural Networks with Euclidean Symmetries - 1</title><link href="https://jipq6175.github.io/blog/2023/e3nn_1/" rel="alternate" type="text/html" title="Neural Networks with Euclidean Symmetries - 1"/><published>2023-06-18T00:48:00+00:00</published><updated>2023-06-18T00:48:00+00:00</updated><id>https://jipq6175.github.io/blog/2023/e3nn_1</id><content type="html" xml:base="https://jipq6175.github.io/blog/2023/e3nn_1/"><![CDATA[<p>Recently, I have been working with equivariant or invariant models. The models leverage inductive bias in the data. For example, convolutional layers is translational equivariant. The messaging aggregation function in the graph neural networks is permutational invariant. Physical data is typically in 3D and the models should respect euclidean symmetries, E(3). If the model does not respect E(3) symmetry, it is usually required to augment the data by random rotation and translation, which is an infinite amount of augmented data and the model might be hard to optimize.</p> <p>If \(f: V \to V\) is an equivariant function on \(G\) and \(g\) is a group operation in \(G\). We have a data \(x\) on some vector space \(V\). We have</p> \[f(g \circ x) = g \circ f(x)\] <p>I am going to explore a general framework <code class="language-plaintext highlighter-rouge">e3nn</code>, which has taken care of the equivariant operations using irreproducible representations, <code class="language-plaintext highlighter-rouge">irreps</code>. There are 3 cases/tasks I want to explore in this post:</p> <ol> <li> <p>Tetris shape prediction: Given 3D coordinates of the voxels of a tetris block, predict the shape. The coordinates might be randomly rotated or translated and the model needs to generalize.</p> </li> <li> <p>Trajectory prediction: Given a 12-body system and coordinates at certain time, predict 12 coordinates at the next time step. The system and physical motions should be independent of the reference frame, therefore, if we rotate or translate the coordinates, the motions should be equivariant.</p> </li> <li> <p>Electron density prediction: The electron density is usually represented by the linear combinations of spherical harmonics, \(Y^l_m\). The goal is to predict the coefficients, which fits nicely to the irreps in <code class="language-plaintext highlighter-rouge">e3nn</code>.</p> </li> </ol> <h1 id="1-tetris">1. Tetris</h1> <p>Given 3D coordinates of the voxels of a tetris block, predict the shape. The coordinates might be randomly rotated or translated and the model needs to generalize.</p> <h2 id="11-packages">1.1 Packages</h2> <p>We will use some basic packages like <code class="language-plaintext highlighter-rouge">torch</code>, geometric libraries <code class="language-plaintext highlighter-rouge">torch_geometric</code> and augmented torch libraries <code class="language-plaintext highlighter-rouge">torch_cluster</code> and <code class="language-plaintext highlighter-rouge">torch_scatter</code>. The main one I am going to use is the <code class="language-plaintext highlighter-rouge">e3nn</code> package.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># minimal example for mesing with e3nn
</span><span class="kn">import</span> <span class="n">torch</span><span class="p">,</span> <span class="n">logging</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="n">torch_cluster</span> <span class="kn">import</span> <span class="n">radius_graph</span>
<span class="kn">from</span> <span class="n">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GATConv</span>
<span class="kn">from</span> <span class="n">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter</span>

<span class="kn">from</span> <span class="n">e3nn</span> <span class="kn">import</span> <span class="n">o3</span>
<span class="kn">from</span> <span class="n">e3nn.o3</span> <span class="kn">import</span> <span class="n">FullyConnectedTensorProduct</span>
<span class="kn">from</span> <span class="n">e3nn.util.test</span> <span class="kn">import</span> <span class="n">assert_equivariant</span>
<span class="kn">from</span> <span class="n">e3nn.nn.models.gate_points_2101</span> <span class="kn">import</span> <span class="n">Network</span>

<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span></code></pre></figure> <h2 id="12-tetris-toy-dataset">1.2 Tetris toy dataset</h2> <p>Each tetris block contain 4 voxels of size 1x1x1. There are 8 different shapes.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># chiral_shape_1
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># chiral_shape_2
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># square
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)],</span>  <span class="c1"># line
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># corner
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># L
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>  <span class="c1"># T
</span>        <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span>  <span class="c1"># zigzag
</span>    <span class="p">]</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">get_default_dtype</span><span class="p">())</span>

    <span class="c1"># Since chiral shapes are the mirror of one another we need an *odd* scalar to distinguish them
</span>    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># chiral_shape_1
</span>            <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># chiral_shape_2
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># square
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># line
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># corner
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># L
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># T
</span>            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># zigzag
</span>        <span class="p">],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nf">get_default_dtype</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="c1"># apply shuffling of data
</span>    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span> 
        <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randperm</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="c1"># apply random rotation
</span>    <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">"</span><span class="s">zij,zaj-&gt;zai</span><span class="sh">"</span><span class="p">,</span> <span class="n">o3</span><span class="p">.</span><span class="nf">rand_matrix</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">pos</span><span class="p">)),</span> <span class="n">pos</span><span class="p">)</span>

    <span class="c1"># put in torch_geometric format
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">)</span> <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">pos</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="nf">iter</span><span class="p">(</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))))</span>

    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span></code></pre></figure> <p>Note that the chiral shape has parity, i.e. the label of the chiral shape is a <code class="language-plaintext highlighter-rouge">pseudo-scalar</code>, which flip signs upon mirror reflection.</p> <p>Everything should look familiar, maybe except for <code class="language-plaintext highlighter-rouge">o3.rand_matrix(n)</code>. It generates \(n\) 3x3 random rotational matrices, which were applied to the coordinates.</p> <p>Let’s take a look at the data.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nc">DataBatch</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">batch</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">ptr</span><span class="o">=</span><span class="p">[</span><span class="mi">9</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span></code></pre></figure> <p>The data follows the <code class="language-plaintext highlighter-rouge">torch_geometric</code> convention where <code class="language-plaintext highlighter-rouge">batch</code> represents which graph the positions belong to and the <code class="language-plaintext highlighter-rouge">ptr</code> is the pointer to the start of each graph.</p> <h2 id="13-gnn-baseline">1.3 GNN Baseline</h2> <p>Let’s build a simple GNN baseline model using message passing with attention: <code class="language-plaintext highlighter-rouge">GATConv</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># GNN base line
</span><span class="k">class</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dim_in</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dim_out</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">GNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim_in</span> <span class="o">=</span> <span class="n">dim_in</span>
        <span class="n">self</span><span class="p">.</span><span class="n">edge_dim</span> <span class="o">=</span> <span class="n">edge_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dim_out</span> <span class="o">=</span> <span class="n">dim_out</span>
        <span class="n">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>

        <span class="c1"># irreps of spherical harmonics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">gat1</span> <span class="o">=</span> <span class="nc">GATConv</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gat2</span> <span class="o">=</span> <span class="nc">GATConv</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">edge_dim</span><span class="o">=</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="n">heads</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">GELU</span><span class="p">(),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">num_neighbors</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">4</span>
        
        <span class="c1"># tensors of indices representing the graph, using fully connected
</span>        <span class="n">edge_index</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">10.1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        
        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="c1"># GNN message passing
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gat1</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_features</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gat2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_features</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Again, this is a very typical GNN and forward pass. However, there are some foreign stuff sneaking in the code and I’ll explain. Since the input or the data only contains a set of 4 coordinates, (x, y, z). The node and edge contain absolutely no features at all except for the coordinates. I am going to use, again, spherical harmonics to featurize the edges and nodes.</p> <p>The line <code class="language-plaintext highlighter-rouge">self.irreps_sh = o3.Irreps.spherical_harmonics(3)</code> is the basis of the spherical harmonics, containing the following irreps:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span></code></pre></figure> <p><code class="language-plaintext highlighter-rouge">1x0e+1x1o+1x2e+1x3o</code></p> <p>Ok and let me expand these weird codes. There are 4 irreps in the above expression. Each irrep is of the form of <code class="language-plaintext highlighter-rouge">mxlp</code>, where</p> <ul> <li><code class="language-plaintext highlighter-rouge">m</code> is the multiplicity, i.e. the number of features</li> <li><code class="language-plaintext highlighter-rouge">x</code> just stands for times</li> <li> <p><code class="language-plaintext highlighter-rouge">l</code> is the rotation order, or the first quantum number of electron orbitals or the order of spherical harmonics.</p> <ul> <li><code class="language-plaintext highlighter-rouge">l = 0</code> is transformed as scalar (one number), or the <code class="language-plaintext highlighter-rouge">l = 0</code> orbital, which is a sphere.</li> <li><code class="language-plaintext highlighter-rouge">l = 1</code> is transformed as vector (three numbers), or the <code class="language-plaintext highlighter-rouge">l = 1</code> orbital, which aligns with the x, y, z axes, corresponding to 3 quantum numbers <code class="language-plaintext highlighter-rouge">m = -1, 0, 1</code>.</li> <li><code class="language-plaintext highlighter-rouge">l = 2</code> is transformed as ?…? (five numbers), or the <code class="language-plaintext highlighter-rouge">l = 2</code> orbital, which are more complicated, corresponding to 5 quantum numbers <code class="language-plaintext highlighter-rouge">m = -2, -1, 0, 1, 2</code>.</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">p</code> describes the parity: even <code class="language-plaintext highlighter-rouge">e</code> or odd <code class="language-plaintext highlighter-rouge">o</code>, describing how these tensors transform under mirror reflection.</li> </ul> <p>So <code class="language-plaintext highlighter-rouge">16x1o</code> is a set of 16 vectors with odd parity.</p> <p>Another line is the <code class="language-plaintext highlighter-rouge">radius_graph(x=data.pos, r=10.1, batch=data.batch)</code> which constructs the <code class="language-plaintext highlighter-rouge">edge_index</code> just using the coordinates and batch. I used <code class="language-plaintext highlighter-rouge">r = 10.1</code> or something <code class="language-plaintext highlighter-rouge">r &gt; 3.1</code> to construct the fully connected graph of 4 nodes. These edges are directional, because they are translational vectors. So in the above line, we will have <code class="language-plaintext highlighter-rouge">4 * 3 = 12</code> edges for each graph. Therefore,</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">10.1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">).</span><span class="n">shape</span>
<span class="c1"># 12 * 8 (graphs) edges in total</span></code></pre></figure> <p><code class="language-plaintext highlighter-rouge">torch.Size([2, 96])</code></p> <p>Since the input is only the 3D coordinates, the straightforward featurization is using the distance vector, \(\mathbf{r}_i - \mathbf{r}_j\) where \(\mathbf{r}\) is the position vector. We further use the coefficients of spherical harmonics as edge features, i.e. we project the distance vector on <code class="language-plaintext highlighter-rouge">l=0, 1, 2, 3</code> spherical harmonics and get the coefficients, with a total number of <code class="language-plaintext highlighter-rouge">1 + 3 + 5 + 7 = 16</code> coefficients. Note that \(&lt;Y^l_m, Y^{l'}_{m'}&gt; = \delta_{ll'}\delta_{mm'}\), meaning that they are orthogonal bases.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">edge_features</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># 96 (edges) x 16 (edge features) tensor</span></code></pre></figure> <p>The node features are the aggregated of the edge features of the inward edges.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># 32 (nodes) x 16 (node features) tensor</span></code></pre></figure> <p>With the node and edge features using spherical harmonics, we can just create a graph convolution and a readout for tetris shape prediction.</p> <p>Let’s build a general training function that can be used for all the models built for this task.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># model training script 
</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>

    <span class="n">every_n</span> <span class="o">=</span> <span class="n">epochs</span> <span class="o">//</span> <span class="mi">100</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">({</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)})</span>
    <span class="n">pbar</span> <span class="o">=</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span> 
        <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="n">acc</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="nf">round</span><span class="p">().</span><span class="nf">eq</span><span class="p">(</span><span class="n">labels</span><span class="p">).</span><span class="nf">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">double</span><span class="p">().</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        <span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">][</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span>

        <span class="n">s</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="s">epoch </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="mi">5</span><span class="n">d</span><span class="si">}</span><span class="s"> | loss </span><span class="si">{</span><span class="mf">1e3</span> <span class="o">*</span> <span class="n">loss</span><span class="si">:</span><span class="o">&lt;</span><span class="mf">10.1</span><span class="n">f</span><span class="si">}</span><span class="s"> | </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">acc</span><span class="si">:</span><span class="mf">5.1</span><span class="n">f</span><span class="si">}</span><span class="s">% accuracy</span><span class="sh">'</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">every_n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="n">pbar</span><span class="p">.</span><span class="nf">set_description</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">logs</span></code></pre></figure> <p>Now we can try to train our GNN baseline model:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">g</span><span class="p">,</span> <span class="n">g_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">GNN</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">g_shuffle</span><span class="p">,</span> <span class="n">g_shuffle_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">GNN</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># epoch 10000 | loss 41.9       |  75.0% accuracy: 100%|██████████| 10001/10001 [01:25&lt;00:00, 117.05it/s]
# epoch 10000 | loss 40.5       |  75.0% accuracy: 100%|██████████| 10001/10001 [01:25&lt;00:00, 116.74it/s]</span></code></pre></figure> <p>Training on CPU took about 90 seconds for 10000 epochs. We tried no shuffling and shuffling and the final loss were \(41.9\) and \(40.5\) respectively. They achieved final accuracy of \(75\%\), which is not optimal given the easiness of the task and small number of data and large GNN models with <code class="language-plaintext highlighter-rouge">GATConv</code>.</p> <h2 id="14-e3nn">1.4 E3NN</h2> <p>In previous GNN model, I used a small part of <code class="language-plaintext highlighter-rouge">e3nn</code> for featurization but the model is still not aware of the E(3) symmetry: it just did something like <code class="language-plaintext highlighter-rouge">torch.nn.Linear</code> and ignored the relationship/interaction of each element under E(3). We were also toruched on the irreps, which I feel it might be better to go through them again.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># We have seen the irreps for spherical harmonics with lmax = 3
</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># 1x0e + 1x1o + 1x2e + 1x3o representing spherical harmonics of lmax = 3</span></code></pre></figure> <p>Similar to the <code class="language-plaintext highlighter-rouge">hidden dimension</code> in the hidden layers of neural networks, we can also define the <code class="language-plaintext highlighter-rouge">hidden irreps</code> in e3nn.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">irreps_mid</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">64x0e + 24x1e + 24x1o + 16x2e + 16x2o</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># 64x0e = 64 hidden scalar, l = 0
# 24x1e = 24 hidden pseudo-vector, l = 1
# 24x1o = 24 hidden vector, l = 1
# 16x2e = 16 even tensor, l = 2
# 16x2o = 16 odd tensor, l=2
# So we have 64 + 24 x 3 + 24 x 3 + 16 x 5 + 16 x 5 = 368 dim tensor as output of the hidden layer. </span></code></pre></figure> <p>The neural network layer (or the Linear layer) in e3nn is called the <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code> with trainable weights. At initialization, it takes 2 input irreps and 1 output 1rreps and in the forward pass, it takes 2 tensors with corresponding input irreps. This layer dictates the interaction between different irreps.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># tensor product 1
</span><span class="n">tp1</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">irreps_in2</span><span class="o">=</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">)</span>
<span class="c1"># each path corresponds to one parameters, the path is defined by |l1 - l2| &lt;= lout &lt;= l1 + l2
# the above layer contains 648 paths and therefore 648 parameters
# this can be shown: 64 * 4 (0e) + 24 * 3 (1e) + 24 * 6 (1o) + 16 * 7 (2e) + 16 * 4 (2o)</span></code></pre></figure> <p>We can check if the above tensor product is the same as exhausting all possible paths of the irreps.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># or we can check this: 
</span><span class="n">npaths</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">in1</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">1x0e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x1o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x2e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x3o</span><span class="sh">'</span><span class="p">]:</span> 
    <span class="k">for</span> <span class="n">in2</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">1x0e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x1o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x2e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">1x3o</span><span class="sh">'</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">64x0e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">24x1e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">24x1o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">16x2e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">16x2o</span><span class="sh">'</span><span class="p">]:</span> 
            <span class="n">p</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="n">in1</span><span class="p">),</span> 
                                                  <span class="n">irreps_in2</span><span class="o">=</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="n">in2</span><span class="p">),</span> 
                                                  <span class="n">irreps_out</span><span class="o">=</span><span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="n">out</span><span class="p">)).</span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">npaths</span> <span class="o">+=</span> <span class="n">p</span>
            <span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">in1</span><span class="si">}</span><span class="s"> + </span><span class="si">{</span><span class="n">in2</span><span class="si">}</span><span class="s"> -&gt; </span><span class="si">{</span><span class="n">out</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">npaths</span> <span class="o">==</span> <span class="n">tp1</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># The output: 
# 1x0e + 1x0e -&gt; 64x0e, 64
# 1x0e + 1x1o -&gt; 24x1o, 24
# 1x0e + 1x2e -&gt; 16x2e, 16
# 1x1o + 1x0e -&gt; 24x1o, 24
# 1x1o + 1x1o -&gt; 64x0e, 64
# 1x1o + 1x1o -&gt; 24x1e, 24
# 1x1o + 1x1o -&gt; 16x2e, 16
# 1x1o + 1x2e -&gt; 24x1o, 24
# 1x1o + 1x2e -&gt; 16x2o, 16
# 1x1o + 1x3o -&gt; 16x2e, 16
# 1x2e + 1x0e -&gt; 16x2e, 16
# 1x2e + 1x1o -&gt; 24x1o, 24
# 1x2e + 1x1o -&gt; 16x2o, 16
# 1x2e + 1x2e -&gt; 64x0e, 64
# 1x2e + 1x2e -&gt; 24x1e, 24
# 1x2e + 1x2e -&gt; 16x2e, 16
# 1x2e + 1x3o -&gt; 24x1o, 24
# 1x2e + 1x3o -&gt; 16x2o, 16
# 1x3o + 1x1o -&gt; 16x2e, 16
# 1x3o + 1x2e -&gt; 24x1o, 24
# 1x3o + 1x2e -&gt; 16x2o, 16
# 1x3o + 1x3o -&gt; 64x0e, 64
# 1x3o + 1x3o -&gt; 24x1e, 24
# 1x3o + 1x3o -&gt; 16x2e, 16</span></code></pre></figure> <p>And we can visualize these interaction paths:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tp1</span><span class="p">.</span><span class="nf">visualize</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/paths-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/paths-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/paths-1400.webp"/> <img src="/assets/img/posts/e3nn/paths.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Now we can define our simple equivariant model using e3nn’s <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">InvariantPolynomial</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">InvariantPolynomial</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> 
        <span class="c1"># dimension = 16 = 1 + 3 + 5 + 7
</span>        
        <span class="n">irreps_mid</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">64x0e + 24x1e + 24x1o + 16x2e + 16x2o</span><span class="sh">'</span><span class="p">)</span> 
        <span class="c1"># dimension = 368 = (64 * 1) + (24 * 3) + (24 * 3) + (16 * 5) + (16 * 5)
</span>        
        <span class="n">irreps_out</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">0o + 6x0e</span><span class="sh">'</span><span class="p">)</span> 
        <span class="c1"># dimension = (1 * 1) + (6 * 1), the first one is the pseudo-scalar for chiral +1, -1
</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tp1</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> 
                                               <span class="n">irreps_in2</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span>
                                               <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">tp2</span> <span class="o">=</span> <span class="nc">FullyConnectedTensorProduct</span><span class="p">(</span><span class="n">irreps_in1</span><span class="o">=</span><span class="n">irreps_mid</span><span class="p">,</span>
                                               <span class="n">irreps_in2</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span>
                                               <span class="n">irreps_out</span><span class="o">=</span><span class="n">irreps_out</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">irreps_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tp2</span><span class="p">.</span><span class="n">irreps_out</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">num_neighbors</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="mi">4</span>
        
        <span class="c1"># tensors of indices representing the graph
</span>        <span class="n">edge_src</span><span class="p">,</span> <span class="n">edge_dst</span> <span class="o">=</span> <span class="nf">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">)</span>
        
        <span class="c1"># edge distance vector
</span>        <span class="n">edge_vec</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_src</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">[</span><span class="n">edge_dst</span><span class="p">]</span>
        
        <span class="n">edge_sh</span> <span class="o">=</span> <span class="n">o3</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="n">l</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">irreps_sh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">edge_vec</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">normalization</span><span class="o">=</span><span class="sh">'</span><span class="s">component</span><span class="sh">'</span><span class="p">)</span>
        <span class="c1"># edge_sh is the coefficients of spherical harmonics from l=0 to l=3
</span>        <span class="c1"># or edge_sh is the projection of edge_vec on spherical harmonics basis
</span>        <span class="c1"># edge_sh is a 50 (number of edges by `radius_graph`) x 16 (l=3 spherical harmonics, i.e. 1 + 3 + 5 + 7) 
</span>        
        
        <span class="c1"># For each node, the initial features are the sum of the spherical harmonics of the neighbors
</span>        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_sh</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>


        <span class="c1"># For each edge, tensor product the features on the source node with the spherical harmonics
</span>        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp1</span><span class="p">(</span><span class="n">node_features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_sh</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
        

        <span class="n">edge_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tp2</span><span class="p">(</span><span class="n">node_features</span><span class="p">[</span><span class="n">edge_src</span><span class="p">],</span> <span class="n">edge_sh</span><span class="p">)</span>
        <span class="n">node_features</span> <span class="o">=</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">edge_features</span><span class="p">,</span> <span class="n">edge_dst</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_neighbors</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>


        <span class="c1"># For each graph, all the node's features are summed as final prediction
</span>        <span class="k">return</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">num_nodes</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span></code></pre></figure> <p>We use the <code class="language-plaintext highlighter-rouge">train</code> function again.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">f</span><span class="p">,</span> <span class="n">f_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantPolynomial</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">f_shuffle</span><span class="p">,</span> <span class="n">f_shuffle_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantPolynomial</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># epoch 10000 | loss 7.3        | 100.0% accuracy: 100%|██████████| 10001/10001 [00:41&lt;00:00, 241.84it/s]
# epoch 10000 | loss 2.0        | 100.0% accuracy: 100%|██████████| 10001/10001 [00:41&lt;00:00, 243.12it/s]</span></code></pre></figure> <p>Clearly, the model was trained better due to the E(3) equivariance. No shuffling and shuffling model achieved a final loss of \(7.3\) and \(2.0\) respectively with \(100\%\) accuracy, which is a lot better than the GNN baseline.</p> <h2 id="15-fancy-e3nn">1.5 Fancy E3NN</h2> <p>I have seen some people use the existent model of e3nn instead of writing the <code class="language-plaintext highlighter-rouge">FullyConnectedTensorProduct</code>. We will use this fancier model from e3nn: <code class="language-plaintext highlighter-rouge">gate_points_2101.Network</code>.</p> <p>We start off by assigning some hyperparameter:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">irreps_in</span><span class="sh">"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>  <span class="c1"># no input features
</span>    <span class="sh">"</span><span class="s">irreps_hidden</span><span class="sh">"</span><span class="p">:</span> <span class="n">o3</span><span class="p">.</span><span class="nc">Irreps</span><span class="p">(</span><span class="sh">'</span><span class="s">64x0e + 24x1e + 24x1o + 16x2e + 16x2o</span><span class="sh">'</span><span class="p">),</span>  <span class="c1"># hyperparameter: hidden irreps
</span>    <span class="sh">"</span><span class="s">irreps_out</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">0o + 6x0e</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># the same output irreps
</span>    <span class="sh">"</span><span class="s">irreps_node_attr</span><span class="sh">"</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">irreps_edge_attr</span><span class="sh">"</span><span class="p">:</span> <span class="n">o3</span><span class="p">.</span><span class="n">Irreps</span><span class="p">.</span><span class="nf">spherical_harmonics</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="c1"># using spherical(3) for featurization
</span>    <span class="sh">"</span><span class="s">layers</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>  <span class="c1"># hyperparameter: depth of the hidden irreps layer
</span>    <span class="sh">"</span><span class="s">max_radius</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">,</span> 
    <span class="sh">"</span><span class="s">number_of_basis</span><span class="sh">"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">radial_layers</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">radial_neurons</span><span class="sh">"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">num_neighbors</span><span class="sh">"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># average number of neighbors w/in max_radius
</span>    <span class="sh">"</span><span class="s">num_nodes</span><span class="sh">"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>  <span class="c1"># not important unless reduce_output is True
</span>    <span class="sh">"</span><span class="s">reduce_output</span><span class="sh">"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>  <span class="c1"># setting this to true would give us one scalar as an output.
</span><span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Network</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span> </code></pre></figure> <p>The output of the model is a <code class="language-plaintext highlighter-rouge">32 x 7</code> tensor, i.e. for each coordinate (regardless of the batch), the model outputs the 7-tensor. We need to aggregate these 4 7-tensors like before according to batch. So we created another wrapper model:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">InvariantNetwork</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">InvariantNetwork</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model_kwargs</span> <span class="o">=</span> <span class="n">model_kwargs</span>
        <span class="n">self</span><span class="p">.</span><span class="n">network</span> <span class="o">=</span> <span class="nc">Network</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span> 
        <span class="n">node_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">network</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="nf">scatter</span><span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">div</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model_kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">num_nodes</span><span class="sh">'</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span></code></pre></figure> <p>Again, we use our <code class="language-plaintext highlighter-rouge">train</code> function.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">ff</span><span class="p">,</span> <span class="n">ff_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantNetwork</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ff_shuffle</span><span class="p">,</span> <span class="n">ff_shuffle_logs</span> <span class="o">=</span> <span class="nf">train</span><span class="p">(</span><span class="nc">InvariantNetwork</span><span class="p">(),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># epoch 10000 | loss 0.0        | 100.0% accuracy: 100%|██████████| 10001/10001 [04:12&lt;00:00, 39.67it/s]
# epoch 10000 | loss 0.0        | 100.0% accuracy: 100%|██████████| 10001/10001 [04:17&lt;00:00, 38.89it/s]</span></code></pre></figure> <p>And.. take a look at those too-good-to-be-true losses and accuracies.</p> <h2 id="16-comparisons">1.6 Comparisons</h2> <p>Let’s compare the 3 models trained: GNN, E3NN Basic, E3NN Fancy. We plot the training losses and accuracies using the logs.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_yscale</span><span class="p">(</span><span class="sh">'</span><span class="s">log</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Loss</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">g_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">GNN Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">f_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNBasic Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span><span class="n">ff_shuffle_logs</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">E3NNFancy Shuffle</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/e3nn/compare-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/e3nn/compare-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/e3nn/compare-1400.webp"/> <img src="/assets/img/posts/e3nn/compare.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="17-check-equivariance">1.7 Check Equivariance</h2> <p>Finally, we need to check the model equivariance, using our very first equation</p> \[f(g \circ x) = g \circ f(x)\] <p>where \(g\) here is a 3D rotation or translation and \(f\) is our trained model. The model is acturally invariant, i.e. the output does not depend on the transformation of group operation.</p> \[f(g \circ x) = f(x)\] <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># == Check equivariance ==
# Because the model outputs (psuedo)scalars, we can easily directly
# check its equivariance to the same data with new rotations:
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Testing equivariance directly...</span><span class="sh">"</span><span class="p">)</span>

<span class="n">data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">rotated_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">tetris</span><span class="p">(</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># GNN
</span><span class="n">error</span> <span class="o">=</span> <span class="nf">g</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">g</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">shuffle_error</span> <span class="o">=</span> <span class="nf">g_shuffle</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">g_shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">GNN: Equivariance error = </span><span class="si">{</span><span class="n">error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">GNN Shuffle: Equivariance error = </span><span class="si">{</span><span class="n">shuffle_error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># E3NN Basic
</span><span class="n">error</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">f</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">shuffle_error</span> <span class="o">=</span> <span class="nf">f_shuffle</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">f_shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Basic: Equivariance error = </span><span class="si">{</span><span class="n">error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Basic Shuffle: Equivariance error = </span><span class="si">{</span><span class="n">shuffle_error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># E3NN Fancy
</span><span class="n">error</span> <span class="o">=</span> <span class="nf">ff</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">ff</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">shuffle_error</span> <span class="o">=</span> <span class="nf">ff_shuffle</span><span class="p">(</span><span class="n">rotated_data</span><span class="p">)</span> <span class="o">-</span> <span class="nf">ff_shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Fancy: Equivariance error = </span><span class="si">{</span><span class="n">error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">E3NN Fancy Shuffle: Equivariance error = </span><span class="si">{</span><span class="n">shuffle_error</span><span class="p">.</span><span class="nf">abs</span><span class="p">().</span><span class="nf">max</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>


<span class="c1"># Testing equivariance directly...
</span>
<span class="c1"># GNN: Equivariance error = 3.6e-01
# GNN Shuffle: Equivariance error = 3.3e-01
</span>
<span class="c1"># E3NN Basic: Equivariance error = 9.5e-07
# E3NN Basic Shuffle: Equivariance error = 9.5e-07
</span>
<span class="c1"># E3NN Fancy: Equivariance error = 5.5e-06
# E3NN Fancy Shuffle: Equivariance error = 5.7e-06</span></code></pre></figure> <p>And we can test the equivariance using e3nn’s <code class="language-plaintext highlighter-rouge">assert_equivariant</code> function.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Testing equivariance using `assert_equivariance`...</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># We can also use the library's `assert_equivariant` helper
# `assert_equivariant` also tests parity and translation, and
# can handle non-(psuedo)scalar outputs.
# To "interpret" between it and torch_geometric, we use a small wrapper:
</span>
<span class="k">def</span> <span class="nf">fwrapper</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span> <span class="k">return</span> <span class="nf">f</span><span class="p">(</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">ffwrapper</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span> <span class="k">return</span> <span class="nf">ff</span><span class="p">(</span><span class="nc">Data</span><span class="p">(</span><span class="n">pos</span><span class="o">=</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">))</span>

<span class="c1"># `assert_equivariant` uses logging to print a summary of the equivariance error,
# so we enable logging
</span><span class="n">logging</span><span class="p">.</span><span class="nf">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>

<span class="nf">assert_equivariant</span><span class="p">(</span>
    <span class="n">fwrapper</span><span class="p">,</span>
    <span class="n">args_in</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">],</span> <span class="c1"># We provide the original data that `assert_equivariant` will transform...
</span>    <span class="n">irreps_in</span><span class="o">=</span><span class="p">[</span> <span class="c1"># ...in accordance with these irreps...
</span>        <span class="sh">"</span><span class="s">cartesian_points</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># pos has vector 1o irreps, but is also translation equivariant
</span>        <span class="bp">None</span><span class="p">,</span>  <span class="c1"># `None` indicates invariant, possibly non-floating-point data
</span>    <span class="p">],</span>
    <span class="n">irreps_out</span><span class="o">=</span><span class="p">[</span><span class="n">f</span><span class="p">.</span><span class="n">irreps_out</span><span class="p">],</span> <span class="c1"># ...and confirm that the outputs transform correspondingly for these irreps:
</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="nf">assert_equivariant</span><span class="p">(</span><span class="n">ffwrapper</span><span class="p">,</span> <span class="n">args_in</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">batch</span><span class="p">],</span> <span class="n">irreps_in</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">cartesian_points</span><span class="sh">"</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">irreps_out</span><span class="o">=</span><span class="p">[</span><span class="n">f</span><span class="p">.</span><span class="n">irreps_out</span><span class="p">])</span>


<span class="c1"># INFO:e3nn.util.test:Tested equivariance of `fwrapper` -- max componentwise errors:
# (parity_k=0, did_translate=False) -&gt; max error=7.153e-07 in argument 0
# (parity_k=0, did_translate=True) -&gt; max error=2.339e-06 in argument 0
# (parity_k=1, did_translate=False) -&gt; max error=8.848e-07 in argument 0
# (parity_k=1, did_translate=True) -&gt; max error=1.810e-06 in argument 0
# INFO:e3nn.util.test:Tested equivariance of `ffwrapper` -- max componentwise errors:
# (parity_k=0, did_translate=False) -&gt; max error=2.742e-06 in argument 0
# (parity_k=0, did_translate=True) -&gt; max error=1.824e-05 in argument 0
# (parity_k=1, did_translate=False) -&gt; max error=3.345e-06 in argument 0
# (parity_k=1, did_translate=True) -&gt; max error=2.146e-05 in argument 0
# Testing equivariance using `assert_equivariance`...</span></code></pre></figure> <p>And this concludes the part 1 of initial messing around of e3nn.</p> <h1 id="references">References</h1> <ol> <li>Mario Geiger, Tess Smidt, e3nn: Euclidean Neural Networks, https://arxiv.org/abs/2207.09453</li> <li>https://e3nn.org</li> <li>https://docs.e3nn.org/en/latest/examples/tetris_polynomial.html</li> </ol>]]></content><author><name></name></author><category term="models"/><category term="coding"/><category term="reading"/><category term="solving"/><summary type="html"><![CDATA[Playing and benchmarking with E3NN]]></summary></entry><entry><title type="html">C4 Group CNN</title><link href="https://jipq6175.github.io/blog/2023/c4_convolution/" rel="alternate" type="text/html" title="C4 Group CNN"/><published>2023-06-13T18:20:00+00:00</published><updated>2023-06-13T18:20:00+00:00</updated><id>https://jipq6175.github.io/blog/2023/c4_convolution</id><content type="html" xml:base="https://jipq6175.github.io/blog/2023/c4_convolution/"><![CDATA[<p>This was my learning process for the simple group convolution from scratch, which I did back in 2021 along with the <a href="https://geometricdeeplearning.com/lectures/">Geometric Deep Learning (GDL) course</a>. This is part of the tutorial 2, which can be found <a href="https://colab.research.google.com/drive/1p9vlVAUcQZXQjulA7z_FyPrB9UXFATrR">here</a>. I was trying to remind myself of some of the key concepts by cleaning my previous codes and summarizing here for myself.</p> <p>The key of the group equivariant neural network is to identify the spaces of input, hidden and output because the network will perform like a function mapping from one space to another. I use \(X\), \(Y\) as input and output spaces and \(H_i\) as the i-th hidden space. The network consists a number of layers, transforming the input to hidden to output:</p> \[X \to H_1 \to H_2 \to ... \to H_i \to ... \to Y\] <p>Each of the layers is represented as \(\to\) in the above and depneding on which spaces the layers map from and to, we need to consider the design of the layers. This will be the focus of this post.</p> <h3 id="0-dependencies">0. Dependencies</h3> <p>Let’s just load some dependencies for later use.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># packages
</span><span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">torch</span><span class="p">,</span> <span class="n">einops</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="n">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>

<span class="n">TOL</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="c1"># if torch.cuda.is_available(): DEVICE = 'cuda'
# else: DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'
</span><span class="n">DEVICE</span> <span class="o">=</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span> <span class="c1"># I find the 'mps' device is buggy or I have not spent time to write better code for the mac gpu
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span></code></pre></figure> <h3 id="1-group">1. Group</h3> <p>A group \((G, \circ )\) is a set \(G\) with a binary operation: \(\circ : G\times G \to G\), which satisfies the following (Ignored the \(\circ\)).</p> <ul> <li>Associativity: \(a (bc) = (ab) c\)</li> <li>Identity: \(e \in G\), \(g e = e g = g\)</li> <li>Inverse: \(\forall g \in G\), \(gg^{-1} = g^{-1}g = e\)</li> </ul> <p>Consider the group \(G = C_4\), the cyclic group with \(\pi / 2\) planar rotation. \(\|C_4\| = 4\). Let \(X\) be the set of some \(n\times n\) gray images. An image \(x \in X\) is a function \(x: p \to x[p] \in R\) which maps each pixel \(p = (h, w)\) to a real number.</p> <p>An element \(g \in G = C_4\), transforms an image \(x \in X\) into the image \(gx \in X\) through rotation. The rotated image \(gx\) is \([gx](p) = x(g^{-1}p)\) where \(g^{-1}p\) is the pixel in the unrotated image. This action is the following:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># rotate an image, the x is ... x H x W in dimension
</span><span class="k">def</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span><span class="p">.</span><span class="nf">rot90</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span></code></pre></figure> <h3 id="2-equivariant-convolution-layers">2. Equivariant Convolution Layers</h3> <p>An equivariant layer (or function) \(\psi: X \to Y\) from an input G-space \(X\) to an output G-space \(Y\). The input space is the pixel space and we choose the same output space: \(Y=X\). So both input and output are the gray-scale image (they might be of different sizes / dimensions.)</p> <p>The equivariant layer will be \(3 \times 3\) filter. We will verify that a random filter is not a rotational equivariant layer.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># random filter
</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span> <span class="o">**</span> <span class="mi">3</span>
<span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">psi_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">psi_gx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">gx</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">g_psi_x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$g.\psi(x)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$\psi(g.x)$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">TOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>Not equivariant!!</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig1-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig1-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig1-1400.webp"/> <img src="/assets/img/posts/gcnn/fig1.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Clearly, if the filter \(\psi\) has no constraint on the weights,</p> \[\psi(gx) \neq g\psi(x)\] <p>There must be some \(C_4\) symmetry boiled in the filter. Let’s first try the isotropic filter where there are 2 trainable weights: one in the middle, the the other in the ring.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Isotropic filter
# The filter looks like: 
# a, a, a
# a, b, a
# a, a, a
</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>

<span class="nb">filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">filter</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">()</span> <span class="c1"># middle pixel
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">filter</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">()</span> <span class="c1"># ring pixel
</span>
<span class="c1"># we recycle the previous codes: 
</span><span class="n">psi_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">psi_gx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">gx</span><span class="p">,</span> <span class="nb">filter</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">g_psi_x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$g.\psi(x)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$\psi(g.x)$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">TOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>Equivariant</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig2-1400.webp"/> <img src="/assets/img/posts/gcnn/fig2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Let’s use this filter to build a equivariant convolution layer:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">IsotropicEConv2d</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">IsotropicEConv2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>

        <span class="c1"># for each filter contains 2 parameters
</span>        <span class="c1"># There are total of in_channels x out_channels filters
</span>        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">out_channels</span><span class="p">)),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">out_channels</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">bias</span> <span class="k">else</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">build_filter</span><span class="p">(</span><span class="n">self</span><span class="p">):</span> 
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">)</span>
        <span class="nb">filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="nb">filter</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">).</span><span class="nf">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
        <span class="nb">filter</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">filter</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">_filter</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">build_filter</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span></code></pre></figure> <p>Since this layer maps from input space \(X\) to input space \(X\), so we define the following equivariance checker.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">check_equivariance_XX</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">):</span> 

    <span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

    <span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">psi_x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">psi_gx</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
    <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">psi_x</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span></code></pre></figure> <p>Let’s check if the <code class="language-plaintext highlighter-rouge">IsotropicEConv2d</code> is acturally equivariant:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">33</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">layer</span> <span class="o">=</span> <span class="nc">IsotropicEConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">check_equivariance_XX</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">g_psi_x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$g.\psi(x)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">$\psi(g.x)$</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <p>Equivariant</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig3-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig3-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig3-1400.webp"/> <img src="/assets/img/posts/gcnn/fig3.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Unfortunately, isotropic filters are not very expressive. Instead, we would like to use more general, unconstrained filters. To do so, we need to rely on group convolution.</p> <p>Let \(X\) be the space of grayscale images, \(\psi \in X\) be a filter and \(x \in x\) be an input image. The group convolution is</p> \[[\psi x](t, r) = \sum_{p} \psi((t, r)^{-1}p)x(p) = \sum_{p} \psi(r^{-1}(p - t))x(p)\] <p>The output of the convolution is not a grayscale image in \(X\). It is now a function over the rotational group. The use of the filter \(\psi\) in the group convolution maps the input space \(X\) into a new larger space $Y$, where \(Y\) is the space of all function \(y: p_4 \to \mathbf{R}\).</p> <p>This is the lifting convolution since it maps the space \(X\) to the more complex space \(Y\). Note that a function \(y \in Y\) can be implemented as a 4-channel image, where the ith channel is defined as \(y_i(t) = y(y, r=i) \in \mathbf{R}, i \in \{0, 1, 2, 3\}\)</p> <p>In the end of the day, we want to have a network</p> \[X \to H_1 \to H_2 \to ... \to Y\] <p>where \(X\) is the grayscale image or the 3-channel image space and \(H\)’s are the group (hidden) space and \(Y\) can be a pooled invariant output or equivariant output space.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span> 
    <span class="c1"># y is (..., 4, h, w)
</span>    <span class="c1"># r = 0, 1, 2, 3
</span>    
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">3</span>
    <span class="k">assert</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>
    <span class="k">assert</span> <span class="n">r</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

    <span class="n">ry</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="c1"># then we just rotate each of the 4 channels
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">ry</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">r</span><span class="p">)</span> <span class="o">%</span> <span class="mi">4</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">r</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ry</span></code></pre></figure> <p>See the rotation p4 group by \(r = 1\):</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Test the rotation by r = 1
</span><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span> <span class="o">**</span> <span class="mi">3</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">*</span><span class="mi">10</span>


<span class="n">ry</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">'</span><span class="s">Original y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">ry</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">].</span><span class="nf">numpy</span><span class="p">())</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">'</span><span class="s">Rotated y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig4-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig4-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig4-1400.webp"/> <img src="/assets/img/posts/gcnn/fig4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/gcnn/fig5-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/gcnn/fig5-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/gcnn/fig5-1400.webp"/> <img src="/assets/img/posts/gcnn/fig5.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Next, we will build a lifting convoltuion. The input is a grayscale image \(x \in X\) and the output is a function \(y \in Y\). This can berealized by exploiting the usual convolution using 4 rotated copies of a <code class="language-plaintext highlighter-rouge">SINGLE</code> learnable filter. The image is colvolved with each copy independently by stacking 4 copies into a unique filter with 4 output channels.</p> <p>Finally, a convolutional layer usually includes a bias term. In a normal convolutional network, it is common to share the same bias over all pixels, i.e. the same bias is summed to the features at each pixel. Similarly, when we use a lifting convolution, we share the bias over all pixels but also over all rotations, i.e. over the output channels.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Lift conv of C4 Group
</span>
<span class="k">class</span> <span class="nc">LiftingConv2d</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LiftingConv2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="c1"># learnable weights for `out_channels x in_channels` different learnable filters, each of shape `kernel_size x kernel_size`
</span>        <span class="c1"># later populate the larger C4 filters of shape `out_channels x 4 x in_channels x kernel_size x kernel_size` by rotating 4 times 
</span>        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">).</span><span class="nf">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                                                               <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">)),</span>
                                         <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_build_filter</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># using the tensors of learnable parameters, build 
</span>        <span class="c1"># - the `out_channels x 4 x in_channels x kernel_size x kernel_size` filter
</span>        <span class="c1"># - the `out_channels x 4` bias
</span>        <span class="n">_filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">_filter</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c -&gt; c g</span><span class="sh">'</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        
        <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_build_filter</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">_filter</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">lifting _filter has shape </span><span class="si">{</span><span class="n">_filter</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        <span class="k">assert</span> <span class="n">_bias</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">lifting _bias has shape </span><span class="si">{</span><span class="n">_bias</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        
        <span class="n">_filter</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_filter</span><span class="p">,</span> <span class="sh">'</span><span class="s">o c i w h -&gt; (o c) i w h</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c g -&gt; (c g)</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">_bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="sh">'</span><span class="s">b (o c) w h -&gt; b o c w h</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    </code></pre></figure> <p>Since this layer maps from input space \(X\) to group space \(Y\), so we define the following equivariance checker.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">check_equivariance_XY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">):</span> 

    <span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

    <span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in X
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">psi_x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">psi_gx</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
    <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in Y
</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">psi_x</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span>
    </code></pre></figure> <p>Let’s check if the <code class="language-plaintext highlighter-rouge">LiftingConv2d</code> is equivariant.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Let's check if the layer is really equivariant
</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">33</span>

<span class="n">layer</span> <span class="o">=</span> <span class="nc">LiftingConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># layer.to(DEVICE)
</span><span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
<span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">check_equivariance_XY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Equivariant</p> <p>The lifting convolution is only the first piece of building the \(C_4\) equivariant neural network. Remember we are after</p> \[X \to H_1 \to H_2 \to ... \to Y\] <p>and lifting convolution is the first “\(\to\)”, we still need to build equivariant layers from \(H_i \to H_j\).</p> <p>As compared to the usual CNN: \(X \to X \to X ... \to Y\).</p> <p>We will construct the convolution on the <code class="language-plaintext highlighter-rouge">OUTPUT</code> from the lifting convolution.</p> \[[\psi x](t, r) = \sum_{s \in C_4}\sum_{p}[r \psi](p-t, s)x(p, s)\] <p>So we simply use additional 4-rotated filters for the convolution of the input, i.e. 4 rotated filters for 4 channels from lift convolution. The output of this group convolution is also 4 channels and we can stack this group convolution to build a deep G-CNN.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># GroupConv2d
</span>
<span class="k">class</span> <span class="nc">GroupConv2d</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">GroupConv2d</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">empty</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> 
                                                     <span class="mi">4</span><span class="p">,</span>
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> 
                                                     <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">).</span><span class="nf">normal_</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
                                                                               <span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">)),</span>
                                         <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_build_filter</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># using the tensors of learnable parameters, build 
</span>        <span class="c1"># - the `out_channels x 4 x in_channels x 4 x kernel_size x kernel_size` filter
</span>        <span class="c1"># - the `out_channels x 4` bias
</span>        <span class="n">_filter</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">_filter</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c -&gt; c g</span><span class="sh">'</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        
        <span class="n">_filter</span><span class="p">,</span> <span class="n">_bias</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_build_filter</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">_filter</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">groupconv _filter has shape </span><span class="si">{</span><span class="n">_filter</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        <span class="k">assert</span> <span class="n">_bias</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="sa">f</span><span class="sh">'</span><span class="s">groupconv _bias has shape </span><span class="si">{</span><span class="n">_bias</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">'</span>
        
        <span class="n">_filter</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_filter</span><span class="p">,</span> <span class="sh">'</span><span class="s">o c i s w h -&gt; (o c) (i s) w h</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">_bias</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">_bias</span><span class="p">,</span> <span class="sh">'</span><span class="s">c g -&gt; (c g)</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="c1"># x is `batch_size x in_channels x 4 x W x H`
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="sh">'</span><span class="s">b i c w h -&gt; b (i c) w h</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_filter</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">_bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">einops</span><span class="p">.</span><span class="nf">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="sh">'</span><span class="s">b (o c) w h -&gt; b o c w h</span><span class="sh">'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    
        </code></pre></figure> <p>Now, <code class="language-plaintext highlighter-rouge">GroupConv2d</code> maps from group space \(Y\) to the same group space \(Y\). We will define another equivariance checker.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">check_equivariance_YY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">TOL</span><span class="p">):</span> 

    <span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

    <span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in Y
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">psi_x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">psi_gx</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
    <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">rotate_p4</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rotate in Y
</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_x</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">psi_x</span><span class="p">),</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Equivariant</span><span class="sh">'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tol</span><span class="p">)</span> <span class="k">else</span> <span class="sh">'</span><span class="s">Not equivariant!!</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span>
    </code></pre></figure> <p>And ckeck the equivariance.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Let's check if the layer is really equivariant
</span><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">33</span>

<span class="n">layer</span> <span class="o">=</span> <span class="nc">GroupConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">layer</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="n">psi_gx</span><span class="p">,</span> <span class="n">g_psi_x</span> <span class="o">=</span> <span class="nf">check_equivariance_YY</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Equivariant</p> <h3 id="3-implement-a-deep-rotation-equivariant-cnn">3. Implement A Deep Rotation Equivariant CNN</h3> <p>Fianlly, you can combine the layers you have implemented earlier to build a rotation equivariant CNN. You model will take in input batches of $33 \times 33$ images with a single input channel.</p> <p>The network performs a first <em>lifting layer</em> with $8$ output channels and is followed by $4$ <em>group convolution</em> with, respectively, $16$, $32$, $64$ and $128$ output channels. All convolutions have kernel size $3$, padding $1$ and stride $1$ and should use the bias. All convolutions are followed by <code class="language-plaintext highlighter-rouge">torch.nn.MaxPool3d</code> and <code class="language-plaintext highlighter-rouge">torch.nn.ReLU</code>. Note that we use <code class="language-plaintext highlighter-rouge">MaxPool3d</code> rather than <code class="language-plaintext highlighter-rouge">MaxPool2d</code> since our feature tensors have $5$ dimensions (there is an additional dimension of size $4$). In all pooling layers, we will use a kernel of size $(1, 3, 3)$, a stride of $(1, 2, 2)$ and a padding of $(0, 1, 1)$. This ensures pooling is done only on the spatial dimensions, while the rotational dimension is preserved. The last pooling layer, however, will also pool over the rotational dimension so it will use a kernel of size $(4, 3, 3)$, stride $(1, 1, 1)$ and padding $(0, 0, 0)$.</p> <p>Finally, the features extracted from the convolutional network are used in a linear layer to classify the input in $10$ classes.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Equivariant Networks
</span>
<span class="c1"># Lifting Layers: X -&gt; Y over p4
# GroupConv Layers: Y -&gt; Y over p4
</span>
<span class="c1"># So the idea is to have a lifting layer followed by groupconv layers and non linearities
</span>
<span class="c1"># to make it invariant, make sure to use c4_pooling at the end
</span><span class="k">class</span> <span class="nc">C4CNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">C4CNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">channels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">n_classes</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">liftingconv</span> <span class="o">=</span> <span class="nc">LiftingConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span> 
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">GroupConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">())</span>
            
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span> <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool3d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">groupconv_encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">3200</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">_c4_pool</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span> 
        <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span> <span class="c1"># batch, channel, group, height, weight
</span>        <span class="k">assert</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>

        <span class="n">x_pre_pool</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">x_pool</span> <span class="o">=</span> <span class="n">x_pre_pool</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_pool</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span> 
        <span class="n">lifted_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">liftingconv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">gp_encoded_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">groupconv_encoder</span><span class="p">(</span><span class="n">lifted_x</span><span class="p">)</span> <span class="c1"># batch x channel x group x width x height
</span>
        <span class="c1"># Before pooling, the network is equivariant and after pooling, the model is invariant
</span>        <span class="c1"># however, the hidden features are still equivariant 
</span>        <span class="n">pooled_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_c4_pool</span><span class="p">(</span><span class="n">gp_encoded_x</span><span class="p">)</span> <span class="c1"># batch x channel x 1 x width x height
</span>        <span class="n">flattened_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">pooled_x</span><span class="p">)</span> <span class="c1"># batch x 3200
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">flattened_x</span><span class="p">)</span></code></pre></figure> <p>So <code class="language-plaintext highlighter-rouge">C4CNN</code> is invariant to \(C_4\) rotation, meaning that it can recognize an image even though it’s rotated in \(C_4\). the <code class="language-plaintext highlighter-rouge">C4CNN</code>, though invariant, it contains a lot to hidden features that are equivariant. In other words:</p> <p>Rotated image -&gt; rotated features -&gt; rotated features -&gt; … -&gt; invariant output</p> <p>Allowing the equivariant hidden features make the model more powerful and data efficient because the model is already symmetry-restricted.</p> <p>Let’s check if the <code class="language-plaintext highlighter-rouge">C4CNN</code> is invariant.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">net</span> <span class="o">=</span> <span class="nc">C4CNN</span><span class="p">()</span>

<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">37</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">y</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># batch x n_classes
</span>
<span class="c1"># Let's check if the model is invariant!
</span><span class="n">gx</span> <span class="o">=</span> <span class="nf">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">gy</span> <span class="o">=</span> <span class="nf">net</span><span class="p">(</span><span class="n">gx</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">allclose</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">gy</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">TOL</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">TOL</span><span class="p">)</span></code></pre></figure> <h3 id="4-compare-cnn-to-gcnn-on-rotated-mnist-dataset">4. Compare CNN to GCNN on rotated MNIST dataset</h3> <p>After buidling the <code class="language-plaintext highlighter-rouge">C4CNN</code> as \(C_4\)-invariant model with \(C_4\)-equivariant features, we want to compare it with typical CNN on the rotated MNIST dataset.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># dataset
# https://zenodo.org/record/3670627/files/mnist_rotation_new.zip?download=1
</span><span class="k">class</span> <span class="nc">MnistRotDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">]</span>
            
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">:</span> <span class="nb">file</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat</span><span class="sh">'</span>
        <span class="k">else</span><span class="p">:</span> <span class="nb">file</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat</span><span class="sh">'</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">)</span>    
        <span class="n">self</span><span class="p">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># images in MNIST are only 28x28
</span>        <span class="c1"># we pad them to have shape 33 x 33
</span>        <span class="n">self</span><span class="p">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">images</span><span class="p">,</span> <span class="n">pad_width</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">edge</span><span class="sh">'</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">self</span><span class="p">.</span><span class="n">images</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">)</span>


<span class="n">train_set</span> <span class="o">=</span> <span class="nc">MnistRotDataset</span><span class="p">(</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ToTensor</span><span class="p">())</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="nc">MnistRotDataset</span><span class="p">(</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ToTensor</span><span class="p">())</span></code></pre></figure> <p>We define functions to train and test models, which is typical pytorch forward pass with/without gradients.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">nepoch</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">nepoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>

            <span class="c1"># x, t = x.to(DEVICE), t.to(DEVICE)
</span>            <span class="n">y</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
          
            <span class="n">y</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">t</span><span class="p">).</span><span class="nf">sum</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
    
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="o">*</span><span class="mf">100.</span>
    <span class="k">return</span> <span class="n">accuracy</span></code></pre></figure> <p>Next, we define a CNN model similar to <code class="language-plaintext highlighter-rouge">C4CNN</code> by recycling the code.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Build a normal CNN 
</span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">channels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">first_conv</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
            <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span> <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span> 
                                        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">first_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># x = torch.nn.functional.layer_norm(x, x.shape[-3:])
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">convs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># apply average pooling over remaining spatial dimensions
</span>        <span class="c1"># x = torch.nn.functional.adaptive_avg_pool2d(x, 1).squeeze()
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></code></pre></figure> <p>Let’s finally get the models trained and report the accuracies.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># training and keep the stats
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training C4CNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">c4cnn</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="nc">C4CNN</span><span class="p">(),</span> <span class="n">nepoch</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Training CNN</span><span class="sh">'</span><span class="p">)</span>
<span class="n">cnn</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="nc">CNN</span><span class="p">(),</span> <span class="n">nepoch</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>


<span class="n">acc_c4cnn</span> <span class="o">=</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">c4cnn</span><span class="p">)</span>
<span class="n">acc_cnn</span> <span class="o">=</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">cnn</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">C4CNN Test Accuracy: </span><span class="si">{</span><span class="n">acc_c4cnn</span> <span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">CNN Test Accuracy: </span><span class="si">{</span><span class="n">acc_cnn</span> <span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">C4CNN</span> <span class="n">Test</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">91.744</span>
<span class="n">CNN</span> <span class="n">Test</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">82.134</span></code></pre></figure> <h3 id="5-final-note">5. Final Note</h3> <p>The performance of <code class="language-plaintext highlighter-rouge">C4CNN</code> is significantly higher. I also did 25 repeated runs and <code class="language-plaintext highlighter-rouge">C4CNN</code> and <code class="language-plaintext highlighter-rouge">CNN</code> averaged <code class="language-plaintext highlighter-rouge">92%</code> and <code class="language-plaintext highlighter-rouge">81%</code> in accuracy. However, <code class="language-plaintext highlighter-rouge">C4CNN</code> took about <code class="language-plaintext highlighter-rouge">5x</code> more time to train. Considering the (maybe) <code class="language-plaintext highlighter-rouge">4x</code> data one needs to augment, this might not be beneficial in this case and also <a href="https://distill.pub/2020/circuits/equivariance">natural equivariance</a> shows up in the trained filters.</p> <p>However, equivariance makes a lot difference in the continuous group where one cannot just rotate the filters to achieve equivariance.</p>]]></content><author><name></name></author><category term="models"/><category term="coding"/><category term="reading"/><summary type="html"><![CDATA[A small exercise to implement C4 group convolution]]></summary></entry><entry><title type="html">Training GNN for Stability Prediction</title><link href="https://jipq6175.github.io/blog/2023/stability_gnn/" rel="alternate" type="text/html" title="Training GNN for Stability Prediction"/><published>2023-03-19T18:19:00+00:00</published><updated>2023-03-19T18:19:00+00:00</updated><id>https://jipq6175.github.io/blog/2023/stability_gnn</id><content type="html" xml:base="https://jipq6175.github.io/blog/2023/stability_gnn/"><![CDATA[<p>Mutations of a protein affect the protein stability, via changing the local interactions among neighboring residues. This mutation effect has been hard to predict especially in the case of protein conformational changes becuase of limited experimental data available. Recently, <a href="https://www.biorxiv.org/content/10.1101/2022.12.06.519132v1">Tsuboyama et al.</a> reported a large study of protein folding stability and made the <a href="https://zenodo.org/record/7401275#.ZBd9r-zMLLU">data</a> available.</p> <p>It might be interesting to model these protein stability data (dG) using the structure and graph neural networks. The notebook and associated subset of the data can be found <a href="https://github.com/jipq6175/StabilityGNN">here</a>. I was using a structure given from the paper: <code class="language-plaintext highlighter-rouge">HEEH_KT_rd6_4322.pdb</code> and the cleaned dG data <code class="language-plaintext highlighter-rouge">test_dG_data.csv</code>. Each entry represent the single point mutation and corresponding dG. The goal is to build a graph neural network that learns the local neighborhood of the point mutation and predict the stability effect.</p> <h3 id="0-dependencies">0. Dependencies</h3> <p>Building a graph from pdb requires many dependencies for the interaction edges. Here I just used minimal functions to construct the edges.</p> <p>If ones uses edge features in the message passing, I would recommend build all edges. Otherwise, these edges might result in over-smoothing in message passing.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre></td><td class="code"><pre><span class="c1"># Dependencies
</span><span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">torch</span><span class="p">,</span> <span class="n">copy</span><span class="p">,</span> <span class="n">Bio</span><span class="p">,</span> <span class="n">logging</span>

<span class="n">logging</span><span class="p">.</span><span class="nf">getLogger</span><span class="p">(</span><span class="sh">'</span><span class="s">matplotlib</span><span class="sh">'</span><span class="p">).</span><span class="nf">setLevel</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">CRITICAL</span><span class="p">)</span>
<span class="n">logging</span><span class="p">.</span><span class="nf">getLogger</span><span class="p">(</span><span class="sh">'</span><span class="s">graphein</span><span class="sh">'</span><span class="p">).</span><span class="nf">setLevel</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">CRITICAL</span><span class="p">)</span>


<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>

<span class="kn">from</span> <span class="n">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="n">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GCNConv</span>
<span class="kn">from</span> <span class="n">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">DataListLoader</span>
<span class="kn">from</span> <span class="n">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="n">torch_geometric.utils</span> <span class="kn">import</span> <span class="n">add_self_loops</span>

<span class="kn">from</span> <span class="n">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter_mean</span><span class="p">,</span> <span class="n">scatter_sum</span>


<span class="kn">from</span> <span class="n">graphein.protein.config</span> <span class="kn">import</span> <span class="n">ProteinGraphConfig</span>
<span class="kn">from</span> <span class="n">graphein.protein.graphs</span> <span class="kn">import</span> <span class="n">construct_graph</span>
<span class="kn">from</span> <span class="n">graphein.protein.edges.distance</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">graphein.protein.features.nodes.amino_acid</span> <span class="kn">import</span> <span class="n">amino_acid_one_hot</span>
<span class="kn">from</span> <span class="n">graphein.protein.visualisation</span> <span class="kn">import</span> <span class="n">plotly_protein_structure_graph</span>

<span class="kn">from</span> <span class="n">graphein.ml.conversion</span> <span class="kn">import</span> <span class="n">GraphFormatConvertor</span>




<span class="n">node_edge_graph_funcs</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">edge_construction_functions</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="n">add_peptide_bonds</span><span class="p">,</span>
                                                         <span class="n">add_hydrogen_bond_interactions</span><span class="p">,</span>
                                                         <span class="n">add_backbone_carbonyl_carbonyl_interactions</span><span class="p">,</span>
                                                         <span class="nf">partial</span><span class="p">(</span><span class="n">add_distance_threshold</span><span class="p">,</span> <span class="n">long_interaction_threshold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">8.0</span><span class="p">)],</span> 
                         <span class="sh">'</span><span class="s">node_metadata_functions</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="n">amino_acid_one_hot</span><span class="p">]}</span>

<span class="n">CONFIG</span> <span class="o">=</span> <span class="nc">ProteinGraphConfig</span><span class="p">(</span><span class="o">**</span><span class="n">node_edge_graph_funcs</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <h3 id="1-example-data">1. Example Data</h3> <p>I merged the tables from <code class="language-plaintext highlighter-rouge">Raw_NGS_count_tables</code>, <code class="language-plaintext highlighter-rouge">K50_dG_tables</code> and pull out one structure from AlphaFold_model_PDBs for this example.</p> <p>The <code class="language-plaintext highlighter-rouge">test_dG_data.csv</code> is the simplified file.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="c1"># tables for dG
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">test_dG_data.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">dropna</span><span class="p">().</span><span class="n">iloc</span><span class="p">[</span><span class="mi">3</span><span class="p">:]</span>
<span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">mutation</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="p">(</span><span class="mi">946</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span></code></pre></figure> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/stabilitygnn/table-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/stabilitygnn/table-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/stabilitygnn/table-1400.webp"/> <img src="/assets/img/posts/stabilitygnn/table.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Now, construct the protein graph using <code class="language-plaintext highlighter-rouge">Graphein</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="code"><pre><span class="c1"># Construct graph from PDB
</span>
<span class="n">g</span> <span class="o">=</span> <span class="nf">construct_graph</span><span class="p">(</span><span class="n">pdb_path</span><span class="o">=</span><span class="sh">'</span><span class="s">HEEH_KT_rd6_4322.pdb</span><span class="sh">'</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">CONFIG</span><span class="p">)</span>

<span class="c1"># visualize as point cloud graph in 3d
</span><span class="n">p</span> <span class="o">=</span> <span class="nf">plotly_protein_structure_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">colour_edges_by</span><span class="o">=</span><span class="sh">"</span><span class="s">kind</span><span class="sh">"</span><span class="p">,</span>
                                      <span class="n">colour_nodes_by</span><span class="o">=</span><span class="sh">"</span><span class="s">element_symbol</span><span class="sh">"</span><span class="p">,</span>
                                      <span class="n">label_node_ids</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                      <span class="n">node_size_min</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                      <span class="n">node_alpha</span><span class="o">=</span><span class="mf">0.85</span><span class="p">,</span>
                                      <span class="n">node_size_multiplier</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                      <span class="n">plot_title</span><span class="o">=</span><span class="sh">"</span><span class="s">HEEH_KT_rd6_4322</span><span class="sh">"</span><span class="p">)</span>
<span class="n">p</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Output:</p> <div class="l-page"> <iframe src="/assets/img/posts/stabilitygnn/prot.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <p>Does it look like 2 alpha helices and 2 small beta sheets, like below?</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/stabilitygnn/prot-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/stabilitygnn/prot-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/stabilitygnn/prot-1400.webp"/> <img src="/assets/img/posts/stabilitygnn/prot.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Now <code class="language-plaintext highlighter-rouge">g</code> is a <code class="language-plaintext highlighter-rouge">networkx</code> graph and we can take a look at what it contains.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="nf">print</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="sh">'</span><span class="s">A:SER:1</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># node features
</span><span class="nf">print</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">edges</span><span class="p">[(</span><span class="sh">'</span><span class="s">A:SER:1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">A:GLU:2</span><span class="sh">'</span><span class="p">)])</span> <span class="c1"># edge_features
# g.graph contains the original pdb info</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="p">{</span><span class="sh">'</span><span class="s">chain_id</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">residue_name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">SER</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">residue_number</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">atom_type</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">CA</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">element_symbol</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">coords</span><span class="sh">'</span><span class="p">:</span> <span class="nf">array</span><span class="p">([</span><span class="mf">1.458</span><span class="p">,</span> <span class="mf">0.</span>   <span class="p">,</span> <span class="mf">0.</span>   <span class="p">]),</span> <span class="sh">'</span><span class="s">b_factor</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="sh">'</span><span class="s">amino_acid_one_hot</span><span class="sh">'</span><span class="p">:</span> <span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])}</span>
<span class="p">{</span><span class="sh">'</span><span class="s">kind</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">bb_carbonyl_carbonyl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">peptide_bond</span><span class="sh">'</span><span class="p">},</span> <span class="sh">'</span><span class="s">distance</span><span class="sh">'</span><span class="p">:</span> <span class="mf">3.8009521175621246</span><span class="p">}</span></code></pre></figure> <h3 id="2-data-wrangling">2. Data Wrangling</h3> <p>Here I defined some functions for arranging the data intoeasy-to-work-with format, including the pytorch data object <code class="language-plaintext highlighter-rouge">GFocus</code>.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">one2three</span><span class="p">(</span><span class="n">resn</span><span class="p">):</span> 
    <span class="k">return</span> <span class="n">Bio</span><span class="p">.</span><span class="n">SeqUtils</span><span class="p">.</span><span class="nf">seq3</span><span class="p">(</span><span class="n">resn</span><span class="p">).</span><span class="nf">upper</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_aa_one_hot</span><span class="p">(</span><span class="n">resn</span><span class="p">):</span> 
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">resn</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span> <span class="n">aa</span> <span class="o">=</span> <span class="n">resn</span>
    <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">resn</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="n">aa</span> <span class="o">=</span> <span class="nf">one2three</span><span class="p">(</span><span class="n">resn</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="nc">NotImplementedError</span><span class="p">()</span>
    <span class="k">return</span> <span class="nf">amino_acid_one_hot</span><span class="p">(</span><span class="sh">''</span><span class="p">,</span> <span class="p">{</span><span class="sh">'</span><span class="s">residue_name</span><span class="sh">'</span><span class="p">:</span> <span class="n">aa</span><span class="p">})</span>

<span class="k">def</span> <span class="nf">get_node_features</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">field</span><span class="p">):</span> 
    <span class="n">node</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">nodes</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">g</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">g</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="p">][</span><span class="n">field</span><span class="p">]</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">g</span><span class="p">.</span><span class="n">nodes</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">graph2data</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">focus</span><span class="p">,</span> <span class="n">fields</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">amino_acid_one_hot</span><span class="sh">'</span><span class="p">]):</span> 
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="nf">nodes</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">focus</span> <span class="ow">in</span> <span class="n">g</span><span class="p">.</span><span class="n">nodes</span>
    <span class="n">d</span> <span class="o">=</span> <span class="nc">GraphFormatConvertor</span><span class="p">(</span><span class="sh">'</span><span class="s">nx</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">pyg</span><span class="sh">'</span><span class="p">).</span><span class="nf">convert_nx_to_pyg</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">d</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="nf">get_node_features</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">field</span><span class="p">)</span> <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">d</span><span class="p">.</span><span class="n">focus</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">nodes</span><span class="p">).</span><span class="nf">index</span><span class="p">(</span><span class="n">focus</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>


<span class="c1"># The Customized Focused Graph
# The focus is the node being mutated
</span><span class="k">class</span> <span class="nc">GFocus</span><span class="p">(</span><span class="n">Data</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">edge_index</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">focus</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mut</span><span class="sh">'</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">attrs</span><span class="p">:</span> <span class="nf">setattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="nf">getattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">attr</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__inc__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="sh">'</span><span class="s">focus</span><span class="sh">'</span><span class="p">:</span> <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="nf">super</span><span class="p">().</span><span class="nf">__inc__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">mutate_aa</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">mut</span><span class="p">):</span> 
    <span class="n">chain</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">g</span><span class="p">.</span><span class="n">nodes</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">wt</span><span class="p">,</span> <span class="n">resi</span><span class="p">,</span> <span class="n">mt</span> <span class="o">=</span> <span class="nf">one2three</span><span class="p">(</span><span class="n">mut</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">mut</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nf">one2three</span><span class="p">(</span><span class="n">mut</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">node</span><span class="p">,</span> <span class="n">new_node</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">chain</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">wt</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">resi</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">chain</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">mt</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">resi</span><span class="si">}</span><span class="sh">'</span>
    <span class="k">assert</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">g</span><span class="p">.</span><span class="n">nodes</span>
    
    <span class="n">ng</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nf">relabel_nodes</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="p">{</span><span class="n">node</span><span class="p">:</span> <span class="n">new_node</span><span class="p">})</span>
    <span class="n">ng</span><span class="p">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">new_node</span><span class="p">][</span><span class="sh">'</span><span class="s">amino_acid_one_hot</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">get_aa_one_hot</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ng</span><span class="p">,</span> <span class="n">new_node</span>


<span class="k">def</span> <span class="nf">generate_dataloader</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="c1"># only do that for mutations, ignore insert or dele for now
</span>    <span class="c1"># insertion can be: duplicating neighbor residues then resample edges
</span>    <span class="c1"># deletion might be tricky: keep neighbor info then deleting the node then use neighbors for prediction
</span>    
    <span class="k">assert</span> <span class="nf">len</span><span class="p">(</span><span class="nb">set</span><span class="p">.</span><span class="nf">intersection</span><span class="p">(</span><span class="nf">set</span><span class="p">([</span><span class="sh">'</span><span class="s">mutation</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">deltaG</span><span class="sh">'</span><span class="p">]),</span> <span class="nf">set</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">)))</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="n">datalist</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">:</span> 
        <span class="n">mut</span><span class="p">,</span> <span class="n">dg</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">mutation</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">deltaG</span><span class="sh">'</span><span class="p">]]</span>
        
        <span class="k">if</span> <span class="n">mut</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">islower</span><span class="p">():</span> <span class="k">continue</span>
        
        <span class="c1"># just skipping some "mutations" that does not pass the assert
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="n">ng</span><span class="p">,</span> <span class="n">new_node</span> <span class="o">=</span> <span class="nf">mutate_aa</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">mut</span><span class="p">)</span>
            <span class="n">d</span> <span class="o">=</span> <span class="nf">graph2data</span><span class="p">(</span><span class="n">ng</span><span class="p">,</span> <span class="n">new_node</span><span class="p">)</span>
            <span class="n">d</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">dg</span>
            <span class="n">d</span><span class="p">.</span><span class="n">mut</span> <span class="o">=</span> <span class="n">mut</span>
        <span class="k">except</span><span class="p">:</span> 
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Cannot process </span><span class="si">{</span><span class="n">mut</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">continue</span>
        
        <span class="n">datalist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">GFocus</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">datalist</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">follow_batch</span><span class="o">=</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Now we can create a data loader for training.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="code"><pre><span class="c1"># data loader
</span><span class="n">dataloader</span> <span class="o">=</span> <span class="nf">generate_dataloader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="nf">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="mi">26</span>
<span class="nc">GFocusBatch</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">1376</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">x_batch</span><span class="o">=</span><span class="p">[</span><span class="mi">1376</span><span class="p">],</span> <span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2880</span><span class="p">],</span> <span class="n">focus</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">mut</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">batch</span><span class="o">=</span><span class="p">[</span><span class="mi">1376</span><span class="p">],</span> <span class="n">ptr</span><span class="o">=</span><span class="p">[</span><span class="mi">33</span><span class="p">])</span></code></pre></figure> <h3 id="3-naive-graph-neural-network-model">3. Naive Graph Neural Network Model</h3> <p>Here I used 4 simple layers:</p> <ul> <li>Pre: Preprocessing</li> <li>GNN: Message passing layers</li> <li>Neighborhood: Neighbor aggregation</li> <li>Head: Regression head</li> </ul> <h4 id="1-preprocessing-layer">1. Preprocessing layer</h4> <p>This layer processes the node features using 2 <code class="language-plaintext highlighter-rouge">Linear</code> layers. Or one can just use <a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"><code class="language-plaintext highlighter-rouge">torch.nn.Embedding</code></a> layer, if the node features are one-hot or discrete.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">Pre</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">Pre</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_dim</span> <span class="o">=</span> <span class="n">in_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                                          <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span> 
                                          <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)])</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> 
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></td></tr></tbody></table></code></pre></figure> <h4 id="2-message-passing-layers">2. Message Passing Layers</h4> <p>This is the message passing operation by the simplest <code class="language-plaintext highlighter-rouge">GCNConv</code> graph convolution layer.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hops</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        
        <span class="nf">super</span><span class="p">(</span><span class="n">GNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="c1"># self.in_dim = in_dim
</span>        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hops</span> <span class="o">=</span> <span class="n">hops</span>
        
        <span class="n">gnn_layers</span><span class="p">,</span> <span class="n">bn_layers</span><span class="p">,</span> <span class="n">act_layers</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">__</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">hops</span><span class="p">):</span> 
            <span class="n">gnn_layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">GCNConv</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">add_self_loops</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
            <span class="n">bn_layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">))</span>
            <span class="n">act_layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">())</span>
        
        
        <span class="n">self</span><span class="p">.</span><span class="n">gnn_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span><span class="n">gnn_layers</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span><span class="n">bn_layers</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">act_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span><span class="n">act_layers</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span> 
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hops</span><span class="p">):</span> <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">bn_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">self</span><span class="p">.</span><span class="n">act_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">self</span><span class="p">.</span><span class="n">gnn_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></td></tr></tbody></table></code></pre></figure> <h4 id="3-local-neighborhood-aggregation">3. Local Neighborhood Aggregation</h4> <p>This might be tricky because given different mutation position, the focused neighborhood changes and indexed by <code class="language-plaintext highlighter-rouge">neighbor_idx</code>. The <code class="language-plaintext highlighter-rouge">GFocus</code> data class has this <code class="language-plaintext highlighter-rouge">focus</code> index and is colleated following minibatches of the graphs.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="code"><pre><span class="c1"># get focus
</span><span class="k">def</span> <span class="nf">get_focus</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">focus</span><span class="p">,</span> <span class="n">hop</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">focus</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
    <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>
    <span class="k">for</span> <span class="n">__</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">hop</span><span class="p">):</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">idx</span><span class="p">,</span> <span class="n">col</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">isin</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">idx</span><span class="p">)],</span> <span class="n">row</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="nf">isin</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">idx</span><span class="p">)]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">idx</span><span class="p">.</span><span class="nf">unique</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">NeighborHood</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">aggr</span><span class="o">=</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">,</span> <span class="n">hop</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">NeighborHood</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="k">assert</span> <span class="n">aggr</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">aggr</span> <span class="o">=</span> <span class="n">aggr</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hop</span> <span class="o">=</span> <span class="n">hop</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">phi</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">act_phi</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bn_phi</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">psi</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">act_psi</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">focus</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span> 
        
        <span class="n">neighbor_idx</span> <span class="o">=</span> <span class="nf">get_focus</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">focus</span><span class="p">)</span>
        <span class="n">message</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">bn_phi</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">act_phi</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">phi</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">neighbor_idx</span><span class="p">])))</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">aggr</span> <span class="o">==</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">:</span> <span class="n">message</span> <span class="o">=</span> <span class="nf">scatter_mean</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="n">neighbor_idx</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">aggr</span> <span class="o">==</span> <span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">:</span> <span class="n">message</span> <span class="o">=</span> <span class="nf">scatter_sum</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="n">neighbor_idx</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="k">raise</span> <span class="nc">NotImplementedError</span><span class="p">()</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">act_psi</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">psi</span><span class="p">(</span><span class="n">message</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></td></tr></tbody></table></code></pre></figure> <h4 id="4-regression-head">4. Regression Head:</h4> <p>This is nothing but a prediction head from the embeddings of the focused neighborhood.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">RegressionHead</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">RegressionHead</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span> 
                                           <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">SiLU</span><span class="p">(),</span>
                                           <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> 
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <h4 id="5-full-model-and-loss">5. Full Model and Loss</h4> <p>The full model <code class="language-plaintext highlighter-rouge">StabilityGNN</code> is now:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre></td><td class="code"><pre><span class="c1"># full model
</span><span class="k">class</span> <span class="nc">StabilityGNN</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">hops</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span> 
        
        <span class="nf">super</span><span class="p">(</span><span class="n">StabilityGNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">in_dim</span> <span class="o">=</span> <span class="n">in_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hops</span> <span class="o">=</span> <span class="n">hops</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">pre</span> <span class="o">=</span> <span class="nc">Pre</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gnn</span> <span class="o">=</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">nh</span> <span class="o">=</span> <span class="nc">NeighborHood</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">head</span> <span class="o">=</span> <span class="nc">RegressionHead</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">focus</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span> 
        
        <span class="n">processed_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pre</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">node_embeds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gnn</span><span class="p">(</span><span class="n">processed_x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">focus_embeds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">nh</span><span class="p">(</span><span class="n">node_embeds</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">focus</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">focus_embeds</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="n">focus_embeds</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Since this is a regression task, I used the <code class="language-plaintext highlighter-rouge">MSELoss</code></p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Now Let’s test the functionalities of these layers and their inputs and outputs.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="code"><pre><span class="c1"># testing the functionalities of the layers
</span>
<span class="c1"># Pre
</span><span class="n">pre</span> <span class="o">=</span> <span class="nc">Pre</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">processed_x</span> <span class="o">=</span> <span class="nf">pre</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># GNN
</span><span class="n">gnn</span> <span class="o">=</span> <span class="nc">GNN</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nf">gnn</span><span class="p">(</span><span class="n">processed_x</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">edge_index</span><span class="p">)</span>

<span class="c1"># Neighborhood
</span><span class="n">nh</span> <span class="o">=</span> <span class="nc">NeighborHood</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="nf">nh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">focus</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">x_batch</span><span class="p">)</span>

<span class="c1"># RegressionHead
</span><span class="n">rh</span> <span class="o">=</span> <span class="nc">RegressionHead</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="nf">rh</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="code"><pre><span class="c1"># testing the whole model
</span>
<span class="n">sgnn</span> <span class="o">=</span> <span class="nc">StabilityGNN</span><span class="p">()</span>
<span class="n">focus_embeds</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="nf">sgnn</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">focus</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">x_batch</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">focus_embeds</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">pred</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">32</span>
</pre></td></tr></tbody></table></code></pre></figure> <h3 id="4-training">4. Training</h3> <p>Training the neighborhood embeddings to fit the dG locally on cpu… Took ~5 min for training with 800 (tiny) mutated graphs.</p> <p>I was training this small example on CPU. If one wants to train on GPU, just <code class="language-plaintext highlighter-rouge">.to('cuda')</code></p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td class="code"><pre><span class="c1"># using naive model
</span><span class="n">stability_gnn</span> <span class="o">=</span> <span class="nc">StabilityGNN</span><span class="p">()</span>
<span class="n">mse_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">()</span>
<span class="n">l1_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">L1Loss</span><span class="p">()</span>


<span class="n">nepochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">wd</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span>
<span class="n">loss_type</span> <span class="o">=</span> <span class="sh">'</span><span class="s">L2</span><span class="sh">'</span>
<span class="n">log_every</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="n">nepochs</span> <span class="o">/</span> <span class="mi">20</span><span class="p">))</span>


<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">stability_gnn</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">wd</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">nepochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="sh">'</span><span class="s">Training Stability GNN</span><span class="sh">'</span><span class="p">):</span> 
    
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span> 
        
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">__</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="nf">stability_gnn</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">focus</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">x_batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">))</span> <span class="k">if</span> <span class="n">loss_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">L2</span><span class="sh">'</span> <span class="k">else</span> <span class="nf">l1_loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">))</span>
        
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="n">losses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
    
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">losses</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">log_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">-- Epoch = </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">, MSE-Loss = </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">5.007125299710494</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.3031598604642428</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.22531221978939497</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">150</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.1948822490297831</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.18019723892211914</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">250</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.16349028222835982</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.16791437165095255</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">350</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.14197989237996247</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.16626639348956254</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">450</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.13275881555791086</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.14490264081037962</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">550</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.11256958214709392</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">600</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.13622687069269326</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">650</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.10607394826813386</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">700</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.11214157938957214</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">750</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.103588092355774</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.11125421910904922</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">850</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.09300274430559231</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">900</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.11821510571126755</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">950</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.15214177851493543</span>
<span class="o">--</span> <span class="n">Epoch</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">MSE</span><span class="o">-</span><span class="n">Loss</span> <span class="o">=</span> <span class="mf">0.09064253620230235</span></code></pre></figure> <p>It seems like for these small singly mutated graphs, the model can learn the stability from local neighorhood embeddings. In another experiment, I was getting <code class="language-plaintext highlighter-rouge">&lt; 0.05</code> MSE loss. It might be interesting to test the trained model on an independent protein structures and see how it performs and if the neighborhood embeddings can be generalized.</p> <h3 id="5-final-note">5. Final Note</h3> <p>The StabilityGNN is just a naive model for this task with minimal inductive bias. I ran it serval times and I could get down to mse &lt; 0.1 in 1000 epochs just using one-hot.</p> <p>The model assumes identical conformation upon mutation, which is not always the case. That is why more complex structural modeling tools, such as Rosetta or Molecular Dynamics simulations were developed and used to model slight to drastic conformational changes.</p> <p>The <code class="language-plaintext highlighter-rouge">focus</code> only consider <code class="language-plaintext highlighter-rouge">k</code>-hop neighbor, if <code class="language-plaintext highlighter-rouge">k=0</code> it might just learn the PSSM of the position. If <code class="language-plaintext highlighter-rouge">k &gt; 2</code>, the neighborhood information might be over-smoothed and is hard to generalize. Moreover, there are some cases where allosterics is critical in protein stability; such long-range interaction might help in stabilizing the proteins and undermine the naive assumption of this GNN model.</p> <p>There can be multiple ways to improve / train the model, I’ll not reveal too much on that then..</p> <p>The complete notebook can be found <a href="https://github.com/jipq6175/StabilityGNN/blob/main/GNN-stability-snippet.ipynb">here</a>.</p>]]></content><author><name></name></author><category term="models"/><category term="coding"/><category term="fitting"/><category term="solving"/><summary type="html"><![CDATA[A small exercise to apply GNN on dG prediction]]></summary></entry><entry><title type="html">Deploying Pytorch Model Without Releasing Model Code</title><link href="https://jipq6175.github.io/blog/2023/torchjit/" rel="alternate" type="text/html" title="Deploying Pytorch Model Without Releasing Model Code"/><published>2023-03-08T23:15:00+00:00</published><updated>2023-03-08T23:15:00+00:00</updated><id>https://jipq6175.github.io/blog/2023/torchjit</id><content type="html" xml:base="https://jipq6175.github.io/blog/2023/torchjit/"><![CDATA[<p>I have been encountering situations where I would like to deploy a trained pytorch model but feeling reluctant to have the full model details revealed. This might be the case where end users will try to copy and reproduce the model (even though the training data is the key) or the code or model has not been published or the model source code needs to be protected.</p> <p>My typical workflow for preliminary model deployemnt has been setting up the models and load the training checkpoints and then do model inference:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># saving the model
</span><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sh">'</span><span class="s">model.pt</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># loading the model
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">model.pt</span><span class="sh">'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="c1"># inference 
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="nf">model</span><span class="p">()</span></code></pre></figure> <p>Even the above is dockerized, in the container, there is still raw model code. The end user can just ssh and fetch the code.</p> <p>Another way to avoid revealing the model code in the deployment is using a cloud api, which I will explore later in my current project.</p> <p>For now, what I am after is like a binary file, that can just load the saved model and do inference on user’s data for some prediction. I found this interesting tool: <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">TorchScript</a>. Basically, it can save the model not as <code class="language-plaintext highlighter-rouge">state_dict</code> but as JIT compiled function, similar to how <code class="language-plaintext highlighter-rouge">Julia</code> compiles a function into binary.</p> <h3 id="simple-example">Simple Example</h3> <p>A very basic example. Say one has a model to deploy without source code.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">()</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">99</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="nf">print</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.5713</span><span class="p">,</span> <span class="mf">0.4536</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.7102</span><span class="p">,</span> <span class="mf">0.2850</span><span class="p">,</span> <span class="mf">0.1824</span><span class="p">,</span> <span class="mf">0.1124</span><span class="p">]])</span></code></pre></figure> <p>Instead of saving the model dictionary, one can do</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">traced_cell</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">traced_cell</span><span class="p">,</span> <span class="sh">'</span><span class="s">model.jit</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>The <code class="language-plaintext highlighter-rouge">torch.jit.trace</code> takes 2 arguments: <code class="language-plaintext highlighter-rouge">model</code> and <code class="language-plaintext highlighter-rouge">inputs</code> which can be tensor or tuple of tensors. If the model’s forward pass take multiple tensors, they can be <code class="language-plaintext highlighter-rouge">torch.jit.trace(model, (x1, x2, x3))</code>.</p> <p>Now at inference time, one does not need to define <code class="language-plaintext highlighter-rouge">Model</code> in the code, just load <code class="language-plaintext highlighter-rouge">model.jit</code> then deploy.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">99</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">model.jit</span><span class="sh">'</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="nf">print</span><span class="p">(</span><span class="nf">loaded_model</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.5713</span><span class="p">,</span> <span class="mf">0.4536</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.7102</span><span class="p">,</span> <span class="mf">0.2850</span><span class="p">,</span> <span class="mf">0.1824</span><span class="p">,</span> <span class="mf">0.1124</span><span class="p">]])</span></code></pre></figure> <p>The outputs are the same.</p> <h3 id="gnn-example">GNN Example</h3> <p>The model I am trying to deploy is a GNN model with multiple input tensors of complex information. I will use a trivial GNN model trained on Cora dataset.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># load the Cora data
</span><span class="kn">from</span> <span class="n">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">Planetoid</span>
<span class="kn">from</span> <span class="n">torch_geometric.transforms</span> <span class="kn">import</span> <span class="n">NormalizeFeatures</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="nc">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">data/Planetoid</span><span class="sh">'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Cora</span><span class="sh">'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">NormalizeFeatures</span><span class="p">())</span>

<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Dataset: </span><span class="si">{</span><span class="n">dataset</span><span class="si">}</span><span class="s">:</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">======================</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of graphs: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of features: </span><span class="si">{</span><span class="n">dataset</span><span class="p">.</span><span class="n">num_features</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of classes: </span><span class="si">{</span><span class="n">dataset</span><span class="p">.</span><span class="n">num_classes</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Dataset</span><span class="p">:</span> <span class="nc">Cora</span><span class="p">():</span>
<span class="o">======================</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">graphs</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">features</span><span class="p">:</span> <span class="mi">1433</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">classes</span><span class="p">:</span> <span class="mi">7</span></code></pre></figure> <p>The GNN model is just a three-hop graph convolution.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">GraphConv</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">GraphNet</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span> 
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">):</span> 
        <span class="nf">super</span><span class="p">(</span><span class="n">GraphNet</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">89</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">num_node_features</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">num_classes</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span> 
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">).</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">).</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="nc">GraphNet</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nc">GraphNet</span><span class="p">(</span>
  <span class="p">(</span><span class="n">conv1</span><span class="p">):</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="mi">1433</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">conv2</span><span class="p">):</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">conv3</span><span class="p">):</span> <span class="nc">GraphConv</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="p">)</span></code></pre></figure> <p>Let’s train it briefly:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="n">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">GraphNet</span><span class="p">(</span><span class="n">hidden_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train_gnn</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">)</span> 
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">train_mask</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">train_mask</span><span class="p">])</span>  
    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>  
    <span class="k">return</span> <span class="n">loss</span>

<span class="k">def</span> <span class="nf">test_gnn</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">test_correct</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">test_mask</span><span class="p">]</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">test_mask</span><span class="p">]</span>  
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">test_correct</span><span class="p">.</span><span class="nf">sum</span><span class="p">())</span> <span class="o">/</span> <span class="nf">int</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">test_mask</span><span class="p">.</span><span class="nf">sum</span><span class="p">())</span>  
    <span class="k">return</span> <span class="n">test_acc</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">)):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">train_gnn</span><span class="p">()</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="nf">test_gnn</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test Acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">Epoch</span><span class="p">:</span> <span class="mi">050</span><span class="p">,</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.8477</span><span class="p">,</span> <span class="n">Test</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.697</span>
<span class="n">Epoch</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.5670</span><span class="p">,</span> <span class="n">Test</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.731</span></code></pre></figure> <p>Assume the model is fully trained and is ready to be saved.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">traced_cell</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">))</span> <span class="c1"># the model inputs are node feature x and edge indices
</span><span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">traced_cell</span><span class="p">,</span> <span class="sh">'</span><span class="s">gnn_model.jit</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>And in the inference time, in another machine or compute environment, just load the <code class="language-plaintext highlighter-rouge">gnn_model.jit</code> without explicitly writing the <code class="language-plaintext highlighter-rouge">GraphNet</code> model:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch_geometric.datasets</span> <span class="kn">import</span> <span class="n">Planetoid</span>
<span class="kn">from</span> <span class="n">torch_geometric.transforms</span> <span class="kn">import</span> <span class="n">NormalizeFeatures</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">gnn_model.jit</span><span class="sh">'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="nc">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="sh">'</span><span class="s">data/Planetoid</span><span class="sh">'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">Cora</span><span class="sh">'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="nc">NormalizeFeatures</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span> <span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">edge_index</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">torch</span><span class="p">.</span><span class="nc">Size</span><span class="p">([</span><span class="mi">2708</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span></code></pre></figure> <p>This is the model prediction for 2708 nodes with 7 classes.</p> <p>We still can get the number of parameters is the same way and look into model weights:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
    <span class="k">break</span>

<span class="nf">print</span><span class="p">()</span>
<span class="nf">sum</span><span class="p">(</span><span class="n">param</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span> <span class="mf">0.0042</span><span class="p">,</span>  <span class="mf">0.0584</span><span class="p">,</span>  <span class="mf">0.0186</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0327</span><span class="p">,</span>  <span class="mf">0.0167</span><span class="p">,</span>  <span class="mf">0.0612</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0389</span><span class="p">,</span>  <span class="mf">0.0680</span><span class="p">,</span>  <span class="mf">0.0121</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0318</span><span class="p">,</span>  <span class="mf">0.0492</span><span class="p">,</span>  <span class="mf">0.0837</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0114</span><span class="p">,</span>  <span class="mf">0.0003</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0106</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0071</span><span class="p">,</span>  <span class="mf">0.0634</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0186</span><span class="p">],</span>
        <span class="p">...,</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0026</span><span class="p">,</span>  <span class="mf">0.0363</span><span class="p">,</span>  <span class="mf">0.0133</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0569</span><span class="p">,</span>  <span class="mf">0.0296</span><span class="p">,</span>  <span class="mf">0.0702</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0274</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0403</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0286</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.0239</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0148</span><span class="p">,</span>  <span class="mf">0.0049</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0077</span><span class="p">,</span>  <span class="mf">0.0201</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0033</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0302</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0283</span><span class="p">,</span>  <span class="mf">0.0827</span><span class="p">]],</span>
       <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="mi">94279</span></code></pre></figure> <h3 id="save-compiled-torch-function">Save compiled torch function</h3> <p><code class="language-plaintext highlighter-rouge">torch.jit.trace</code> extends beyond just pytorch models. It can be applied to pytorch functions as well. It can save a compiled function, which can be loaded without defining the function explicitly, like a binary.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">some_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="nf">some_function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span></code></pre></figure> <p>And use the same trick.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">traced_cell</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">some_function</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">traced_cell</span><span class="p">,</span> <span class="sh">'</span><span class="s">some_function.jit</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <p>In another python script or in another machine, just do:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">f</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">some_function.pth</span><span class="sh">"</span><span class="p">)</span>
<span class="n">f</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nc">RecursiveScriptModule</span><span class="p">(</span><span class="n">original_name</span><span class="o">=</span><span class="n">PlaceholderModule</span><span class="p">)</span></code></pre></figure> <p>And</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">f</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span></code></pre></figure> <p>Output:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nf">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span></code></pre></figure> <p>That’s pretty convenient. The inference pipeline can consist of a number of these compiled models as blackboxes without revealing the code of the model or functions.</p> <p>Another advantage. There are a number of models with different hyperparameters at deployment. I had to fetch the model config via <code class="language-plaintext highlighter-rouge">wandb</code> and initiate the model accordingly before loading the state dictionary. But with saved jit-compiled model, just load them and forward pass (given that they all take the same inputs).</p>]]></content><author><name></name></author><category term="pytorch"/><category term="coding"/><category term="solving"/><summary type="html"><![CDATA[Deploying pytorch Model without releasing model code]]></summary></entry></feed>